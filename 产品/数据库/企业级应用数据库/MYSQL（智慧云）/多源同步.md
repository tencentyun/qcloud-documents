## BUG修复
- 修复mydumper在ssl场景下由于yassl导致的导出性能极低的问题：开启了SSL的db，旧版本mydumper dump效率极低，改用mysql8的 libmysqlclient 和 openssl 
- 修复水平扩容时手动切换路由导致任务被重复创建的问题：同时创建2个扩容任务并选择手动切换，当两个set均创建成功后进行手动切换路由，会导致第二个扩容出来的任务被重复创建
- 修复同步到Oracle目标为clob类型时同步错误问题：目标为Oracle，类型为CLOB时，由于字段长度过长，会出现to_clob函数长度限制的异常，修改后会在本地进行转码后再进行数据插入
- 修复producter生产数据时占用delete状态 tmp文件不释放的问题
	- 每处理完一个binlog文件，进行一次清理，在单个binlog文件处理的中途不会进行清理。
	- 具体的清理操作通过 reinit PRINT_EVENT_INFO 来完成。


## 新增功能
- 动态调整kafka msg size 参数（productBatchMsg），避免消息过大导致的任务延迟：
	- 当kafka限制单次包大小的情况下，单次批量发送数据可能会发送失败，导致反复重启重试
	- 更新后会动态向下调整，步长 3/4，后续版本添加自动回调的配置
- mgn抢占机制完善，更好的灰度方案：
	- 优化后被kill掉的任务进程会优先在原来所在的消费者机器上重启
	- mgn配置weight为0时，不参与抢占和负载均衡的操作
- 多源同步合并版本支持二级分区表的同步：
	- 添加了14.50版本二级分区需求的相关功能和实现，具体内容参考14.55版本release-note
- 多源同步支持topic快速迁移：
	- 修改zk中对应set的 setrun节点，修改对应的 unique_id字段，将原有的 unique_id 添加到 history_unique_ids 的尾部，history_unique_ids 记录历史曾经使用过的 unique_id，类似 history_ids 字段
	- 多源同步自动监听相应变更，实现topic的切换，保障数据完整/一致性
- consumer监控合并版本目标proxy变更：
	- consumer会监听合并版本目标垂直/水平扩容等动作，自动更新zk节点中的dstproxylist信息
- consumermgn支持限制任务总量：
	- consumermgn可以通过参数joblimit配置本机的任务数，任务数达到上限后不再参与任务抢占
- 全量校验工具支持多个noshard到单groupshard的数据校验：
	- 全量校验工具支持配置extrawhere参数，添加查询条件到实际SQL中，从而实现noshard→groupshard的部分条件下校验


## 功能优化
- 全量同步过程中支持暂停任务，暂停后会等待开启后再继续全量
	- 这里的暂停是当前表全量完后开始暂停，并不会停止正在进行的全量进程
- 多源同步目标为kafka时回调优化：目标为kafka时，回调消息不再解析Json，减少消耗
- 初始化的时候支持多个表并行oncesync：内部添加任务线程池，允许配置全量线程数，多线程对多表并行全量同步
- oracle插入数据的时候带上列名：向目标oracle插入数据时，SQL中添加了插入的相关列的列名
- 同步前置校验不支持表名带小数点的表：源库中存在带" . "的表时，任务无法正常创建开启，现在对源端带" . "的表名会在全量同步匹配规则前自动进行过滤

