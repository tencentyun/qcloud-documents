## 快速使用 GooseFSRuntime

使用 GooseFSRuntime 流程简单，在准备完基本 k8s 和对象存储（Cloud Object Storage，COS）环境的条件下，您只需要耗费10分钟左右即可部署完成所需的 GooseFSRuntime 环境，您可以按照下面的流程进行部署。

## 前提条件

- 已安装 Git。
- 已安装 Kubernetes 集群（version >= 1.14），并且支持 CSI 功能。为获得最佳实践，您可以直接在 [腾讯云容器服务（Tencent Kubernetes Engine，TKE）](https://cloud.tencent.com/document/product/457/32187)部署。
- 已安装 kubectl（version >= 1.14）。关于 `kubectl` 安装和配置详情，请参见 [Kubernetes 文档](https://kubernetes.io/docs/tasks/tools/install-kubectl/)。
- 已安装 Helm（version >= 3.0）。关于 Helm 3 安装和配置详情，请参见 [HELM 文档](https://v3.helm.sh/docs/intro/install/)。
- 如下提供了本地安装包 `fluid.tgz`，您可以直接安装使用：
```shell
$ helm install fluid fluid.tgz
NAME: fluid
LAST DEPLOYED: Mon Mar 29 11:21:46 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
```

>? `helm install`命令的一般格式是`helm install <RELEASE_NAME> <SOURCE>`，在上面的命令中，第一个`fluid`指定了安装的 release 名称（可自行更改），第二个`fluid.tgz`指定了helm chart 所在的路径。
>

## 操作步骤

### 1. 创建命名空间
```shell
kubectl create ns fluid-system
```
### 2. 下载 fluid

单击下载 [fluid-0.6.0.tgz](https://cos-data-lake-release-1253960454.cos.ap-guangzhou.myqcloud.com/fluid.tgz) 安装包。

>! 您也可以前往 [Fluid Releases](https://github.com/fluid-cloudnative/fluid/releases) 下载最新版本，但部分机器从中国境内访问该网站可能存在网络问题。
>

### 3. 使用 Helm 安装 Fluid

```shell
helm install --set runtime.goosefs.enabled=true fluid fluid-0.6.0.tgz
```

### 4. 查看 Fluid 的运行状态

```shell
$ kubectl get pod -n fluid-system
NAME                                         READY   STATUS    RESTARTS   AGE
csi-nodeplugin-fluid-2mfcr                   2/2     Running   0          108s
csi-nodeplugin-fluid-l7lv6                   2/2     Running   0          108s
dataset-controller-5465c4bbf9-5ds5p          1/1     Running   0          108s
goosefsruntime-controller-564f59bdd7-49tkc    1/1     Running   0          108s
```
其中，csi-nodeplugin-fluid-xx 的数量应与 k8s 集群中节点 node 的数量相同。

### 5. GooseFS 缓存环境准备

#### （1）准备 COS 服务

您需要开通 COS，并完成存储桶的创建，创建指引可参见 [创建存储桶](https://cloud.tencent.com/document/product/436/13309)。

#### （2）准备测试样例数据

我们可以使用 Apache 镜像站点上的 Spark 相关资源作为演示中使用的远程文件。在实际使用当中，您也可以将这个远程文件修改为您的任意远程文件。

- 现在远程资源文件到本地
```shell
mkdir tmp
cd tmp
wget https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz 
wget https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz 
```
- 上传本地文件到 COS 上
您可以使用腾讯云 COS 团队提供的客户端 [COSCMD](https://cloud.tencent.com/document/product/436/10976) 或者腾讯云 COS 团队提供的 [COS SDK](https://cloud.tencent.com/document/product/436/6474)，按照使用说明将本地下载的文件上传到 COS 的存储桶上。

#### （3）创建 dataset 和 GooseFSRuntime

i. 创建一个 resource.yaml 文件，里面包含如下内容：
- 包含数据集及 ufs 的 dataset 信息。
- 创建一个 Dataset CRD 对象，描述了数据集的来源，例如示例中的 test-bucket。
- 创建一个 GooseFSRuntime，相当于启动一个 GooseFS 的集群用于提供缓存服务。

<dx-codeblock>
::: yaml yaml
apiVersion: data.fluid.io/v1alpha1
kind: Dataset
metadata:
  name: hadoop
spec:
  mounts:
    - mountPoint: cosn://test-bucket/
      options:
        fs.cos.accessKeyId: <COS_ACCESS_KEY_ID>
        fs.cos.accessKeySecret: <COS_ACCESS_KEY_SECRET>
        fs.cosn.bucket.region: <COS_REGION>
        fs.cosn.impl: org.apache.hadoop.fs.CosFileSystem
        fs.AbstractFileSystem.cosn.impl: org.apache.hadoop.fs.CosN
        fs.cos.app.id: <COS_APP_ID> 
      name: hadoop

---
apiVersion: data.fluid.io/v1alpha1
kind: GooseFSRuntime
metadata:
  name: hadoop
spec:
  replicas: 2
  tieredstore:
    levels:
      - mediumtype: HDD
        path: /mnt/disk1
        quota: 100G
        high: "0.9"
        low: "0.8"
:::
</dx-codeblock>

- Dataset：
 - mountPoint：表示挂载 UFS 的路径，路径中不需要包含 endpoint 信息。
 - options：在 options 需要指定存储桶的必要信息，具体可参考 [API 术语信息](https://cloud.tencent.com/document/product/436/7751)。
 - fs.cos.accessKeyId/fs.cos.accessKeySecret：拥有权限访问该 COS 存储桶的密钥信息。
- GooseFSRuntime：更多 API 可参考 [api_doc.md](https://github.com/fluid-cloudnative/fluid/blob/master/docs/en/dev/api_doc.md)。
 - replicas：表示创建 GooseFS 集群节点的数量。
 - mediumtype： GooseFS 支持 HDD/SSD/MEM 三种类型缓存介质，提供多级缓存配置。
 - path：存储路径。
 - quota：缓存最大容量。
 - high：水位上限大小。
 - low：水位下限大小。

ii. 执行如下命令，创建 GooseFSRuntime：
```shell
kubectl create -f resource.yaml
```
iii. 查看部署的 GooseFSRuntime 情况，显示全部为 Ready 状态表示部署成功。
```shell
kubectl get goosefsruntime hadoop
NAME     MASTER PHASE   WORKER PHASE   FUSE PHASE   AGE
hadoop    Ready           Ready           Ready     62m
```

 iv. 查看 dataset 的情况，显示 Bound 状态表示 dataset 绑定成功。
```shell
$ kubectl get dataset hadoop
NAME     UFS TOTAL SIZE   CACHED   CACHE CAPACITY   CACHED PERCENTAGE   PHASE   AGE
hadoop        511MiB       0.00B    180.00GiB              0.0%          Bound   1h
```

v. 查看 PV、PVC 创建情况，GooseFSRuntime 部署过程中会自动创建 PV 和 PVC。
```shell
kubectl get pv,pvc
NAME                      CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM            STORAGECLASS   REASON   AGE
persistentvolume/hadoop   100Gi      RWX            Retain           Bound    default/hadoop                           58m


NAME                           STATUS   VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/hadoop   Bound    hadoop   100Gi      RWX                           58m
```

### 6. 创建应用容器体验加速效果

您可以通过创建应用容器来使用 GooseFS 加速服务，或者进行提交机器学习作业来进行体验相关功能。

如下，创建一个应用容器 app.yaml 用于使用该数据集。我们将多次访问同一数据，并比较访问时间来展示 GooseFS 的加速效果。
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: demo-app
spec:
  containers:
    - name: demo
      image: nginx
      volumeMounts:
        - mountPath: /data
          name: hadoop
  volumes:
    - name: hadoop
      persistentVolumeClaim:
        claimName: hadoop
```

i. 使用 kubectl 完成创建应用：
```shell
kubectl create -f app.yaml
```

ii. 查看文件大小：
```shell
$ kubectl exec -it demo-app -- bash
$ du -sh /data/hadoop/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2 
210M    /data/hadoop/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2 
```

iii. 进行文件的 cp 观察时间消耗了18s：
```shell
$ time cp /data/hadoop/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2 /dev/null

real    0m18.386s
user    0m0.002s
sys      0m0.105s
```

iv. 查看此时 dataset 的缓存情况，发现210MB的数据已经都缓存到了本地。
```shell
$ kubectl get dataset hadoop
NAME     UFS TOTAL SIZE   CACHED   CACHE CAPACITY   CACHED PERCENTAGE   PHASE   AGE
hadoop   210.00MiB       210.00MiB    180.00GiB        100.0%           Bound   1h
```

v. 为了避免其他因素（例如 page cache）对结果造成影响，我们将删除之前的容器，新建相同的应用，尝试访问同样的文件。由于此时文件已经被 GooseFS 缓存，可以看到第二次访问所需时间远小于第一次。
```shell
kubectl delete -f app.yaml && kubectl create -f app.yaml
```

vi. 进行文件的拷贝观察时间，发现消耗48ms，整个拷贝的时间缩短了300倍。
```shell
$ time cp /data/hadoop/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2  /dev/null

real    0m0.048s
user    0m0.001s
sys      0m0.046s
```

### 7. 环境清理

- 删除应用和应用容器
- 删除 GooseFSRuntime
```shell
kubectl delete goosefsruntime hadoop
```
- 删除 dataset
```shell
kubectl delete dataset hadoop
```

以上通过一个简单的例子完成 GooseFS on Fluid 的入门体验和学习，并最后进行环境的清理，更多 Fluid GooseFSRuntime 的功能介绍可参见 [功能列表](https://cloud.tencent.com/document/product/436/59495)。
