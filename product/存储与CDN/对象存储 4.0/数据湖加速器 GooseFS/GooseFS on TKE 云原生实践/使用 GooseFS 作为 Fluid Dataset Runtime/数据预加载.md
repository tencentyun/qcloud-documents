为了保证应用在访问数据时的性能，可以通过**数据预加载**提前将远程存储系统中的数据拉取到靠近计算结点的分布式缓存引擎中，使得消费该数据集的应用能够在首次运行时即可享受到缓存带来的加速效果。

为此，我们提供了 DataLoad CRD，该 CRD 让您可通过简单的配置就能完成整个数据预加载过程，并对数据预加载的许多行为进行自定义控制。

本文档通过以下两个例子演示了 DataLoad CRD 的使用方法：

- DataLoad 快速使用
- DataLoad 进阶配置


## 前提条件

已安装了 [Fluid](https://github.com/fluid-cloudnative/fluid)（version >= 0.6.0）

>? 请参见 [安装](https://cloud.tencent.com/document/product/436/59493) 文档完成 Fluid 安装。
>

## 新建工作环境

```yaml
$ mkdir <any-path>/warmup
$ cd <any-path>/warmup
```

## DataLoad 快速使用

**配置待创建的 Dataset 和 Runtime 对象**
```yaml
apiVersion: data.fluid.io/v1alpha1
kind: Dataset
metadata:
  name: spark
spec:
  mounts:
    - mountPoint: https://mirrors.bit.edu.cn/apache/spark/
      name: spark 
---
apiVersion: data.fluid.io/v1alpha1
kind: GooseFSRuntime
metadata:
  name: spark
spec:
  replicas: 2
  tieredstore:
    levels:
      - mediumtype: SSD
        path: /mnt/disk1/
        quota: 2G
        high: "0.8"
        low: "0.7"
```

>? 为了方便用户进行测试，mountPoint 这里使用的是 Web UFS，使用 COS 作为 UFS 可见 [使用 GooseFS 挂载 COS（COSN）](https://cloud.tencent.com/document/product/436/56413#.E4.BD.BF.E7.94.A8-goosefs-.E6.8C.82.E8.BD.BD-cos.EF.BC.88cosn.EF.BC.89-.E6.88.96.E8.85.BE.E8.AE.AF.E4.BA.91-hdfs.EF.BC.88chdfs.EF.BC.89)。
>

在这里，我们将要创建一个 kind 为 `Dataset` 的资源对象（Resource object）。`Dataset` 是 Fluid 所定义的一个 Custom Resource Definition（CRD），该 CRD 被用来告知 Fluid 在哪里可以找到您所需要的数据。Fluid 将该 CRD 对象中定义的 `mountPoint` 属性挂载到 GooseFS 之上。

在本示例中，为了简单，我们使用 COS 进行演示。

**创建 Dataset 和 Runtime 对象**

```shell
$ kubectl create -f dataset.yaml
```

**等待 Dataset 和 Runtime 准备就绪**

```shell
$ kubectl get datasets spark
```

如果看到类似以下结果，说明 Dataset 和 Runtime 均已准备就绪：

```shell
NAME    UFS TOTAL SIZE   CACHED   CACHE CAPACITY   CACHED PERCENTAGE   PHASE   AGE
spark   1.92GiB          0.00B    4.00GiB          0.0%                Bound   4m4s
```

**配置待创建的 DataLoad 对象**
```yaml
apiVersion: data.fluid.io/v1alpha1
kind: DataLoad
metadata:
  name: spark-dataload
spec:
  loadMetadata: true
  dataset:
    name: spark
    namespace: default
```

`spec.dataset` 指明了需要进行数据预加载的目标数据集，在该例子中，我们的数据预加载目标为 `default` 命名空间下名为 `spark` 的数据集，如果该配置与您所在的实际环境不符，请根据您的实际环境对其进行调整。

**默认情况下，上述 DataLoad 配置将会尝试加载整个数据集中的全部数据**，如果您希望进行更细粒度的控制（例如仅加载数据集下指定路径的数据），请参见 [DataLoad 进阶配置](https://github.com/fluid-cloudnative/fluid/blob/master/docs/en/dev/api_doc.md)。

**创建 DataLoad 对象**

```shell
$ kubectl create -f dataload.yaml
```

**查看创建的 DataLoad 对象状态**

```shell
$ kubectl get dataload spark-dataload
```

上述命令会得到类似以下结果：

```shell
NAME             DATASET   PHASE     AGE
spark-dataload   spark     Loading   2m13s
```

您也可以通过 `kubectl describe` 获取有关该 DataLoad 的更多详细信息：

```shell
$ kubectl describe dataload spark-dataload
```

得到以下结果：
```
Name:         spark-dataload
Namespace:    default
Labels:       <none>
Annotations:  <none>
API Version:  data.fluid.io/v1alpha1
Kind:         DataLoad
...
Spec:
  Dataset:
    Name:       spark
    Namespace:  default
Status:
  Conditions:
  Phase:  Loading
Events:
  Type    Reason              Age   From      Message
  ----    ------              ----  ----      -------
  Normal  DataLoadJobStarted  80s   DataLoad  The DataLoad job spark-dataload-loader-job started
```

上述数据加载过程根据您所在的网络环境不同，可能会耗费数分钟。

**等待数据加载过程完成**

```shell
$ kubectl get dataload spark-dataload
```

您会看到该 DataLoad 的 `Phase` 状态已经从 `Loading` 变为 `Complete`，这表明整个数据加载过程已经完成。

```shell
NAME             DATASET   PHASE      AGE
$ spark-dataload   spark     Complete   5m17s
```

此时再次查看 Dataset 对象的缓存状态：

```shell
$ kubectl get dataset spark
```

可发现，远程存储系统中的全部数据均已成功缓存到分布式缓存引擎中。

```shell
NAME    UFS TOTAL SIZE   CACHED    CACHE CAPACITY   CACHED PERCENTAGE   PHASE   AGE
spark   1.92GiB          1.92GiB   4.00GiB          100.0%              Bound   7m41s
```

**环境清理**

```shell
$ kubectl delete -f .
```

## DataLoad 进阶配置

除了上述示例中展示的数据预加载功能外，通过一些简单的配置，您可以对数据预加载进行更加细节的调整，这些调整包括：

- 指定一个或多个数据集子目录进行加载
- 设置数据加载时的缓存副本数量
- 数据加载前首先进行元数据同步

### 指定一个或多个数据集子目录进行加载

进行数据加载时可以加载指定的子目录（或文件），而不是整个数据集，例如：
```yaml
apiVersion: data.fluid.io/v1alpha1
kind: DataLoad
metadata:
  name: spark-dataload
spec:
  dataset:
    name: spark
    namespace: default
  loadMetadata: true
  target:
    - path: /spark/spark-2.4.8
    - path: /spark/spark-3.0.1/pyspark-3.0.1.tar.gz
```

上述 DataLoad 仅会加载 `/spark/spark-2.4.8` 目录下的全部文件，以及 `/spark/spark-3.0.1/pyspark-3.0.1.tar.gz` 文件。

`spec.target.path` 的值均为 `mountpoint` 挂载点下的相对路径。例如当前的挂载点为 `cos://test/`，原始路径下有以下文件：

```shell
cos://test/user/sample.txt
cos://test/data/fluid.tgz
```

那么 `target.path` 可定义为：
```yaml
target:
  - path: /user
  - path: /data
```

### 设置数据加载时的缓存副本数量

进行数据加载时，您也可以通过配置控制加载的数据副本数量，例如：
```yaml
apiVersion: data.fluid.io/v1alpha1
kind: DataLoad
metadata:
  name: spark-dataload
spec:
  dataset:
    name: spark
    namespace: default
  loadMetadata: true
  target:
    - path: /spark/spark-2.4.8
      replicas: 1
    - path: /spark/spark-3.0.1/pyspark-3.0.1.tar.gz
      replicas: 2
```

上述 DataLoad 在进行数据加载时，对于 `/spark/spark-2.4.8` 目录下的文件仅会在分布式缓存引擎中保留**1份**数据缓存副本，而对于文件 `/spark/spark-3.0.1/pyspark-3.0.1.tar.gz`，分布式缓存引擎将会保留**2份**缓存副本。

### 数据加载前首先进行元数据同步（建议开启）

在许多场景下，底层存储系统中的文件可能发生了变化，对于分布式缓存引擎来说，需要重新进行文件元信息的同步才能感知到底层存储系统中的变化。因此在进行数据加载前，您也可以通过设置 DataLoad 对象的 `spec.loadMetadata` 来预先完成元信息的同步操作，例如：
```yaml
apiVersion: data.fluid.io/v1alpha1
kind: DataLoad
metadata:
  name: spark-dataload
spec:
  dataset:
    name: spark
    namespace: default
  loadMetadata: true
  target:
    - path: /
      replicas: 1
```
