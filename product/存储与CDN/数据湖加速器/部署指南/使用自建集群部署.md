本文主要介绍如何规范化地在单机、集群以及腾讯云 EMR 集群（暂未集成支持 GooseFS 的版本）中部署、配置以及运行 GooseFS。

## 部署环境要求

### 硬件环境

目前 GooseFS 支持主流 x86/x64 架构的 Linux/MacOS 运行环境（**注意：MacOS M1处理器未验证支持**）。详细的运行节点配置如下：

#### Master 节点

- **CPU**：工作主频1GHz 及以上，考虑到 Master 需要处理量大，建议生产环境使用多核架构处理器。
- **物理内存**：1GB 及以上，生产环境建议使用8GB 以上的物理内存配置。
- **磁盘**：20GB 及以上，建议生产环境配备高性能的 NVME SSD 盘作为元数据缓存盘（RocksDB 模式）。

#### Worker 节点

- **CPU**：工作主频1GHz 及以上，考虑到 Worker 节点也需要处理大量的并发请求，同样建议生产环境使用多核架构处理器。
- **物理内存**：2GB 及以上，生产环境建议根据性能需求选用合适的物理内存配置。例如，生产环境中需要将大量的数据块缓存到 Worker 节点的内存中或是采用 MEM + SSD/HDD 的混合存储时，需要根据实际可能会缓存到内存中的数据量来配备物理内存。无论使用何种缓存模式，生产环境都建议 Worker 节点配备16GB 及以上的物理内存。
- **磁盘**：20GB 及以上 SSD/HDD 盘，建议根据实际生产环境中所需要预热缓存的数据量大小来估计每个 Worker 节点所需配置的磁盘空间。另外，为了更好的性能体验，建议配备采用 NVME 接口的 SSD 盘作为 Worker 节点的数据盘。

### 软件环境

- Red Hat Enterprise Linux 5.5+、Ubuntu Linux 12.04 LTS+（不使用批量部署时可以支持）、CentOS 7.4+以及 TLinux 2.x（Tencent Linux 2.x），基于 Intel 架构 MacOS 10.8.3 以上版本。腾讯云 CVM 用户推荐使用 CentOS 7.4、Tencent（TLinux 2.x）或 TencentOS Server 2.4 版本的操作系统。
- OpenJDK 1.8/Oracle JDK 1.8，需要注意的是，未验证支持 JDK 1.9 及以上版本。
- 支持 SSH 工具集（包括 SSH 和 SCP 工具）、Expect Shell（使用批量部署时需要）工具以及 Yum 包管理工具。

### 集群网络环境

- Master/Worker 节点之间外网或内网互通。使用批量部署时，要求 Master 能够正常访问外网软件源，或正确配置包管理系统的内网软件源。
- 集群能够通过外网或内网访问到 COS 存储桶或者 CHDFS 文件系统。

### 安全组与用户权限要求

一般情况，GooseFS 建议用户使用专用的 Linux 账户部署运行 GooseFS， 例如在自建集群和 EMR 环境中，可以统一使用 hadoop 用户来部署运行 GooseFS。在批量部署中，则需要补充以下用户能力和权限：

- 具备切换到 root 或使用 sudo 权限的能力；
- 部署运行账户具备读写安装目录的权限；
- Master 节点具备 SSH 登录到集群中所有 Worker 节点的权限；
- 集群中对应的节点角色需要放开对应的端口：Master（9200和9201）、Worker（9203和9204）、Job Master(9205、9206和9207)、Job Worker（9208、9209和9210）、Proxy（9211）以及 LogServer（9212）。

## 单机模式部署运行（伪分布式架构）

伪分布式架构部署主要适用于体验和调试 GooseFS，初级用户可以在自己的 Linux 或 Mac 系统主机上快速体验和调试 GooseFS。

### 部署

1. 首先 [下载 GooseFS 的二进制分发包](https://downloads.tencentgoosefs.cn/goosefs/1.4.2/release/goosefs-1.4.2-bin.tar.gz)。
2. 分发包下载后解压，进入到 GooseFS 的目录中，执行如下操作：
 - 通过拷贝 conf/goosefs-site.properties.ai-template 创建 conf/goosefs-site.properties 配置文件：
```bash
 $ cp conf/goosefs-site.properties.ai-template conf/goosefs-site.properties
```
或者通过拷贝 conf/goosefs-site.properties.bigdata-template 创建 conf/goosefs-site.properties 配置文件：
```bash
 $ cp conf/goosefs-site.properties.bigdata-template conf/goosefs-site.properties
```
 - 在 conf/goosefs-site.properties 配置文件中设置 `goosefs.master.hostname` 为 `localhost`。
 - 在 conf/goosefs-site.properties 配置文件中设置 `goosefs.master.mount.table.root.ufs` 为本地文件系统中的目录，例如：/tmp 或是 /data/goosefs 等。

建议配置 localhost 的 SSH 免密登录，否则格式化和启动等操作，需要输入 localhost 的登录密码。

### 运行

执行如下命令，就可以完成挂载一个 RamFS 文件系统：

```bash
$ ./bin/goosefs-mount.sh SudoMount
```

同样，也可以不执行上面的命令，而直接在启动 GooseFS 集群时挂载：

```bash
$ ./bin/goosefs-start.sh local SudoMount
```

当启动后，使用 `jps` 命令，能够看到伪分布式模式下，GooseFS 的所有进程：

```bash
$ jps
35990 Jps
35832 GooseFSSecondaryMaster
35736 GooseFSMaster
35881 GooseFSWorker
35834 GooseFSJobMaster
35883 GooseFSJobWorker
35885 GooseFSProxy
```

然后就可以使用 `goosefs` 命令行，执行 namespace、fileSystem、job 以及 table 的各项操作了。例如，上传一个本地文件到 GooseFS 中，并且列出当前 GooseFS 中根目录下的文件和目录：

```bash
$ goosefs fs copyFromLocal test.txt /
Copied file:///Users/goosefs/test.txt to /

$ goosefs fs ls /
-rw-r--r--  goosefs         staff                        0       PERSISTED 04-28-2021 04:00:35:156 100% /test.txt

```

GooseFS 的命令行为用户提供了管理和访问 GooseFS 所有命令行接口，包括命名空间（namespace）、表（table）、作业（job）以及常用的文件系统（fs）操作等，具体可参考我们的官方文档或使用 `goosefs -h` 命令行参数获得详细帮助信息。

## 集群模式部署运行

集群部署运行主要针对用户自建 IDC 集群的生产环境或尚未集成 GooseFS 的腾讯云 EMR 生产环境，这里有具体分为 Standalone 架构部署与高可用（HA）架构部署。

GooseFS 在 `scripts` 目录下提供了批量配置 SSH 免密登录以及批量安装部署 GooseFS 的脚本工具，可供用户方便快捷地完成 GooseFS 大规模集群的安装部署。用户可自检前一章节的部署环境要求中的批量部署条件，灵活地选择是否可以执行批量部署。

### 批量部署工具介绍

GooseFS 在 `scripts` 目录下提供了批量配置 SSH 免密登录以及批量部署安装 GooseFS 的工具化脚本，用户在满足执行条件的前提下，可按照如下步骤完成批量部署任务：
- 进入GooseFS解压目录，`cd ${GOOSEFS_HOME}`。
- 配置 `conf/masters` 和 `conf/workers` 中的主机名或 IP 地址。
- 然后进入到 `scripts` 目录中，认真填写 `commons.sh` 这一脚本文件中的 `SCRIPT_EXEC_USER`和`SCRIPT_EXEC_PASSWORD`。再切换到 `root` 账户或使用 `sudo` 身份执行 `config_ssh.sh` 完成整个集群的免密登录配置。
- 免密配置完成后，可以执行 `validate_env.sh` 工具，校验整个集群配置状态。
- 创建配置文件目录软连接，`ln -s conf ~/.goosefs`。
- 最后执行 `goosefs copy .` 和 `goosefs copy ~/.goosefs` 将 goosefs 二进制包和配置文件分发到所有的节点。

在整个部署流程都成功完成以后，可以执行 `./bin/goosefs-start.sh all SudoMount` 来启动运行整个集群。默认配置下，所有的运行日志都会记录到 `${GOOSEFS_HOME}/logs` 下。

### Standalone 架构部署

Standalone 架构采用的是单 Master 节点，多 Worker 节点的集群部署架构。具体可参考如下步骤部署运行：

1. [下载 GooseFS 的二进制分发包](https://downloads.tencentgoosefs.cn/goosefs/1.4.2/release/goosefs-1.4.2-bin.tar.gz)。
2. 使用 `tar zxvf goosefs-x.x.x-bin.tar.gz` 命令解压到安装路径后。可参见批量部署工具的介绍配置和执行集群的批量部署，也可以继续参考下文详细地手动部署流程。

（1）从 `conf` 目录下拷贝 `template` 文件创建配置文件：
```bash
$ cp conf/goosefs-site.properties.template conf/goosefs-site.properties
```
（2）在 `goosefs-site.properties` 配置文件中指定如下配置：
```properties
goosefs.master.hostname=<MASTER_HOSTNAME>
goosefs.master.mount.table.root.ufs=<STORAGE_URI>
```
其中，`goosefs.master.hostname` 设置为单 master 节点的 hostname 或 ip。`goosefs.master.mount.table.root.ufs` 则指定 GooseFS 根目录所挂载的底层文件系统（UFS）路径URI。
>!这个 URI 必须保证 Master 和 Worker 节点都能访问到，因此不支持本地目录。

例如，您可以挂载一个 COS 路径为 GooseFS 根路径：`goosefs.master.mount.table.root.ufs=cosn://bucket-1250000000/goosefs/`。

在 `masters` 配置文件中指定单 Master 节点的 hostname 或 ip，例如：

```plaintext
# The multi-master Zookeeper HA mode requires that all the masters can access
# the same journal through a shared medium (e.g. HDFS or NFS).
# localhost
cvm1.compute-1.myqcloud.com
```

在 `workers` 配置文件中指定所有 Worker 节点的 host 或 ip，例如：

```plaintext
# An GooseFS Worker will be started on each of the machines listed below.
# localhost
cvm2.compute-2.myqcloud.com
cvm3.compute-3.myqcloud.com
```

待所有配置都设置完毕后，执行 `./bin/goosefs copyDir conf/` 就可以将配置同步到所有节点。

最后执行 `./bin/goosefs-start.sh all` 就可以启动 GooseFS 集群。


### 高可用架构部署

单 Master 节点的 Standalone 架构容易出现单点问题，因此，实际生产环境建议部署多 Master 节点来获得高可用的系统架构。多个 Master 节点中只有一个会作为主（Leader）节点对外提供服务，其他的备（Standby）节点通过同步共享日志（Journal）来保持与主节点相同的文件系统状态。当主节点故障宕机后，会从当前的备节点中自动选择一个接替主节点继续对外提供服务，这样就消除了系统的单点故障，实现了整体高可用架构。

目前 GooseFS 支持基于 Raft 日志和 Zookeeper 两种方式来实现主备节点状态的强一致性。下面将会针对这两种部署方式分别进行介绍。

#### 基于 Raft 嵌入式日志的高可用部署配置

首先依据配置模板创建配置文件：

```bash
$ cp conf/goosefs-site.properties.template conf/goosefs-site.properties
```

```properties
goosefs.master.mount.table.root.ufs=<STORAGE_URI>
goosefs.master.embedded.journal.addresses=<EMBBEDDED_JOURNAL_ADDRESS>
```

>?上述配置选项中，说明如下：
-  `goosefs.master.mount.table.root.ufs` 则设置为挂载到 GooseFS 根目录的底层存储 URI。
-  `goosefs.master.embedded.journal.addresses` 则设置为所有备节点的 `ip:embedded_journal_port` 或 `host:embedded_journal_port`。其中，embedded_journal_port 默认为9202。例如：192.168.1.1:9202,192.168.1.2:9202,192.168.1.3:9202。

基于 Raft 嵌入式日志的部署方案依赖于 [copycat](https://github.com/atomix/copycat) 的 Leader 选举机制。因此，Raft 的 HA 部署架构不可与 Zookeeper 相互混用。

在完成所有配置以后，同样使用如下命令同步所有配置：

```bash
$ ./bin/goosefs copyDir conf/
```

最后，完成格式化以后，即可启动 GooseFS 集群：

```bash
$ ./bin/goosefs format
```

```bash
$ ./bin/goosefs-start.sh all
```
如果提示权限不足，则尝试如下方式重启：
```bash
$ ./bin/goosefs-stop.sh all
$ ./bin/goosefs-start.sh all SudoMount
```

使用如下命令可查看当前的主（Leader）节点：

```bash
$ ./bin/goosefs fs leader
```

也可以使用如下命令查看集群状态：

```bash
$ ./bin/goosefs fsadmin report
```

#### 基于 Zookeeper 的共享日志部署配置

配置 Zookeeper 服务搭建 GooseFS 的高可用架构需要满足如下条件：
 - Zookeeper 集群，GooseFS Master 使用 Zookeeper 进行 Leader 选取，GooseFS 的客户端和 Worker 节点则通过 Zookeeper 查询主 Master 节点；
 - 高可用强一致的共享存储系统，并且保证所有 GooseFS 的 Master 节点均可以访问到。主 Master 节点会将日志写入到该存储系统上，备（Standby）节点则会不断地从共享存储系统上读取日志，并且重放来保持与主节点的状态一致性。一般情况，该共享存储系统，推荐设置为 HDFS 或 COS。例如，`hdfs://10.0.0.1:9000/goosefs/journal` 或 `cosn://bucket-1250000000/journal`。

配置如下：

```properties
goosefs.zookeeper.enabled=true
goosefs.zookeeper.address=<ZOOKEEPER_ADDRESSS>
goosefs.master.journal.type=UFS
goosefs.master.journal.folder=<JOURNAL_URI>
```

需要注意的是，ZK 模式的 `JOURNAL_URI` 必须是共享存储系统的 URI。然后使用 `./bin/goosefs copyDir conf/` 将配置同步分发到集群中的所有节点。最后启动集群  `./bin/goosefs-start.sh all` 即可。


## GooseFS 的进程列表

当执行 `goosefs-start.sh all` 脚本并启动 GooseFS 后，集群将包含如下进程：

| 进程             | 描述                                |
| ---------------- | ----------------------------------- |
| GooseFSMaster    | 默认 RPC 端口为9200，Web 端口为9201 |
| GooseFSWorker    | 默认 RPC 端口为9203，Web 端口为9204 |
| GooseFSJobMaster | 默认 RPC 端口为9205，Web 端口为9206 |
| GooseFSProxy     | 默认 Web 端口为9211                 |
| GooseFSJobWorker | 默认 RPC 端口为9208，Web 端口为9210 |

