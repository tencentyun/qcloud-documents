### 1. Word2Vec

* **算法说明**  
  Word2Vec (Word to Vector) 由谷歌Mikolov提出，通过将词映射至连续的向量空间，克服擦表达的稀疏性，进而有效地表达词汇，度量语义关系。TI-ONE平台提供了基于 Skip-gram 的词向量模型，编码好的词向量可用于其他NLP场景。

* **训练节点**
  - 数据形式
    - 数据形式：TextTrainData 
  - 算法IO参数
    - 训练集输入：训练数据输入路径，必须为ceph文件系统上的路径名。
    - 验证集输入：验证数据输入路径，每行数据为四个词，做类比推理验证，没有验证集可不填。必须为ceph文件系统上的路径名。
    - 模型输出：模型输出路径，也就是checkpoint路径，必须为ceph文件系统上的路径名，如/cephfs/person/rtx/word2vec/model
    - 可视化输出：可视化信息输出路径，即summary输出路径，必须为ceph文件系统上的路径名，如/cephfs/person/rtx/word2vec/summary
  - 算法参数
    - 词向量维度：指定最终词向量的维度
    - 梯度更新batch大小：每次梯度更新时用的batch大小，即一次训练输入多少个样本
    - 初始学习步长：初始学习步长，随着迭代的进行，会逐渐减小
    - 训练次数：训练数据的次数，在机器学习领域一般称之为epoch次数
    - 负采样个数：负采样的个数，为公式3中k的大小
    - 二次采样t：高频二次采样参数，为公式5中t的大小
    - 最小词频：词频低于该值得词表示为陌生词，过滤该类词，不将其加入语料库词典
    - 上下文窗口大小：Skip-gram提取样本时指定的上下文大小，即一个词与前后多少个词有关
    - 训练线程数：指定训练时的线程数
    - 可视化时间间隔(s)：每隔多少秒输出一次summary信息
    - 模型时间间隔(s)：每隔多少秒对模型做一次checkpoint
