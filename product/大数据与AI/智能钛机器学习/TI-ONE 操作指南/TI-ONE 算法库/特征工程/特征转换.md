## Dummy
模块将低维的特征做**特征交叉** ，并将特征转换成高维的 One-Hot 特征。Dummy 模块中包含两个阶段，**特征交叉**和**特征 One-Hot**。**特征交叉** 根据 json 配置文件，对指定的特征字段做交叉，生成 feature name 组成的特征；**特征 One-Hot** 将 feature name 编码成全局统一、连续的 index。

#### 输入
- 数据形式：Dense 或 libsvm
- 格式：| features |
- 说明：
 - 数据中的0和-1是两个特殊值，0表示默认值，-1表示非法值；读取数据过程中将会过滤掉这两个特殊值；因此特征的数值表示应该避开0和-1。
 - Dense 数据支持多值特征（该特征可以包含多个 value），每个 value 以“|”分割。例如，某特征是“喜欢的游戏”，该特征对应的值应该是多个游戏名，即游戏列表。
 - 必须包含 target 字段。训练数据的 target 字段是0或1的 label 值，预测数据的 target 字段是每条数据的标识 ID。
  
#### 输出
输出包含三个目录：featureCount、featureIndexs 和 instances。
- featureCount：Dummy 后的特征空间维度，一个 Int 值。
- featureIndexs：feature name 到 feature index 的映射关系，中间用“:”分隔。
- instances：One-Hot 后的 Dummy 格式的样本数据。

#### 参数
- 并行数：训练数据的分区数、Spark 的并行数。
- 特征生成配置：特征交叉的配置文件有两个对象“fields”和“feature_cross”，"fields"对象保存着输入数据每个字段对应的 name 和 index；“feature_cross”对象是生成特征的配置，其中“id_features”是指生成单个特征，“comb_features”是指交叉的特征，dependencies 是指交叉的特征，用逗号分隔，可以指定多个。
- 说明：必须包含 target 字段。若某个特征是多值特征，"id_features"会生成多个特征，"comb_features"也会多次与其他的 dependencies 做交叉。
- 示例：以下为示例数据的配置和特征交叉阶段生成的中间结果。
```json
	{
  	"fields": [
  	  {
  	    "name": "target",
  	    "index": "0"
  	  },
  	  {
  	    "name": "f1",
  	    "index": "1"
  	  },
  	  {
   	    "name": "f2",
  	    "index": "2"
 	   },
 	   {
   	    "name": "f3",
  	    "index": "3"
 	   }
 	 ],
        "feature_cross": {
 	 "id_features": [
           {
            "name": "f1"
           },
           {
            "name": "f3"
           }
   	  ],
  	 "comb_features": [
          {
            "name": "f1_f2",
            "dependencies": "f1,f2"
          },
          {
            "name": "f2_f3",
            "dependencies": "f2,f3"
          }
        ]
     }
  }
```
- featureIndex：指定了特征 One-Hot 时，使用的 feature name 到 index 之间的映射。该参数为选填，当需要基于上次特征 Dummy 的结果做增量更新或者预测数据的 Dummy 时，需要指定该参数，以保证两次 Dummy 的 index 一致。
- 负样本抽样率：大部分应用场景中，负样本比例太大，可通过该参数对负样本采样。


## PCA
主成分分析（Principal Component Analysis，PCA）是一种统计学的特征降维方法，将数据从原来的坐标系投影到新的坐标系，通过每个维度的方差大小来衡量该维度的重要性。从中选取重要性排在前 K 个的特征作为新的特征，达到数据降维的目的。

[算法示例 >>](https://tio.cloud.tencent.com/ml/platform.html?projectId=33&flowId=133)

#### 输入
- 数据形式：Dense 或 Libsvm
- 格式：| 参与计算的 features | 不参与计算的 features | 
- 参与计算的 features：可通过**选择特征列**指定。
- 不参与计算的 features：可包括不参与计算的特征，如果存在则保留在输出中，对于 Libsvm 格式的数据，也包括了 label 列，该 label 仅用于标识样本 ID。

#### 输出
- 格式：| 不参与计算的 features | PCA 结果列 |
- PCA 结果列：选取的前 K 个新特征。

#### 参数
- 选择特征列：表示需要计算的特征所在列，例如“1-12,15”，表示取特征在表中的1到12列，15列，从0开始计数。
- 提取主成份维度：降维后的特征维度。
- 并行数：训练数据的分区数、Spark 的并行数。
- 抽样率：输入数据的采样率。

## Normalizer
该模块提供了特征正则化，将各维特征正则化成[0, 1]阈值，可以避免不同特征值的分布域不一致而影响算法的决策。该算法的计算过程：首先计算每行所选特征的 p 阶范数，然后将该行所选的每个特征值与该范数相除的结果作为最终的正则化结果。当某行特征的 p 阶范数为0.0时，该行特征的正则化结果为该行特征的原始值。

[算法示例 >>](https://tio.cloud.tencent.com/ml/platform.html?projectId=33&flowId=133)

#### 输入
- 数据形式：Dense 或 Libsvm
- 格式：| 参与计算的 features | 不参与计算的 features | 
- 参与计算的 features：可通过**选择特征列**指定。
- 不参与计算的 features：可包括不参与计算的特征，如果存在则保留在输出中，对于 Libsvm 格式的数据，也包括了 label 列，该 label 仅用于标识样本 ID。

#### 输出
- 格式：| 不参与计算的 features | 正则化的结果 |
- 正则化的结果：被选取的特征的正则化结果。


#### 参数
- 选择特征列：表示需要计算的特征所在列，例如“1-12,15”，表示取特征在表中的1到12列，15列，从0开始计数。
- p： p-norm 参数，默认为 2，表示用 L2-Norm 做正则化。
- 并行数：训练数据的分区数、Spark 的并行数。
- 抽样率：输入数据的采样率。
  
## SVD
SVD（Singular Value Decomposition)奇异值分解法是一种对矩阵的分解方法。通常，对于大型稀疏矩阵，我们往往采用矩阵分解技术将矩阵表示成新的易于处理的形式，从而简化计算。一个矩阵A可以通过SVD算法分解为：S、V 和 U 三个矩阵。其中，S 为奇异值矩阵，V 为右奇异向量(V^T不是右奇异向量)，U 为左奇异向量。

[算法示例 >>](https://tio.cloud.tencent.com/ml/platform.html?projectId=33&flowId=133)

#### 输入
- 数据形式：Dense 或 Libsvm
- 格式：| label | 参与计算的 features | 不参与计算的 features | 
- label：每行矩阵的行索引，通过**算法参数**中的**矩阵行索引**指定。
- 参与计算的 features：与行索引对应的矩阵中的行向量，可通过**算法参数**的**特征起始列**和**特征终止列**指定。
- 不参与计算的 features：对于 Dense 形式的数据可包括不参与计算的特征。

#### 输出
- outputS：奇异值矩阵 <img src="https://main.qcloudimg.com/raw/8c6cfd3087e20ec9227fcc7e738de42f.png" style="margin:0;">
  - 格式：|S1 S2 ...|  
  - 说明：奇异值（如 S1、S2 等），以降序排列组成的行向量，以空格连接。
- outputV：右奇异向量 V
  - 格式：| index | vector |
  - 说明：以空格连接各字段。
  - index：对应输入数据的行索引。
  - vector：右奇异向量 V 矩阵。
- outputU：左奇异向量 U
  - 格式：| index | vector |
  - 说明：以空格连接各字段。
  - index：对应输入数据的行索引。
  - vector：左奇异向量 U 矩阵。

#### 参数
- 矩阵行索引：矩阵行索引所在的列号，默认为0，libsvm 数据填0。
- 特征起始列：待分解矩阵的第一列所在的列号，从0开始计数。
- 特征终止列：待分解矩阵的最后一列所在的列号，从0开始计数。
- 并行数：训练数据的分区数、Spark 的并行数。
- 抽样率：输入数据的采样率。
- k：奇异值的个数。
- rCond：条件数倒数。

## Scaler
Scaler 模块集成了最大最小值归一化（MinMaxScaler）和标准化（StandardScaler）两种方式，用户可通过特征配置文件来指定某个特征的归一化方法。

**MinMaxScaler 算法**对特征数据进行统一的归一化处理，默认归一化后的特征数值范围在[0,1]，用户也可以指定归一化后的取值范围为[min,max]。
该归一化的计算公式为：((x-EMin) / (EMax-EMin)) * (max-min) + min
其中，x 表示需要归一化的特征值，EMin 表示该特征下的最小值，EMax 表示该特征下的最大值，min 与 max 为用户设定的归一化后的数值范围。**当某列特征的最大最小值相等时，该列所有数值归一化为 0.5 \* (max - min) + min**。

**StandardScaler 算法**主要对特征进行标准化处理，原始特征数据通过该算法的转化将成为方差为1，均值为0的新的特征。
该标准化的计算公式为：(x - Mean) / Var
其中，Mean 代表该特征的平均值，Var 表示该特征的样本标准差。
>!
- 如果 Var 为0，则 x 标准化后的结果直接为0.0
- 不需要均值化处理：此时算法只做方差处理，即：x/Var
- 不需要方差处理：x 直接取值(x - Mean)

[算法示例 >>](https://tio.cloud.tencent.com/ml/platform.html?projectId=33&flowId=133)

#### 输入
- 数据形式：Dense
- 格式：| 参与计算的 features | 不参与计算的 features | 
- 参与计算的 features：通过**特征配置文件**指定。
- 不参与计算的 features：可包括不参与计算的特征，如果存在则保留在输出中。

#### 输出
- 格式：与输入数据格式一致。
- 说明：特征排列顺序与输入数据的一致，根据特征配置对数据进行归一化或标准化处理，没有配置的特征值保持不变。

#### 参数
- 并行数：训练数据的分区数、Spark 的并行数。
- 抽样率：输入数据的采样率。
- 特征配置文件名：从 TI-ONE 页面上传配置文件。

示例：以下是一个该模块的 JSON 格式的特征配置文件样例。
```json
{
    "minmax":[
      {
        "colStr": "1-2",
        "min": "0",
		"max":"1"
      },
      {
		"colStr":"5",
        "min":"-1",
        "max": "1"
       }
       ],
		"standard":[
       {
        "colStr": "3,6-7",
        "std": "true",
		"mean":"false"
       },
       {
        "colStr": "8,9",
		"std":"true",
		"mean":"true"
       }
       ]
}
```

#### 特征配置文件参数
- "minmax"和"standard"：分别代表了相应的归一化模块 MinMaxScaler 和 StandardScaler。
- "colStr"：需要做相应处理的特征 ID，取值根据该特征在原始表的所在列，从0开始计数。多个特征可用","隔开，还可用"-"标识特征的起始到结束列，例如"1-20"表示第1列到第20列。
- "min"：归一化后的最小值。
- "max"：归一化后的最大值。
- "std"：是否需要做方差的标准化。
- "mean"：是否需要做均值的标准化。

## Discrete
Discrete 算法用于对特征数据进行离散化处理。离散方法包括等频和等值离散方式，等频离散法按照特征值从小到大的顺序将特征值划分到对应的桶中，每个桶中容纳的元素个数是相同的；等值离散法根据特征值中的最小值和最大值确定每个桶的划分边界，从而保证每个桶的划分宽度在数值上相等。

[算法示例 >>](https://tio.cloud.tencent.com/ml/platform.html?projectId=33&flowId=133)

#### 输入
- 数据形式：Dense
- 格式：| 参与计算的 features | 不参与计算的 features | 
- 参与计算的 features：可通过**特征配置文件**指定。
- 不参与计算的 features：可包括不参与计算的特征，如果存在则保留在输出中。

#### 输出
- 离散化结果：
  - 格式：与输入数据格式一致。
  - 说明：特征的排列顺序与输入数据一致，根据特征配置对数据进行离散化处理的结果，没有配置的特征值保持不变。

- 离散特征边界：每个特征进行离散化时使用的边界值
  - 格式：| index | bound1 bound2 bound3 ...|
  - 说明：以空格连接各字段。
  - index：离散化的特征 ID，从0开始计数。
  - boundx：每个特征对应的离散边界值，各边界值以空格连接。

#### 参数
- 并行数：训练数据的分区数、Spark 的并行数。
- 抽样率：输入数据的采样率。
- 特征配置文件名：从 TI-ONE 页面上传配置文件。
 
示例：以下是一个该模块的 JSON 格式的特征配置文件示例，特征配置之间的顺序没有要求，如果某些特征不需要离散配置，则不写在配置中。该配置文件中的"feature"不可更改，用户只需对如下参数进行修改即可。
```json
{
    "feature": [
      {
        "id": "2",
        "discreteType": "equFre",
        "numBin": "3"
      },
      {
		"id": "5",
        "discreteType": "equVal",
        "numBin": "3",
		"min": "0",
		"max": "100"
       },
       {
        "id": "0",
        "discreteType": "equVal",
        "numBin": "2",
		"min":"-1"
      }
    ]
}
```

#### 特征配置文件参数
- "id"：表示特征 ID，该 ID 是输入数据中特征所在的列号，从0开始计数。
- "discreteType"：离散化的类型，"equFre"表示等频离散，"equVal"表示等值离散。
- "numBin"：离散化的桶数，在等频离散方法中，如果桶数设置过大，每个桶中的元素个数过少，导致离散边界中有重复的点，则出错。
- "min"：针对等值离散的配置，限定了特征值的最小值，如果特征值中有比这个值还小的则出错。如果没有需要可不填，同下面的"max"。
- "max"：针对等值离散的配置，限定了特征值的最大值，如果特征值中有比这个值还大的则出错，没有需要可不填。


## TransformByGBDT
TransformByGBDT 算法是基于 TI-ONE 平台 XGBoost-On-Spark 组件的训练、预测结果进行特征转换的算法。TransformByGBDT 算法的特征转换过程为：首先判断每个样本属于 GBDT 集成模型中每棵树的某个叶子节点，然后根据这一情况利用 GBDT 模型的所有叶子节点组合成该样本对应的特征。算法的特征最后以 onehot 的格式输出，其中1代表样本落入该叶子节点，0代表未落入该叶子节点。
>!
- 如果 XGBoost 模型(用 **modelIn** 表示，同下文)存在，则无需训练过程，直接采用该模型预测样本，并根据结果进行特征转换，该模型必须是经过 xgboost-on-spark 训练的模型。
- 如果 XGBoost 模型不存在，则需要先训练模型，再根据该模型去预测。其中训练后的模型保存路径为 **modelOut**，同下文
- Spark 版本选择：tdw3.10
- spark-conf 中 需要填如下信息：
spark.hadoop.hadoop.job.ugi=用户名:密码,资源组
spark.executorEnv.LD_LIBRARY_PATH=/data/gaiaadmin/gaiaenv/tdwgaia/lib/native:$LD_LIBRARY_PATH
spark.yarn.appMasterEnv.LD_LIBRARY_PATH=/data/gaiaadmin/gaiaenv/tdwgaia/lib/native:$LD_LIBRARY_PATH

[算法示例 >>](https://tio.cloud.tencent.com/ml/platform.html?projectId=29&flowId=91)

#### 输入
- 数据：
  - 数据形式：Dense 或 Libsvm
  - 格式：| label | 参与计算的 features | 不参与计算的 features |
  - label：Double 类型，通过**算法参数**中的 **label 所在列**指定。
  - 参与计算的 features：可通过**算法参数**的**选择特征列**指定。
  - 不参与计算的 features：可包括不参与计算的特征。
- 已获得的 XGBoost 模型：已经获得经过 xgboost-on-spark 训练的模型。
  
#### 输出
- 模型：新训练的 XGBoost 模型。
- 转换结果：
  - 格式：|label| 不参与计算的features | 转换结果 |
  - 不参与计算的 features：表示未被选择的特征列，可通过**算法参数**的**是否保留未被选择的特征列**指定是否保留在结果中。	
```
     # 第1列为 label，第2列为未被选择的特征数据，后面三列为转换后的特征
     0.0 1 1 1 0
     1.0 2 1 0 1
     1.0 3 1 1 0
   1.0 4 1 0 1
   0.0 5 1 1 0
   0.0 6 1 1 0
   1.0 7 1 0 1
   1.0 8 1 1 0
   0.0 9 1 0 1
   0.0 10 1 0 1
```

#### 参数
- 特征所在列：例如“1-10,12,15”，其说明取特征在表中的第1到第10列，第12列以及第15列，从0开始计数。
- label 所在列：从0开始计数，libsvm 数据填0。
- 并行数：训练数据的分区数、Spark 的并行数。
- 抽样率：输入数据的采样率。
- 是否保留未被选择的特征列：默认为 false，不保留。
- 迭代轮数：numRound
- 收缩步长：eta
- 树的最大深度：max_depth
- 目标函数：同 XGBoost 的目标函数，如 reg:linear” 表示线性回归；“reg:logistic” 表示逻辑回归。
- worker 数量：表示 xgboost 的并发度，worker 数量 <=（spark 的 executor个数）\*（每个 executor 上的 core 数）
- XGBoost 配置文件：XGBoost 其他参数的配置，在 TI-ONE 页面，脚本类型选择"纯文本"，以下是配置文件格式示例：
```
subsample=0.6
colsample_bytree=0.9
```

## RandomizedSVD
RandomizedSVD 算法是根据论文[《Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions》](https://arxiv.org/pdf/0909.4061.pdf)原理以及 Spark 平台实现的矩阵 SVD 分解算法。与 TI-ONE 平台提供的另外一个矩阵分解 SVD 算法在原理上有所不同，详情请参考论文，此处不再详述。

[算法示例 >>](https://tio.cloud.tencent.com/ml/platform.html?projectId=29&flowId=91)

#### 输入
- 数据形式：Dense 或 Libsvm
- 格式：| label | 参与计算的features | 不参与计算的features | 
- label：每行矩阵的行索引，通过**算法参数**中的**标签列**指定。
- 参与计算的 features：与行索引对应的矩阵中的行向量，可通过**算法参数**的**选择特征列**指定。
- 不参与计算的 features：对于 Dense 形式的数据可包括不参与计算的特征。

#### 输出
- outputS：奇异值矩阵 sigma
  - 格式：|S1 S2 ...|  
  - 说明：奇异值（如 S1、S2 等），以降序排列组成的行向量，以空格连接。 	
- outputV：右奇异向量 V
  - 格式：| index | vector |
  - 说明：以空格连接各字段。
  - index：对应输入数据的行索引。
  - vector：右奇异向量 V 矩阵。
- outputU：左奇异向量 U
  - 格式：| index | vector |
  - 说明：以空格连接各字段。
  - index：对应输入数据的行索引。
  - vector：左奇异向量 U 矩阵。

#### 参数
- 标签列：label 所在列，从0开始计数，默认为0，libsvm 数据填0。
- 选择特征列：例如“1-12,15”，其说明取特征在表中的1到12列，15列，从0开始计数。
- 并行数：训练数据的分区数、Spark 的并行数。
- 抽样率：输入数据的采样率。
- 矩阵乘积的迭代类型：分为两种："QR"与"none"，"QR"方式表示每轮迭代都需要进行 QR 分解，"none"方式表示每轮迭代仅进行左乘矩阵 A 以及 A 的转置，中间无"QR"分解过程。
- k：SVD 分解的奇异值个数。
- 过采样参数 q：randomized SVD 的过采样个数。
- 迭代轮数：矩阵乘积的迭代轮数。
- rCond：条件数倒数。


