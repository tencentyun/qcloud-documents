训练好的模型可以作为一个服务对外部署，使模型快速投入使用。

## 利用无服务器函数部署

### 准备模型

这里我们依然采用 MNIST 的例子，来部署一个可以判断图片上数字的服务。部署无服务函数需要我们把运行环境都准备好。这里，我们提供一份包含已经训练好的模型的代码包 `mnist_demo.zip`。

> **说明：** 
> 本文档以及使用样例基于 [使用 Serverless 进行 AI 预测推理](https://cloud.tencent.com/developer/article/1083516) 修改。
>  用户利用 `tictl` 完成模型部署后，可以登入腾讯云控台，在  [SCF 函数](https://cloud.tencent.com/document/product/583/18263) 中进行更多操作。

代码包内的文件结构如下：

```bash
mnist_demo
|
|-- mnist.py
|-- utils.py
| export
    | 4
        |-- saved_model.pb
        | variables
            |-- variables.data-00000-of-00001
            |-- variables.index
| PIL
    |-- ...
```

其中，export 路径下为导出好的模型，而 PIL 是我们需要使用的依赖包。另外，[mnist.py](#代码一：mnist.py) 是程序执行的入口，而 [utils.py](#代码二：utils.py) 则包含需要用到的一些函数。

请使用 `coscmd` 来下载我们准备好的程序包：

```bash
coscmd -r ap-shanghai -b tia-demo-1255502019 download scf/mnist_demo.zip scf/mnist_demo.zip
```

下载完成后，将准备好的模型再上传到自己的 COS：

```bash
coscmd upload mnist_demo.zip mnist_demo.zip
```



### 部署模型

新建模型：
```bash
tictl model create mnist-scf \
--model "cos://scf-1256926628.cos.ap-guangzhou.myqcloud.com/mnist_demo.zip" \
--description "A service telling you the number in the given image." \
--runtime Python2.7 \
--region ap-beijing \
--serverless \
--conf Handler=mnist.apigw_interface \
--conf MemorySize=1024 \
--conf Timeout=10
```

返回结果：
```
The model is created successfully.
NAME         CREATED                              STATE
mnist-scf    Wednesday, 22-Aug-18 11:47:21 CST    READY
```

> **注意：**
> 初次上传代码压缩文件，生效时间可能有延迟。如果创建失败，可以等待一段时间后再试。如果仍有问题，请联系我们。

参数说明：

- --model：模型所在 package 的存储路径。
- --description：对模型的描述性文字，最大支持 1000 个英文字母、数字、空格、逗号、换行符和英文句号，支持中文。
- --runtime：模型运行环境标签，默认 Python2.7。
- --region：模型服务所部署的地域，会根据用户首次登录有一个默认值。可选：`ap-shanghai`, `ap-beijing`, `ap-guangzhou`, `ap-chengdu`。若需要使用 **TensorFlow** 作为运行环境，则请选 `ap-shanghai`, `ap-beijing`，别的区域暂不支持。
- --serverless：表示选择采用无服务器函数的方式来部署模型。
- --conf：可选的额外针对无服务器函数的配置：
  - Handler：函数的入口脚本名及方法名。
  - MemorySize：指定函数运行环境所分配的内存大小。
  - Timeout：指定函数运行所允许等待的时间，若到此时间没有运行结束，则直接返回任务失败。


### 查看和删除模型

#### 列出模型

> **注意：**
> 如果部署的模型在默认的地域下，可以不用添加形如 `--region=ap-beijing` 的参数。

列出所有已部署的无服务器模型服务：

```bash
tictl model list --serverless --region ap-beijing
```

返回结果：

```
NAME             CREATED                RUNTIME  
scf              2018-08-21 22:13:45    Python2.7
mnist-scf        2018-08-22 11:47:21    Python2.7
```

#### 获取模型详细信息

获取名为 *mnist-scf* 模型服务的信息：

```bash
tictl model describe mnist-scf --serverless --region ap-beijing
```

返回结果：

```
NAME         CREATED                STATE    MESSAGE    DESRIPTION
mnist-scf    2018-08-22 11:47:21    Ready           	MNIST service ...
```

字段说明：

- CREATED：无服务器函数服务部署，或者最近被更新的时间。
- STATE：当前部署状态。
- MESSAGE：函数状态的更多描述，健康时为空。
- DESCRIPTION：提交模型部署时所添加的描述性文字。

#### 删除模型

删除名为 *scf* 的模型服务：

```
tictl model delete scf --serverless --region ap-beijing
```

>**注意：**
>目前请不要使用 `tictl` 来删除控制台中的函数，也不要在控制台中删除 `tictl` 创建的函数，否则会造成一些错误。

返回结果：

```
The model scf is deleted successfully.
```



### 测试模型

在腾讯云控制台，打开 **无服务器函数**，找到名为 **mnist-scf** 的该函数。点开函数后，单击 **测试**。使用下面内容来测试函数：

```json
{
  "requestContext": {
    "serviceName": "testsvc",
    "path": "/test/{path}",
    "httpMethod": "POST",
    "requestId": "c6af9ac6-7b61-11e6-9a41-93e8deadbeef",
    "identity": {
      "secretId": "abdcdxxxxxxxsdfs"
    },
    "sourceIp": "10.0.2.14",
    "stage": "prod"
  },
  "headers": {
    "Accept-Language": "en-US,en,cn",
    "Accept": "text/html,application/xml,application/json",
    "Host": "service-3ei3tii4-251000691.ap-guangzhou.apigateway.myqloud.com",
    "User-Agent": "User Agent String"
  },
  "body": "{\"image_base64\": \"\", \"image_url\": \"https://main.qcloudimg.com/raw/84783c178cdc6d6b2302bc1b4749b91b.bmp\"}",
  "pathParameters": {
    "path": "value"
  },
  "queryStringParameters": {
    "foo": "bar"
  },
  "headerParameters":{
    "Refer": "10.0.2.14"
  },
  "stageVariables": {
    "stage": "test"
  },
  "path": "/test/value?foo=bar",
  "httpMethod": "POST"
}
```

这里模仿了一个 HTTP 请求，其中数据位于 body 字段中：

```json
{
  "image_base64": "",
  "image_url": "https://main.qcloudimg.com/raw/84783c178cdc6d6b2302bc1b4749b91b.bmp"
}
```

运行成功后，可以看到，结果为：

```json
{"result": 0}
```


### 利用 API 网关开放接口

接下来我们通过 API 网关服务，来创建一个 API 对刚刚创建的推理函数进行封装，并对外提供 API 服务。

#### 创建 API 服务及 API

首先在 API 网关的控制台，在广州区创建一个 API 服务。服务名可以起一个容易记住的名字，例如 mnist。

接着进入API 管理，创建 API。同样可以起一个容易记住的名字，例如 number。请求路径可以写为 /predict，请求方法为 POST。为了方便调试，我们这里可以勾选上免鉴权。

接着下一步，后端类型选择为 *cloud function*，并选择我们在前面创建的函数 *mnist-scf*。注意，建立 API 网关的地域需要和 SCF 所在的地域一致。

最后一步填入响应内容为 JSON，描述正确示例为 `{"result":0}`，错误示例为 `{"errMsg":"error info"}` 即可。

#### 调试 API

单击 API 查看界面的 API 调试，进入调试页面。确定 Content-Type 为 application/json，输入框内填入以下内容后单击发送请求。

```js
{
  "image_base64": "",
  "image_url": "https://main.qcloudimg.com/raw/84783c178cdc6d6b2302bc1b4749b91b.bmp"
}
```

确认响应的 body 为 `{"result": 0}`，符合预期。同理，这里的 URL 地址同样可以更改，并且响应内容随图片的不同而不同。

#### API 发布及外网测试

在 API 调试成功后，我们可以在服务列表页面，将我们刚刚创建的 mnist 服务发布到 `发布环境`。

然后根据 mnist 的服务域名，我们可以得到刚才的 API 的完整路径为：`http://service-kzeyrb6x-1253970226.ap-beijing.apigateway.myqcloud.com/release/mnist`。我们可以使用 HTTP request 的发起工具，例如 Postman，或 restclient 等，向此 API 地址发起 POST请求，POST 内容可以为如下内容。

```js
{
  "image_base64": "",
  "image_url": "https://main.qcloudimg.com/raw/84783c178cdc6d6b2302bc1b4749b91b.bmp"
}
```

或

```js
{
  "image_base64": "Qk1mCQAAAAAAADYAAAAoAAAAHAAAABwAAAABABgAAAAAADAJAAAAAAAAAAAAAAAAAAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////AAAA////////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////AAAAAAAA////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////",
  "image_url": ""
}
```

这两个不同的数据结构，分别测试了使用 base64 编码的图片内容，或者使用图片 URL 地址传递图片内容的方式。同时可以根据自身需求，修改数据结构内的 image_base64 或 image_url 内容，查看测试结果。


## 在集群上部署

### 部署服务

*MNIST For ML Beginner* 示例中，训练后存储在 COS 的模型可以作为服务直接部署：

```bash
$ tictl model create mnist-model \
  --description=mnist-model \
  --model="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/mnist_example:/data/mnist" \
  --servtype=2U4G1P

create model success.
NAME           CREATED                          URL    STATE    MESSAGE
mnist-model    2018-05-04 13:49:52 +0800 CST                    creating
```

查看模型服务部署状态：

```bash
$ tictl model list
NAME           CREATED                          URL                STATE      MESSAGE
mnist-model    2018-05-04 13:49:52 +0800 CST    193.112.231.182    Running    Deployment has minimum availability.
```

从 URL 字段我们看到服务对外暴露的 IP，同时暴露的还有 80(HTTP) 和 9000(RPC) 端口。

### 测试服务是否部署成功

这里我们使用例子中的测试脚本测试服务（目前还在 beta 阶段，如果环境准备有困难，请跳过此部分）：

#### 环境准备

- [安装 TensorFlow](https://tensorflow.google.cn/install/)

- 安装 Serving API：

```bash
$ pip install tensorflow-serving-api
```

#### 查看测试结果

>**注意：**
>这里需要将 mnist_client.py 文件中的 model 名称改为之前创建的模型名，此处为 mnist-model。

```bash
$ python mnist_client.py --num_tests=100 --server=193.112.231.182:9000
...
Inference error rate: 7.0%
```


### 附录
<span id="代码一：mnist.py"></span>
    
#### 代码一：mnist.py

```python
#!/usr/bin/env python2.7

import os
import sys
import base64
import urllib
import tensorflow as tf
import numpy as np
import utils
import json

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Load model
cur_dir = os.getcwd()
model_dir = cur_dir+"/export/4"
sess = tf.Session(graph=tf.Graph())
meta_graph_def = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], model_dir)
x = sess.graph.get_tensor_by_name('x:0')
y = sess.graph.get_tensor_by_name('y:0')

def run(event):
    local_path = ""
    if event['image_base64'] != "":
        data=base64.b64decode(event['image_base64'])
        local_path = '/tmp/test_image.xxx'
        file=open(local_path,'wb')
        file.write(data)
        file.close()
    elif event['image_url'] != "":
        img_url = event['image_url']
        filename = urllib.unquote(img_url).decode('utf8').split('/')[-1]
        local_path = os.path.join('/tmp/', filename)
        if not utils.download_image(event['image_url'], local_path):
            return False, -1
    else:
        print('Please specify a image.')

    try:
        x_ = utils.get_image_array(local_path)
        predict = tf.argmax(y, 1)
        res = sess.run(predict, feed_dict={x: x_})[0] 
        return True, sess.run(predict, feed_dict={x: x_})[0]
    except Exception as e:
        print(e)
        return False, -1

def demo(event, context):
    res, num = run(event)
    print num
    return num
        
def apigw_interface(event, context):
    if 'requestContext' not in event.keys():
        return {"errMsg":"request not from api gw"}
    body_str = event['body']
    body_info = json.loads(body_str)
    res, num = run(body_info)
    return {"result":num}
```

返回 [准备模型 >>](#准备模型)

<span id="代码二：utils.py"></span>
    
#### 代码二：utils.py

```python
#!/usr/bin/env python2.7

import urllib2
import numpy as np
from PIL import Image

def download_image(img_url, local_file):
    ret = True
    try: 
      f = urllib2.urlopen(img_url)
      data = f.read()
      with open(local_file, "wb") as img:
          img.write(data)
    except Exception as e:
        print(e)
        ret = False
    return ret

def get_image_array(img_path):
    x_s = 28
    y_s = 28
    n0 = 0
    n255 = 0
    threshold = 100
    im = None
    im = Image.open(img_path)

    img = np.array(im.resize((x_s, y_s), Image.ANTIALIAS).convert('L'))

    for x in range(x_s):
      for y in range(y_s):
        if img[x][y] > threshold:
          n255 = n255 + 1
        else:
          n0 = n0 + 1

    if(n255 > n0) :
      for x in range(x_s):
        for y in range(y_s):
          img[x][y] = 255 - img[x][y]
          if(img[x][y] < threshold) :
            img[x][y] = 0

    arr = img.reshape((1, 784))
    arr = arr.astype(np.float32)
    arr = np.multiply(arr, 1.0 / 255.0)
    return arr
```

返回 [准备模型>>](#准备模型)
