
## Word2Vec

**算法说明**
Word2Vec 是一种经典的词向量算法，能够从大量文本中学习出各个词语的向量表示。这一向量表示可以用作其它深度学习模型的初始值 [参考文档](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)。

**输入参数**
- 训练数据：文本文件，词语之间使用空格分隔。
- 验证数据：（可选）包含四元组的数据集，如 word2vec 官方 questions-words.txt，用于评价生成的词向量的质量。

**输出参数**
保存路径：生成的词向量文件的保存路径。生成的文件为文本文件，每行为一个词语及其向量表示，词语和向量之间，向量中的各个数字之间使用空格分隔。

**算法参数**
- 词向量维度：要训练的词向量维度。
- 窗口大小：skip-gram 算法中的 window_size 参数。
- 最小出现次数：只训练出现次数大于这一次数的词语的词向量。
- 训练 epoch 数：训练数据的训练次数。
- 学习率：即 learning_rate 参数。
- 批处理大小：即训练的 batch_size。
- 负采样个数：skip-gram 算法中的负样本个数。

**实例生成**
1. 使用数据节点上传数据，数据格式请参见【输入参数】部分。
2. 将数据节点连接到 word2vec 节点，配置好保存路径，单击【运行】开始训练。
