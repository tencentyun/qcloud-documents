### 1. Linear Regression

* **算法说明**

  线性回归算法是逻辑回归的原型，常用于预测连续的目标值。该算法具有模型简单、可解释性强等优点。

- [**样例**](https://tio.cloud.tencent.com/ml/platform.html?projectId=33&flowId=139)

* **训练节点**
  - 输入 
    - 数据形式：Dense 或 Libsvm
    - 格式：| label | 参与计算的features | 不参与计算的features| 
    - label：Double类型，通过**算法参数**中的**数据标签列**指定
    - 参与计算的features：可通过**算法参数**的**选择特征列**指定
    - 不参与计算的features：可包括不参与计算的特征
  - 输出 
    - PMML格式的Linear Regression model
    - 模型格式：| 特征权重 | 偏置项 |
  - 算法参数：
    - 数据标签列：数据标签(label)所在列，从0开始计数
    - 选择特征列：从0开始计数，以类似“1-12，15”的方式选择特征，表示取特征在表中的1到12列，15列
    - 并行数：训练数据的分区数、spark的并行数
    - 抽样率：输入数据的采样率 
    - 正则化系数：默认为0，表示不添加正则项
    - elasticNet：范围：0~1.0，0表示L2正则，1表示L1正则，0~1.0表示L1和L2正则的结合
    - 最大迭代次数：默认为100

* **预测节点**
  - 输入
    - 数据形式：Dense 或 Libsvm
    - 格式：| 参与计算的features | 不参与计算的features |
    - 参与计算的features：同训练节点
    - 不参与计算的features：如果存在则保留在输出中，对于Libsvm格式的数据，也包括了label列，该label仅用于标识样本ID
  - 输出
    - 格式：| 不参与计算的features数据 | predict_value | 
    - predict_value：预测值
  	  

### 2. DecisionTree Regression

* **算法说明**

  决策树算法是机器学习中非常常用的一类分类/回归算法。决策树算法有很多优点，如：解释性好，可以处理类别特征，支持多分类，不需要做特征scaling，可以表示非线性模型。平台的决策树回归算法支持连续、非连续特征，最高可以支持百万级别的样本。

- [**样例**](https://tio.cloud.tencent.com/ml/platform.html?projectId=33&flowId=139)

* **训练节点**
  - 输入 
    - 数据形式：Dense 或 Libsvm
    - 格式：| label | 参与计算的features | 不参与计算的features | 
    - label：Double类型，通过**算法参数**中的**数据标签列**指定
    - 参与计算的features：可通过**算法参数**的**选择特征列**指定
    - 不参与计算的features：可包括不参与计算的特征
  - 输出 
    - PMML格式的DecisionTree model
    - 模型格式：| treeId | node |，决策树中的所有节点信息
    - treeId：树标号，都为0
    - node：树中的节点信息
  - 算法参数：
    - 数据标签列：数据标签(label)所在列，从0开始计数
    - 选择特征列：从0开始计数，以类似“1-12,15”的方式选择特征，表示取特征在表中的1到12列，15列
    - 并行数：训练数据的分区数、spark的并行数
    - 并行数：输入数据的分区数
    - 决策树最大深度： 训练决策树所允许的高度上限, 默认为10
    - 决策树最大分支数： 训练决策树所允许的最大分叉树, 默认为32

* **预测节点**
  - 输入
    - 数据形式：Dense 或 Libsvm
    - 格式：| 参与计算的features | 不参与计算的features |
    - 参与计算的features：同训练节点
    	 不参与计算的features：如果存在则保留在输出中，对于Libsvm格式的数据，也包括了label列，该label仅用于标识样本ID	
  - 输出
    - 格式：| 不参与计算的features数据 | predict_value | 
    - predict_value：预测值
  	  

### 3.  RandomForest Regression

* **算法说明**

  随机森林是决策树的一种ensemble算法，可用于分类和回归。平台的RandomForest分类算法支持连续、非连续特征。

- [**样例**](https://tio.cloud.tencent.com/ml/platform.html?projectId=33&flowId=139)

* **训练节点**
  - 输入 
    - 数据形式：Dense 或 Libsvm
    - 格式：| label | 参与计算的features | 不参与计算的features | 
    - label：Double类型，通过**算法参数**中的**数据标签列**指定
    - 参与计算的features：可通过**算法参数**的**选择特征列**指定
    - 不参与计算的features：可包括不参与计算的特征
  - 输出 
    - PMML格式的RandomForest model
    - 模型格式：| treeId | node |，所有组成森林的随机树
    - treeId：树的标号
    - node：树中的节点信息
  - 算法参数：
    - 数据标签列：数据标签(label)所在列，从0开始计数
    - 选择特征列：从0开始计数，以类似“1-12,15”的方式选择特征，表示取特征在表中的1到12列，15列
    - 并行数：训练数据的分区数、spark的并行数
    - 决策树棵树：模型使用的决策树的个数，默认为10
    - 决策树最大深度： 训练决策树所允许的高度上限, 默认为10
    - 决策树最大分支数： 训练决策树所允许的最大分叉树, 默认为32
    - 抽样率： 训练每课数使用的数据百分比，默认为1.0, 减少可以加快训练过程
    - 标签抽样策略：训练决策树选择标签的策略
    - auto：自动选择，当决策树棵树为1时选择all，否则选择sqrt
    - all：选择全部标签
    - sqrt：选择开根号个数的标签
    - log：选择取对数个数的标签

* **预测节点**
  - 输入
    - 数据形式：Dense 或 Libsvm
    - 格式：| 参与计算的features | 不参与计算的features |
    - 参与计算的features：同训练节点
    	 不参与计算的features：如果存在则保留在输出中，对于Libsvm格式的数据，也包括了label列，该label仅用于标识样本ID	
  - 输出
    - 格式：| 不参与计算的features数据 | predict_value | 
    - predict_value：所有树的预测值的平均值

