## 服务调用示例

模型服务列表页面显示了当前各个服务的运行状态、占用资源、调用地址以及其他信息。单击【模型调用】，可获得当前服务的访问地址和密钥。
![avatar](https://main.qcloudimg.com/raw/c996367198ed90aa94b22ac43517cc4e.png)

下文通过一个示例展示服务调用方式：

**模型文件：** tensorflow 框架训练的经典深度学习 inception 模型

**模型运行环境:**  tfserving 环境

**模型地址**： 

	‌ cos://data-122232422.cos.ap-bejing.myqcloud.com/tfserving/inception/155645133 

**资源配置：** 1CPU核2G内存

**扩缩容配置：** CPU利用率目标60%，内存利用率目标60%；最小实例数为1，最大实例数为5

**测试图片：**

![avatar](https://main.qcloudimg.com/raw/e6bcf91f8596a1da18f534e3dc6b2d95.png)

**本地测试：**

 模型默认暴露两个端口：80端口提供http服务，9000端口提供grpc服务。模型服务的预测访问路径默认为`/v1/models/m:predict`。本地使用curl或者其他rest测试工具进行测试，这里我们使用curl进行测试，将获取的token填写为`header: X-Auth-Token`。
![avatar](https://main.qcloudimg.com/raw/1b6f9b94c2764430e8929075fdf560bf.png)

上图例子中的 `image.encode `为训练生成的 inception 模型定义的 JSON 数据格式:
`{"instances":[{"b64": 图片 base64 编码}]}`。这里我们使用上面的测试图片进行编码。可以看出模型服务运行正常，正确的对发送的花朵进行了分类。
