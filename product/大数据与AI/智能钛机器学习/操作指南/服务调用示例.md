
模型服务列表页面显示了当前各个服务的运行状态、占用资源、调用地址以及其他信息。
![](https://main.qcloudimg.com/raw/dfe11a2e277db8e307bc3ffbe2d5470a.png)
单击【模型调用】，可获得当前服务的访问地址 IP 和密钥 Token。
![](https://main.qcloudimg.com/raw/02af42f7c9fca5fabf8e39f04661458c.jpg)
##  相关资料
本文通过示例展示服务调用方式：
请单击下载 [案例模型文件](http://ti-ems-1255502019.cosbj.myqcloud.com/tfserving/inception/1556451336.zip) 和 [测试图片文件](http://ti-ems-1255502019.cosbj.myqcloud.com/tfserving/inception/image.encode)。

## 准备内容
- **模型文件：** tensorflow 框架训练的经典深度学习 inception 模型。
- **模型运行环境：**tfserving 环境。
- **模型地址：**cos://ti-ems-1255502019.cos.ap-beijing.myqcloud.com/tfserving/inception/1556451336
>!上述模型 cos 地址可以直接访问，您也可以将模型文件上传到自己的 cos 存储桶中，并按照规定格式在【创建模型服务配置】页面输入模型地址。
- **资源配置：**1核CPU，2G 内存。
- **扩缩容配置：** CPU 利用率目标60%，内存利用率目标60%；最小实例数为1，最大实例数为5。
- **测试图片：**
![](https://main.qcloudimg.com/raw/dbb0911e259a608ff11f1481ca210bcc.jpg)

## 调用测试
模型默认暴露两个端口：80端口提供 HTTP 服务，9000端口提供 grpc 服务。模型服务的预测访问路径默认为`/v1/models/m:predict`。本地使用 curl 或者其他 rest 测试工具进行测试，这里我们使用 curl 进行测试，将获取的 token 填写为`header: X-Auth-Token`。我们将从页面获取访问地址（IP）和 Token 代入下述调用代码：
```
curl -H “Content-Type: application/json” \
-H "x-Auth-Token: TOKEN" \
-X POST IP/v1/models/m:predict -d "@image.encode"
```
上述例子中的 `image.encode 为训练生成的 inception 模型定义的 JSON 数据格式`：
`{"instances":[{"b64": 图片 base64 编码}]}`。这里我们使用上面的测试花朵图片进行编码。

**返回结果：**
模型服务运行正常，并且对发送的花朵正确分类。
```
{
    "predictions": [
        {
            "class_idx": 2,
            "probabilities": [0.00685295, 0.00298387, 0.965622, 0.0072101, 0.0173306],
            "classes": "roses"
        }
    ]
}
```
