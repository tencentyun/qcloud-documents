
用户能将模型保存至模型仓库，在模型仓库中，用户可进行模型部署，并将模型部署为 Restful API，还可进行离线批量预测、导入第三方模型等服务，下文将分别介绍：

**模型部署**
提供两种方式：【任务流页面快捷部署】、【将模型保存至模型仓库页面进行部署】

**任务流页面快捷部署**

1. 在任务流上方单击部署模型![](https://main.qcloudimg.com/raw/afb53af4b1d09d1b1a0a7cc4a393b824.png)图标。
2. 选择模型并保存至模型仓库。
3. 单击【下一步】进行部署设置（需要选择运行环境、以及模型资源配置）。
4. 单击【部署】按钮。

**将模型保存至模型仓库页面进行部署**
1. 右键单击【模型】组件，选择【保存】到模型仓库。
![](https://main.qcloudimg.com/raw/7f038ad3aa8b0b7dad2616520b08a869.png)
2. 输入模型名称
3. 页面将跳转至模型仓库页面，单击【部署】按钮
4. 进行部署设置（需要选择运行环境、以及模型资源配置）


**调用模型说明**
   单击模型服务名称可查看此服务的访问地址与密钥，服务密钥会在后台自动生成，您可单击复制图标进行复制。
   目前模型服务支持三种类型的模型部署：Angel、PMML、tfserving。
   公有云的服务部署后，可以在界面上测试，可也以通过 curl 在支撑环境进行调用。

- 调用 Angel/PMML 推理服务

   ```bash
   curl \
   -v \
   -H "Content-Type: application/json" \
   -H "Authorization: ${accessKey}" \
   -H "Host: ${hostUri}"  \
   -X POST \
   -d '${data}' \
    ${gatewayUri}/v1/models/m:predict
   ```

- 调用 tfserving 推理服务

   ```bash
   curl \
   -v \
   -H "Content-Type: application/json" \
   -H "Authorization: ${accessKey}" \
   -H "Host: ${hostUri}"  \
   -X POST \
   -d '${data}' \
    ${gatewayUri}/v1/models/m:predict
   ```

**变量说明：**

   目前只有腾讯云支撑环境可以访问。具体调用时，请替换调用服务中的变量：

   - accessKey：从模型服务界面获得的密钥，例如`a15fea3033ba4496d87cfa74bafdae8a1`。
   - hostUri：从模型服务界面获得的链接，例如`e1wBicDrTaWAQ4D3gRQFOA.ti-test.com`。
   - data：推理服务的输入数据，json 格式，例如`{"instances": [{"x1":6.2, "x2":2.2, "x3":1.1, "x4":1.2}]}`。
   - gatewayUri：请求转发所需的地址，目前配置固定为`100.98.32.37:31292`。

**参考文档**

   - [Angel 模型服务文档](https://github.com/Angel-ML/serving/blob/master/docs/serving_doc.md)
   - [TensorFlow 模型服务文档 ](https://www.tensorflow.org/tfx/serving/api_rest)


模型部署完成后，可在模型服务的操作列中，进行如下操作：
1. **测试**：页面内对服务进行小数量级的测试。支持的任务类型为图像分类、图像目标识别和机器学习。
 - 图像分类和图像目标识别的数据支持用户通过 COS 和本地上传。
 - 机器学习任务的数据支持的提交格式为 JSON（用户需要先在任务流界面右击组件选择导出模型并找到对应 txt 文件）。
2. **升级/回退**：用户可对实例进行部分/全量的版本升级与回退。
3. **负载均衡**：单击列表的流量数，分配此服务各个版本的流量百分比，新建的模型版本默认流量为0。
4. **监控**：用户可在界面上查看某一段时间的响应、请求、使用率等情况。
5. **删除**：在弹框中确认删除后模型将不再对外进行服务。

**离线批量预测**
1. 进入【模型仓库】页面，选择相应的模型单击【离线批量预测】。
![](https://main.qcloudimg.com/raw/1f3ea805b7b175940dc7903d615c3f17.png)


2. 在跳转的离线批量预测页面对**作业类型**、**调度周期**与**开始时间**进行设置。并对预处理环节进行编辑，如果删除预处理节点，请重新在组件间完成连线。
3. 成功开启作业后，您将进入批量预测作业列表页面，可以对所有作业进行查看和管理。
   作业的运行状态有三种：运行中、已完成、已失败。单击**运行中**，可以打开任务流视图，查看离线预测作业的运行详情。



**导入模型**
1. 进入【模型仓库】页面，单击右上角【导入模型】按钮。
2. 填写 COS 路径、模型名称、选择模型类型等信息。
3. 单击【确定】，导入模型。



