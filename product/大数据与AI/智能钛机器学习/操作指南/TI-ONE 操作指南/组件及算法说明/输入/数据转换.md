## 中文分词

分词，将中文句子划分成词语，词语之间用空格分隔。

#### **输入参数**

输入数据：未分词的中文文本，每行为一个句子。

#### **输出参数**

输出数据：分词后的中文文本，每行为一个句子，词与词之间用空格分隔。

#### 算法参数
标签分隔符：（可选）如行中有标签分隔符，则只对标签分隔符左侧的文本进行分词。
#### 实例生成	
1. 使用数据节点，上传数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到分词节点，配置好输出数据路径和标签分隔符，单击【运行】开始分词。

## 中文去停用词

去除文本中的停用词，文本需要预先分词。

#### **输入参数**

- 输入数据：分词后的中文文本，每行为一个句子，词语之间用空格分隔。
- 停用词表：要去除的停用词列表，每行为一个词。

#### **输出参数**

输出数据：去除停用词后的中文文本，每行为一个句子。

#### 算法参数
标签分隔符：（可选）如行中有标签分隔符，则只对标签分隔符左侧的文本进行去停用词。
#### 实例生成
1. 使用数据节点，上传输入数据和停用词表数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到去停用词节点，配置好输出数据路径和标签分隔符，单击【运行】开始去停用词。

## 句子转向量表示

句子转向量表示可以将句子转换为向量表示，转换方法有三种：
- 转换为词向量平均值。
- 转换为词向量加权平均值，权重由词频决定，词频越高，权重越低。
- 使用论文 [A simple but tough-to-beat baseline for sentence embeddings](https://openreview.net/pdf?id=SyK00v5xx) 的方法进行转换。

#### 输入参数
输入数据：文本文件，每一行为一个句子，词语之间使用空格分隔。

#### 输出参数
输出数据：文本文件，每一行为输入数据对应行的句子的向量表示，数字之间用空格分隔。

#### 算法参数
- 预训练词向量文本文件，格式请参考 word2vec 和 glove 算法的【输出参数】部分。
- 转换方式：三选一，average 对应词向量平均值；weighted_average 对应词向量加权平均值；svd 对应论文中的方法。

#### 实例生成
1. 使用数据节点上传数据，数据格式请参考【输入数据】部分。
2. 将数据节点连接到 sentence2vec 节点，配置好预训练词向量路径和转换方式，单击【运行】按钮开始训练。


## 文本数据切分

该模块将 NLP 任务的输入文件按一定比例切分成训练集和验证集两份文件。输入数据中每行为一个样本，用分隔符区分特征和标签，eg. spiderman rocks.\_\_label\_\_1，此时分隔符为'\_\_label\_\_'

#### **输入参数**

输入数据：要切分的文本文件，每行为一个句子。

#### **输出参数**

- 切分后文件1：切分后的第一份文件。
- 切分后文件2：切分后的第二份文件。

#### 算法参数
- 切分比：第一份文件所占的比例。
- 分隔符：分隔一行中句子和标签的分隔符，如果某些标签仅在两份切分后文件之一中出现，则日志中会有提示。

#### 实例生成
1. 使用数据节点，上传文本数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到文本数据切分节点，配置好输出数据路径，切分比和分隔符，单击【运行】开始。

## 图像切分转换

对图片分类或者目标检测的数据集进行切分，并转换成 tfrecord 格式，同时生成表示标签和类别索引对应关系 label_map 文件，供算法节点调用。

#### 算法 IO 参数
- 图像目录：对于图片分类任务，目录中需包含若干个子目录，子目录名字为类别名；对目标检测任务而言，该目录中需要包含所有图像。
- xml 文件目录：仅目标检测任务需要填写。存放 xml 文件的目录，xml需要为 pascal voc 格式，且为 utf-8 编码。
- 训练集输出：输出训练集的 tfrecord 文件的路径。
- 验证集输出：输出验证集的 tfrecord 文件的路径。
- label_map 文件输出路径：label_map 文件的输出路径。

#### 算法参数
- 任务类型：图片分类或目标检测
- 是否进行切分：是否对数据集进行切分。如果不切分，所有数据将会转换成 tfrecord，并输出到【训练集输出】目录下。
- 验证集比例：如果进行切分，切分成验证集的数据比例。

#### 实例生成
将输入数据连接到算子的输入桩，单击运行进行切分和转换。

