Closeness on SONA 

#### 算法简介
紧密中心度算法（Closeness Centrality）计算一个节点到所有其他可达节点的最短距离的倒数，进行累积后归一化的值。紧密中心度可以用来衡量信息从该节点传输到其他节点的时间长短。
节点的 Closeness Centrality 越小，其在所在图中的位置越靠近中心。紧密中心度算法（Closeness Centrality）适用于社交网络中关键节点挖掘等场景。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：

```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的 COS 路径，每行一条边。
  - 结果输出路径：输出结果保存 COS 路径。
  - 分区数：Spark RDD 的分区数量。
  - srcIndex：输入数据的源顶点列下标，0是第一列，默认为0。
  - dstIndex：输入数据的目标顶点列下标，默认为1。
  - PS分区个数：参数服务器模型的分区数量。
  - 分隔符：每条边的起始顶点、目标顶点以及权重列之间的分隔符：tab，空格等。
  - 输出额外信息：是否输出节点 cardinality 及以半径加权求和的 cardinality，true or false。
- **算法参数**
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - 均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否。
  - 精度：HyperLogLog counter 的精度(≥4)。精度会以指数形式影响算法性能，建议在资源允许的情况下尽量设为10。
  - 分批向 PS 更新数值的批数：每个 worker 分批向参数服务器传输数值更新的批次。
  - 图的类型：无向图或者有向图。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - executor-memory(g)：每个 executor 需要的内存，单位为 g。
  - executor-cores：每个 executor 需要的 CPU 核数。
  - driver-memory(g)：spark driver 需要的内存，单位为 g。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为 true。
  - spark.ps.instances：angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - spark.ps.cores：每个 angel ps 需要的核数。
  - spark.ps.memory(g)：每个 angel ps 需要的内存，单位为 g。

#### 本算子主要解决了网络中节点的重要性评价的问题
- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/3ce3ed12cb198529048beaae4a4434a7.png)
- 运行算子后得到的结果输出格式为 nodeId(long) | closeness(float) | 节点 cardinality | 半径加权求和的 cardinality， closeness 值越大表示节点越重要。
![](https://main.qcloudimg.com/raw/b815b9b1ee4eb1689c591df4e4ece269.png)

## Common Friends on SONA
#### 算法简介
计算顶点与它的直接(一度)邻居之间的共同邻居数量。在社交网络中，可以全量计算网络中每个顶点的共同好友数量，也可以输入多对不存在好友关系的顶点对，计算这些顶点之间的共同好友数量。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，每条边由起始顶点和终止顶点标识，如下所示：

```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

- **算法 IO 参数**
  - 所有好友边：输入的边表所在的 COS 路径，每行一条边，每条边由起始顶点和终止顶点标识。
  - 需要计算的好友边：需要计算共同好友的顶点对（边）COS 路径，每行一条。
  - 结果输出路径：输出结果保存 COS 路径。
  - 数据分隔符：每条边的起始顶点和终止顶点之间的分隔符：tab，空格等。
  - checkpoint路径：模型的 checkpoint 保存 COS 路径。
  - RDD存储级别：`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
- **算法参数**
  - 分区数量：Spark RDD 的分区数量。
  - 参数服务器分区数量：参数服务器模型的分区数量。
  - 数据中源顶点的列：输入数据的源顶点列下标，0是第一列，默认为0。
  - 数据中目标顶点的列 输入数据的目标顶点列下标，默认为1。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - executor-memory(g)：每个 executor 需要的内存，单位为 g。
  - executor-cores：每个 executor 需要的 CPU 核数。
  - driver-memory(g)：spark driver 需要的内存，单位为 g。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为 true。
  - spark.ps.instances：angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - spark.ps.cores：每个 angel ps 需要的核数。
  - spark.ps.memory(g)：每个 angel ps 需要的内存，单位为 g。

#### 本算子主要解决了计算两个好友的共同好友数的问题
某种程度上可以刻画两个节点之间的紧密程度
- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/89b9e23ea4f013e81d89a0215b81b976.png)
- 运行算子后得到的结果输出格式为输出的格式为 srcId(long) | dstId(long) | count(int)
![](https://main.qcloudimg.com/raw/66a5a2ce09cc13e2f0c11ce274c7cb4a.png)

## [CD]FastUnfolding on SONA 
#### 算法简介
模块度成为度量社区划分优劣的重要标准，划分后的网络模块度值越大，说明社区划分的效果越好，Fast Unfolding 算法便是基于模块度对社区划分的算法。Fast Unfolding 算法是一种迭代的算法，主要目标是不断划分社区使得划分后的整个网络的模块度不断增大。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：

```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的 COS 路径，每行一条边。
  - 输出路径：输出结果保存 COS 路径。
  - checkpoint路径：模型的 checkpoint 保存 COS 路径。
  - srcIndex：输入数据的源顶点列下标，0是第一列，默认为0。
  - dstIndex: 输入数据的目标顶点列下标，默认为1。
  - 输入数据分隔符：每条边的起始顶点、目标顶点之间的分隔符：tab，空格 等。
  - 是否带权：边是否带权重
  - weightIndex：输入数据边的权重列下标，默认为2
- **算法参数**
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - 数据分区数：Spark RDD 分区数目。
  - psPartitionNum：参数服务器模型的分区数量。
  - batchSize：每个 batch 数据大小。
  - numFold：折叠次数。
  - numOpt：每轮模块度优化次数。
  - eps：每次模块度优化提升下界。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - executor-memory(g)：每个 executor 需要的内存，单位为 g。
  - executor-cores：每个 executor 需要的 CPU 核数。
  - driver-memory(g)：spark driver 需要的内存，单位为 g。
  - spark conf参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为 true。
  - spark.ps.instances：angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - spark.ps.cores：每个 angel ps 需要的核数。
  - spark.ps.memory(g)：每个 angel ps 需要的内存，单位为 g。

#### 本算子主要解决了社团发现的问题
目标是从图数据中挖掘节点之间的社群属性
- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/874e20c893c0be022ed9b2a56bda37de.png)
- 运行算子后得到的结果输出的格式为 nodeId(long) | communityId(long)，communityId 一致表示属于同一个社区，编号不连续。
![](https://main.qcloudimg.com/raw/111beef2d49b6345605acf36ff47fc0b.png)

## Kcore on SONA 
#### 算法简介
对输入的网络数据，获得每个节点的 coreness。 Kcore 算法的最直观解释是剥洋葱，即首先将网络中度为1的节点剥离，
此时剩余的网络中可能会产生新的度为1的节点，再依次剥离，直到剩余的网络中所有节点的度都大于等于2。 那么之前被剥离的节点的 coreness 即为1。
之后再依次剥离得到 coreness 为2,3,...,n的节点，直到网络中所有的节点都得到对应的 coreness。实际的分布式实现没有这么朴素，请参考论文 [Distributed k-Core Decomposition](https://arxiv.org/pdf/1103.5320.pdf)。 coreness 越大表示节点属于越中心的位置, 从而也越重要。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，每条边由起始顶点和终止顶点标识，如下所示：

```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的cos路径，每行一条边。
  - srcIndex：输入数据的源顶点列下标，0是第一列，默认为0。
  - dstIndex: 输入数据的目标顶点列下标，默认为1。
  - 输入数据分隔符：每条边的起始顶点、目标顶点之间的分隔符：tab，空格等
  - 输出路径：输出结果保存 COS 路径。
  - checkpoint路径：模型的 checkpoint 保存 COS 路径。
- **算法参数**
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - 数据分区数：Spark RDD 分区数目。
  - ps分区数：参数服务器模型的分区数量。
  - 是否使用均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - executor-memory(g)：每个 executor 需要的内存，单位为 g。
  - executor-cores：每个 executor 需要的 CPU 核数。
  - driver-memory(g)：spark driver 需要的内存，单位为 g。
  - spark conf参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为 true。
  - spark.ps.instances：angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - spark.ps.cores：每个 angel ps 需要的核数。
  - spark.ps.memory(g)：每个 angel ps 需要的内存，单位为 g。

#### 本算子主要解决了网络中节点的重要性评价的问题
- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/28b7fdf06b4d1518c9febcbc3803bc85.png)
- 运行算子后得到的结果输出格式为 nodeId(long) | coreness(int)， coreness 值越大表示节点越重要
![](https://main.qcloudimg.com/raw/37d76553da5c7bd155e89132c6eb9325.png)

## LINE_V2 on SONA 
#### 算法简介
LINE [Large-scale Information Network Embedding](https://arxiv.org/abs/1503.03578) 算法，Network Embedding领域著名的算法之一，重点在于设计了两个目标函数，分别刻画节点之间的一阶相似性（直接连边）和二阶相似性（相似邻居）。

#### 参数说明
- **输入数据格式**
无向图，节点需要从0开始连续编号，以空白符或者逗号分隔，如下所示：

```
0    2
2    1
3    1
3    2
4    1
... ...
... ...
```

- **算法 IO 参数**
  - 训练数据：训练数据所在的 COS 路径。
  - remapping：是否对节点 ID 进行重新映射。
  - 模型保存路径：训练结果保存 COS 路径。
- **算法参数**
  - Embedding 特征的维度：embedding向量的维度，是 PS 分区数的倍数。
  - ps分区数：参数服务器模型的分区数量。
  - 负采样数：负采样节点个数。
  - 学习率：初始学习率。
  - BatchSize：每个 mini batch 数据大小。
  - 最大 epoch 数：最大迭代轮数。
  - Order：一阶或者二阶的 LINE。
  - subSample：是否对训练数据进行采样。
  - 每隔多少个 epoch 保存一次模型：每隔多少个 epoch 保存一次模型。
  - 每隔多少轮做一次 checkpoint：每隔多少轮做一次 checkpoint。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - executor-memory(g)：每个 executor 需要的内存，单位为 g。
  - executor-cores：每个executor需要的 CPU 核数。
  - driver-memory(g)：spark driver 需要的内存，单位为 g。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为 true。
  - spark.ps.instances：angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - spark.ps.cores：每个 angel ps 需要的核数。
  - spark.ps.memory(g)：每个 angel ps 需要的内存，单位为 g。

#### 本算子主要解决了将难以处理的图数据转换为易于处理的向量型数据（将高维的图数据嵌入到低维的向量空间）的问题

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/874e20c893c0be022ed9b2a56bda37de.png)
- 运行算子后得到的结果有节点向量文件和节点 ID 映射文件
- ID 映射文件格式为：映射后的节点 ID：原节点 ID。
![](https://main.qcloudimg.com/raw/cd1533ea89061d44776399184f6eb8ea.png)
- 词向量文件格式为：映射后的节点 ID：节点向量
![](https://main.qcloudimg.com/raw/479e4d760f7f97b23693cf528cc3dd00.png)

## PageRank on SONA 
#### 算法简介
PageRank 算法可能是最著名的节点重要性评价算法，最初由拉里佩奇提出，被应用于 Google 搜索的网页排名。 详细算法细节参考论文 [The PageRank Citation Ranking:Bringing Order to the Web](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf)。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：

```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的 COS 路径，每行一条边。
  - 结果输出路径：输出结果保存 COS 路径。
  - 分区数：Spark RDD 的分区数量。
  - srcIndex：输入数据的源顶点列下标，0是第一列，默认为0。
  - dstIndex：输入数据的目标顶点列下标，默认为1。
  - weightIndex：输入数据边的权重列下标，默认为2。
  - PS 分区个数：参数服务器模型的分区数量。
  - 分隔符：每条边的起始顶点、目标顶点以及权重列之间的分隔符：tab、空格等。
- **算法参数**
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - 均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否。
  - 均衡划分比例：0 - 1之间的浮点数，节点索引越不均衡，该值越小，建议0.7。
  - tolerance：停止进行消息更新的精度阈值。
  - 重定向概率：重定向概率。
  - 是否带权：边是否带权重。
  - 版本：图的切割方式，点切或者边切。
  - 存储时分批次数：存储时的分批次数。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - executor-memory(g)：每个 executor 需要的内存，单位为 g。
  - executor-cores：每个 executor 需要的 CPU 核数。
  - driver-memory(g)：spark driver 需要的内存，单位为g。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为 true。
  - spark.ps.instances：angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 ps 个数越多。
  - spark.ps.cores：每个 angel ps 需要的核数。
  - spark.ps.memory(g)：每个 angel ps 需要的内存，单位为 g。

#### 本算子主要解决了网络中节点的重要性评价的问题
- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/b40581907fad92cd0ef9d349065706e0.png)
- 运行算子后得到的结果输出格式为 nodeId(long) | rank(float)， rank 值越大表示节点越重要。
![](https://main.qcloudimg.com/raw/8b6f420c1c25d3250c876648648812b4.png)

## Triangle Counting on SONA 
#### 算法简介
统计有向图中每个顶点所在的三角形数量。
有向图中的三角形有 [7种类型](https://arxiv.org/abs/1404.5874)，本算法对于每个顶点会分别统计7种三角形的数量。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，每条边由起始顶点和终止顶点标识，如下所示：

```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

- **算法 IO 参数**
  - 图的边表路径：输入的边表所在的 COS 路径，每行一条边，每条边由起始顶点和终止顶点标识。
  - 结果输出路径：输出结果保存 COS 路径。
  - 数据分隔符：每条边的起始顶点和终止顶点之间的分隔符：tab，空格等。
  - RDD 存储级别：`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - checkpoint 路径：模型的 checkpoint 保存 COS 路径。
- **算法参数**
  - Spark 分区数量：Spark RDD 的分区数量。
  - 参数服务器分区数量：参数服务器模型的分区数量。
  - 数据中源顶点的列：输入数据的源顶点列下标，0是第一列，默认为0。
  - 数据中目标顶点的列：输入数据的目标顶点列下标，默认为1。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - executor-memory(g)：每个 executor 需要的内存，单位为 g。
  - executor-cores：每个 executor 需要的 CPU 核数。
  - driver-memory(g)：spark driver 需要的内存，单位为 g。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为 true。
  - spark.ps.instances：angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - spark.ps.cores：每个 angel ps 需要的核数。
  - spark.ps.memory(g)：每个 angel ps 需要的内存，单位为 g。

#### 本算子主要解决了判断社会网络的成熟度或者社区的年龄的问题
三角形越多，代表图中节点关联程度越高，组织关系越严密，则更像一个成熟的社区网络。
- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/874e20c893c0be022ed9b2a56bda37de.png)
- 运行算子后得到的结果输出格式为第一列是顶点，后面七列是有向图每个顶点所在的7种三角形数量，具体是哪7种三角形可参考算法简介章节
![](https://main.qcloudimg.com/raw/357896760d504c2448f15e625c2fdc95.png)

## [2.0]HyperAnf
估计网络的平均半径，参考论文 [HyperANF: Approximating the Neighbourhood Function of Very Large Graphs on a Budget](https://arxiv.org/pdf/1011.5599.pdf) 开发，详细细节请看论文。

#### 输入
- 输入数据路径：输入文件所在路径，无权网络数据, 数据格式为两列 `srcId(long) | dstId(long)`, 其中`|`为分隔符，分隔字段表示空白符或者逗号等。
- 输入文件类型：格式包括以下两种：
  - csv：csv 文件。
    - 输入数据包含 header 信息。
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。

#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下两种：
  - csv：csv 文件。
    - 输出数据包含 header 信息。
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。

 >算法结果保存路径，共两列，其中第一列为 round 值，第二列为 anf 值，其中round = -1对应的 anf 为最终估计值。

**参数说明**
- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。
- maxIter：最大迭代次数。

## [2.0]LPA
LPA（Label Propagation Algorithm）是最简单的社区发现算法，通过标签扩散发掘网络的社区关系。
#### 输入
- 输入数据路径：输入文件所在路径。
- 输入文件类型：格式包括以下两种：
  - csv：csv 文件。
    - 输入数据包含 header 信息。
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。

#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下两种：
  - csv：csv 文件。
    - 输出数据包含 header 信息。
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。
  
 > 算法结果保存路径，共两列，其中第一列为节点 ID，第二列为节点对应的社区 ID。社区 ID 相同表示属于同一个社区。

**资源参数**
- num-executors：使用多少个 Spark 节点。
- driver-memory：Spark driver 的内存大小。
- executor-cores：每个 Spark 节点使用多少个 core。
- executor-memory：每个 Spark 节点使用的内存大小。
- spark-conf：Spark 的其他参数。 由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=用户名：密码。

#### 参数说明
- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。

## [2.0]EffectiveSize
EffectiveSize 是由结构空洞理论得到的网络度量指标，是 ego-network 中节点的重要衡量指标。

#### 输入
- 输入数据路径：输入文件所在路径。
- 输入文件类型：格式包括以下两种：
  - csv：csv 文件。
    - 输入数据包含 header 信息。
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - text：本文件。
  - parquet：列式存储格式 parquet。

#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下两种：
  - csv：csv 文件。
    - 输出数据包含 header 信息
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。
  > 算法结果保存路径，共三列，其中第一列为节点 ID，第二列为 effectiveSize 值，第三列为 redundancyCol 值。

**资源参数**
- num-executors：使用多少个 Spark 节点。
- driver-memory：Spark driver 的内存大小。
- executor-cores：每个 Spark 节点使用多少个 core。
- executor-memory：每个Spark节点使用的内存大小。
- spark-conf：Spark的其他参数。由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=用户名：密码。

#### 参数说明
- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。
