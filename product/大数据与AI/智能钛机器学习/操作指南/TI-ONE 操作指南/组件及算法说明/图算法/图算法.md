# 图算法

## [2.0]HyperAnf
估计网络的平均半径，参考论文 [HyperANF: Approximating the Neighbourhood Function of Very Large Graphs on a Budget](https://arxiv.org/pdf/1011.5599.pdf) 开发，详细细节请看论文。

#### 输入
- 输入数据路径：输入文件所在路径，无权网络数据, 数据格式为两列 `srcId(long) | dstId(long)`, 其中`|`为分隔符，分隔字段表示空白符或者逗号等
- 输入文件类型：格式包括以下三种：
  - csv：csv 文件
    - 输入数据包含 header 信息
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet

#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下两种：
    - csv：csv 文件。
         - 输出数据包含 header 信息。
         - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符。
    - parquet：列式存储格式 parquet。

算法结果保存路径，共两列，其中第一列为 round 值，第二列为 anf值；其中 round = -1对应的 anf 为最终估计值。

**参数说明**
- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。
- maxIter：最大迭代次数。

##Closeness on SONA ##
### 算法简介
紧密中心度算法（Closeness Centrality）计算一个节点到所有其他可达节点的最短距离的倒数，进行累积后归一化的值。紧密中心度可以用来衡量信息从该节点传输到其他节点的时间长短。
节点的“Closeness Centrality”越小，其在所在图中的位置越靠近中心。紧密中心度算法（Closeness Centrality）适用于社交网络中关键节点挖掘等场景。

### 参数说明
* **输入数据格式**

边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：
```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

* **训练节点**
  - 算法IO参数
    * 边输入路径：输入的边表所在的cos路径，每行一条边。
    * 结果输出路径：输出结果保存cos路径
    * 分区数：Spark RDD的分区数量
    * srcIndex：输入数据的源顶点列下标，0是第一列，默认为0
    * dstIndex: 输入数据的目标顶点列下标，默认为1
    * PS分区个数：参数服务器模型的分区数量
    * 分隔符：每条边的起始顶点、目标顶点以及权重列之间的分隔符: `tab`, `空格`等
    * 输出额外信息：是否输出节点cardinality及以半径加权求和的cardinality，true or false

  - 算法参数
    * storageLevel：RDD存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`
    * 均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否
    * 精度：HyperLogLog counter的精度(≥4)。精度会以指数形式影响算法性能，建议在资源允许的情况下尽量设为10
    * 分批向PS更新数值的批数：每个worker分批向参数服务器传输数值更新的批次
    * 图的类型：无向图或者有向图

  - spark conf参数
    * spark.angel.tmp.output.path.prefix：angel临时目录的前缀路径，为cos路径
    * saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为true

  - 资源参数
    * num-executors：任务启动的spark executor个数，可根据数据量来配置，一般训练数据量越大，需要的worker个数越多
    * executor-memory(g)：每个executor需要的内存，单位为g
    * executor-cores：每个executor需要的CPU核数
    * driver-memory(g)：spark driver需要的内存，单位为g
    * spark.ps.instances：angel ps个数，可根据模型大小来配置，一般模型越大，需要的ps个数越多
    * spark.ps.cores：每个angel ps需要的核数
    * spark.ps.memory(g)：每个angel ps需要的内存，单位为g

### demo实例
* **数据集准备**
  - 从 输入->数据源->cos数据集 拉取数据集组件
  - 配置数据集组件参数即训练数据的cos路径
![](https://main.qcloudimg.com/raw/e6173375b6759cf0a68ef3d7ff2a97d0.png)

* **拉取算子组件配置参数**
  - 从 算法->图算法->Closeness on SONA 拉取算子组件，和数据集组件组成pipeline
![](https://main.qcloudimg.com/raw/29c1e372a8eabc36d0c785bd00ab8e90.png)

  - 配置算子的io参数以及算法参数
![](https://main.qcloudimg.com/raw/4a6a3e9656fe5a5efe396a9f30da3b75.png)

  - 配置算子的资源参数，包括spark和angel的资源参数
![](https://main.qcloudimg.com/raw/606f82156a2ac83f0b13224bed2ac8d0.png)

  - 点击运行按钮运行作业
![](https://main.qcloudimg.com/raw/529873c344d7284ba0b3a1bc1d17e06d.png)

  - 右键算子组件->日志信息->spark控制台 查看日志
![](https://main.qcloudimg.com/raw/bab0bd08368f8e1374de0e6398026346.png)

### 本算子主要解决了网络中节点的重要性评价的问题
* 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/5a51a80d9494aaf9cfac40283a907424.png)

* 运行算子后得到的结果输出格式为nodeId(long) | closeness(float) | 节点cardinality | 半径加权求和的cardinality, closeness值越大表示节点越重要
![](https://main.qcloudimg.com/raw/b815b9b1ee4eb1689c591df4e4ece269.png)

##Common Friends on SONA ##
### 算法简介
计算顶点与它的直接(一度)邻居之间的共同邻居数量。在社交网络中，可以全量计算网络中每个顶点的共同好友数量；也可以输入多对不存在好友关系的顶点对，计算
这些顶点之间的共同好友数量。

### 参数说明
* **输入数据格式**

边表形式，每行一条边，每条边由起始顶点和终止顶点标识，如下所示：
```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

* **训练节点**
  - 算法IO参数
    * 所有好友边：输入的边表所在的cos路径，每行一条边，每条边由起始顶点和终止顶点标识。
    * 需要计算的好友边：需要计算共同好友的顶点对（边）cos路径，每行一条
    * 结果输出路径：输出结果保存cos路径
    * 数据分隔符：每条边的起始顶点和终止顶点之间的分隔符: `tab`, `空格`等
    * checkpoint路径：模型的checkpoint保存cos路径
    * RDD存储级别：`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`

  - 算法参数
    * 分区数量：Spark RDD的分区数量
    * 参数服务器分区数量：参数服务器模型的分区数量
    * 数据中源顶点的列：输入数据的源顶点列下标，0是第一列，默认为0
    * 数据中目标顶点的列 输入数据的目标顶点列下标，默认为1

  - spark conf参数
    * spark.angel.tmp.output.path.prefix：angel临时目录的前缀路径，为cos路径
    * saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为true

  - 资源参数
    * num-executors：任务启动的spark executor个数，可根据数据量来配置，一般训练数据量越大，需要的worker个数越多
    * executor-memory(g)：每个executor需要的内存，单位为g
    * executor-cores：每个executor需要的CPU核数
    * driver-memory(g)：spark driver需要的内存，单位为g
    * spark.ps.instances：angel ps个数，可根据模型大小来配置，一般模型越大，需要的ps个数越多
    * spark.ps.cores：每个angel ps需要的核数
    * spark.ps.memory(g)：每个angel ps需要的内存，单位为g

### demo实例
* **数据集准备**
  - 从 输入->数据源->cos数据集 拉取数据集组件
  - 配置数据集组件参数即训练数据的cos路径
![](https://main.qcloudimg.com/raw/0195275a1331f6a95606efe8d210f82e.png)

* **拉取算子组件配置参数**
  - 从 算法->图算法->Common Friends on SONA 拉取算子组件，和数据集组件组成pipeline
![](https://main.qcloudimg.com/raw/0b0bb1c968991eb7a2d56b177ea21089.png)

  - 配置算子的io参数以及算法参数
![](https://main.qcloudimg.com/raw/176087d9471b6ba9a4aa60a6a47c00eb.png)

  - 配置算子的资源参数，包括spark和angel的资源参数
![](https://main.qcloudimg.com/raw/bebfc40dafafcff9e6f1f065da90f953.png)

  - 点击运行按钮运行作业
![](https://main.qcloudimg.com/raw/4be5b67b8f5d7cf5ff0f06526ed5b562.png)

  - 右键算子组件->日志信息->spark控制台 查看日志
![](https://main.qcloudimg.com/raw/084a4b31c5a7dbe60ce02407c23db7af.png)

### 本算子主要解决了计算两个好友的共同好友数的问题
某种程度上可以刻画两个节点之间的紧密程度
* 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/e0ba2c41e950dc19f9c00b0e0c935411.png)

* 运行算子后得到的结果输出格式为输出的格式为 srcId(long) | dstId(long) | count(int)
![](https://main.qcloudimg.com/raw/66a5a2ce09cc13e2f0c11ce274c7cb4a.png)

##[CD]FastUnfolding on SONA ##
### 算法简介
模块度成为度量社区划分优劣的重要标准，划分后的网络模块度值越大，说明社区划分的效果越好，
Fast Unfolding算法便是基于模块度对社区划分的算法，Fast Unfolding算法是一种迭代的算法，主要目标是不断划分社区使得划分后的整个网络的模块度不断增大。

### 参数说明
* **输入数据格式**

边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：
```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

* **训练节点**
  - 算法IO参数
    * 边输入路径：输入的边表所在的cos路径，每行一条边
    * 输出路径：输出结果保存cos路径
    * checkpoint路径：模型的checkpoint保存cos路径
    * srcIndex：输入数据的源顶点列下标，0是第一列，默认为0
    * dstIndex: 输入数据的目标顶点列下标，默认为1
    * 输入数据分隔符：每条边的起始顶点、目标顶点之间的分隔符: `tab`, `空格`等
    * 是否带权：边是否带权重
    * weightIndex：输入数据边的权重列下标，默认为2

  - 算法参数
    * storageLevel：RDD存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`
    * 数据分区数：Spark RDD分区数目
    * psPartitionNum：参数服务器模型的分区数量
    * batchSize：每个batch数据大小
    * numFold：折叠次数
    * numOpt：每轮模块度优化次数
    * eps：每次模块度优化提升下界

  - spark conf参数
    * spark.angel.tmp.output.path.prefix：angel临时目录的前缀路径，为cos路径
    * saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为true

  - 资源参数
    * num-executors：任务启动的spark executor个数，可根据数据量来配置，一般训练数据量越大，需要的worker个数越多
    * executor-memory(g)：每个executor需要的内存，单位为g
    * executor-cores：每个executor需要的CPU核数
    * driver-memory(g)：spark driver需要的内存，单位为g
    * spark.ps.instances：angel ps个数，可根据模型大小来配置，一般模型越大，需要的ps个数越多
    * spark.ps.cores：每个angel ps需要的核数
    * spark.ps.memory(g)：每个angel ps需要的内存，单位为g

### demo实例
* **数据集准备**
  - 从 输入->数据源->cos数据集 拉取数据集组件
  - 配置数据集组件参数即训练数据的cos路径
![](https://main.qcloudimg.com/raw/94b891750124ea04452e80f38f6e3b59.png)

* **拉取算子组件配置参数**
  - 从 算法->图算法->[CD]FastUnfolding on SONA 拉取算子组件，和数据集组件组成pipeline
![](https://main.qcloudimg.com/raw/8550f56a28e82f6f51a2cf46b77e5884.png)

  - 配置算子的io参数以及算法参数
![](https://main.qcloudimg.com/raw/98735b6a46a0f164fe823d3f00d1f4ca.png)

  - 配置算子的资源参数，包括spark和angel的资源参数
![](https://main.qcloudimg.com/raw/a8db3a792b7e76f5db6fbb76c8f38f7a.png)

  - 点击运行按钮运行作业
![](https://main.qcloudimg.com/raw/bf61fec15a3a93a16a0a516004775a6a.png)

  - 右键算子组件->日志信息->spark控制台 查看日志
![](https://main.qcloudimg.com/raw/fc9e8210f43c4ad9b92d159a104513e0.png)

### 本算子主要解决了社团发现的问题
目标是从图数据中挖掘节点之间的社群属性
* 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/874e20c893c0be022ed9b2a56bda37de.png)

* 运行算子后得到的结果输出的格式为nodeId(long) | communityId(long), communityId一致表示属于同一个社区, 编号不连续
![](https://main.qcloudimg.com/raw/111beef2d49b6345605acf36ff47fc0b.png)



##Kcore on SONA ##
### 算法简介
对输入的网络数据，获得每个节点的coreness。 Kcore算法的最直观解释是剥洋葱，即首先将网络中度为1的节点剥离，
此时剩余的网络中可能会产生新的度为1的节点，再依次剥离，直到剩余的网络中所有节点的度都大于等于2。 那么之前被剥离的节点的coreness即为1。
之后再依次剥离得到coreness为2,3,...,n的节点，直到网络中所有的节点都得到对应的coreness。 当然，实际的分布式实现没有这么朴素，
请参考论文[Distributed k-Core Decomposition](https://arxiv.org/pdf/1103.5320.pdf)。 coreness越大表示节点属于越中心的位置, 从而也越重要。

### 参数说明
* **输入数据格式**

边表形式，每行一条边，每条边由起始顶点和终止顶点标识，如下所示：
```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

* **训练节点**
  - 算法IO参数
    * 边输入路径：输入的边表所在的cos路径，每行一条边。
    * srcIndex：输入数据的源顶点列下标，0是第一列，默认为0
    * dstIndex: 输入数据的目标顶点列下标，默认为1
    * 输入数据分隔符：每条边的起始顶点、目标顶点之间的分隔符: `tab`, `空格`等
    * 输出路径：输出结果保存cos路径
    * checkpoint路径：模型的checkpoint保存cos路径

  - 算法参数
    * storageLevel：RDD存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`
    * 数据分区数：Spark RDD分区数目
    * ps分区数：参数服务器模型的分区数量
    * 是否使用均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否

  - spark conf参数
    * spark.angel.tmp.output.path.prefix：angel临时目录的前缀路径，为cos路径
    * saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为true

  - 资源参数
    * num-executors：任务启动的spark executor个数，可根据数据量来配置，一般训练数据量越大，需要的worker个数越多
    * executor-memory(g)：每个executor需要的内存，单位为g
    * executor-cores：每个executor需要的CPU核数
    * driver-memory(g)：spark driver需要的内存，单位为g
    * spark.ps.instances：angel ps个数，可根据模型大小来配置，一般模型越大，需要的ps个数越多
    * spark.ps.cores：每个angel ps需要的核数
    * spark.ps.memory(g)：每个angel ps需要的内存，单位为g

### demo实例
* **数据集准备**
  - 从 输入->数据源->cos数据集 拉取数据集组件
  - 配置数据集组件参数即训练数据的cos路径
![](https://main.qcloudimg.com/raw/19d1a4d05ec872685dd8966861c418dd.png)

* **拉取算子组件配置参数**
  - 从 算法->图算法->Kcore on SONA 拉取算子组件，和数据集组件组成pipeline
![](https://main.qcloudimg.com/raw/f582b00435c22e0b6132e1be5892056e.png)

  - 配置算子的io参数以及算法参数
![](https://main.qcloudimg.com/raw/5181898107bb68657661264af74f6595.png)

  - 配置算子的资源参数，包括spark和angel的资源参数
![](https://main.qcloudimg.com/raw/8c4480691c4cda238af360817112e7e6.png)

  - 点击运行按钮运行作业
![](https://main.qcloudimg.com/raw/f63cbd4bedc9a3199c5fec99b7824fa3.png)

  - 右键算子组件->日志信息->spark控制台 查看日志
![](https://main.qcloudimg.com/raw/56f9eb059d9240e3b8a24be575df4d54.png)

### 本算子主要解决了网络中节点的重要性评价的问题
* 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/1f07ffa80157106afa88b1ad8f80dd78.png)

* 运行算子后得到的结果输出格式为nodeId(long) | coreness(int), coreness值越大表示节点越重要
![](https://main.qcloudimg.com/raw/7c7bfdac2c77d979cc0ba5f26a61b6aa.png)

##LINE_V2 on SONA ##
### 算法简介
LINE([Large-scale Information Network Embedding](https://arxiv.org/abs/1503.03578))算法，Network Embedding领域著名的算法之一，
重点在于设计了两个目标函数，分别刻画节点之间的一阶相似性(直接连边)和二阶相似性(相似邻居)。

### 参数说明
* **输入数据格式**

无向图，节点需要从0开始连续编号，以空白符或者逗号分隔，如下所示：
```
0    2
2    1
3    1
3    2
4    1
... ...
... ...
```

* **训练节点**
  - 算法IO参数
    * 训练数据：训练数据所在的cos路径
    * remapping：是否对节点id进行重新映射
    * 模型保存路径：训练结果保存cos路径

  - 算法参数
    * Embedding特征的维度：embedding向量的维度，是ps分区数的倍数
    * ps分区数：参数服务器模型的分区数量
    * 负采样数：负采样节点个数
    * 学习率：初始学习率
    * BatchSize：每个mini batch数据大小
    * 最大epoch数：最大迭代轮数
    * Order：一阶或者二阶的LINE
    * subSample：是否对训练数据进行采样
    * 每隔多少个epoch保存一次模型：每隔多少个epoch保存一次模型
    * 每隔多少轮做一次checkpoint：每隔多少轮做一次checkpoint

  - spark conf参数
    * spark.angel.tmp.output.path.prefix：angel临时目录的前缀路径，为cos路径
    * saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为true

  - 资源参数
    * num-executors：任务启动的spark executor个数，可根据数据量来配置，一般训练数据量越大，需要的worker个数越多
    * executor-memory(g)：每个executor需要的内存，单位为g
    * executor-cores：每个executor需要的CPU核数
    * driver-memory(g)：spark driver需要的内存，单位为g
    * spark.ps.instances：angel ps个数，可根据模型大小来配置，一般模型越大，需要的ps个数越多
    * spark.ps.cores：每个angel ps需要的核数
    * spark.ps.memory(g)：每个angel ps需要的内存，单位为g

### demo实例
* **数据集准备**
  - 从 输入->数据源->cos数据集 拉取数据集组件
 - 配置数据集组件参数即训练数据的cos路径
![](https://main.qcloudimg.com/raw/7474ae8af07d76f727de6df3eac72d8d.png)

* **拉取算子组件配置参数**
  - 从 算法->图算法->LINE_V2 on SONA 拉取算子组件，和数据集组件组成pipeline
![](https://main.qcloudimg.com/raw/e77bd810784b87a8202674cfc9425c52.png)

  - 配置算子的io参数以及算法参数
![](https://main.qcloudimg.com/raw/b8cd6285c67288f75ac42b1b5cf5f01c.png)

  - 配置算子的资源参数，包括spark和angel的资源参数
![](https://main.qcloudimg.com/raw/7c61721e388d4d5f538f4da610c0ac0b.png)

  - 点击运行按钮运行作业
![](https://main.qcloudimg.com/raw/2710658055da8c2bba26f1bfef2591b7.png)

  - 右键算子组件->日志信息->spark控制台 查看日志
![](https://main.qcloudimg.com/raw/9c54e25bd6c6b4bce811788e2adfff37.png)

### 本算子主要解决了将难以处理的图数据转换为易于处理的向量型数据（将高维的图数据嵌入到低维的向量空间）的问题
* 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/874e20c893c0be022ed9b2a56bda37de.png)


* 运行算子后得到的结果有节点向量文件和节点id映射文件
  - id映射文件格式为：映射后的节点id:原节点id
![](https://main.qcloudimg.com/raw/cd1533ea89061d44776399184f6eb8ea.png)

  - 词向量文件格式为：映射后的节点id:节点向量
![](https://main.qcloudimg.com/raw/479e4d760f7f97b23693cf528cc3dd00.png)



##PageRank on SONA ##
### 算法简介
PageRank算法可能是最著名的节点重要性评价算法，最初由拉里佩奇提出，被应用于Google搜索的网页排名。 详细算法
细节参考论文[The PageRank Citation Ranking:Bringing Order to the Web](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf)。

### 参数说明
* **输入数据格式**

边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：
```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

* **训练节点**
  - 算法IO参数
    * 边输入路径：输入的边表所在的cos路径，每行一条边。
    * 结果输出路径：输出结果保存cos路径
    * 分区数：Spark RDD的分区数量
    * srcIndex：输入数据的源顶点列下标，0是第一列，默认为0
    * dstIndex: 输入数据的目标顶点列下标，默认为1
    * weightIndex：输入数据边的权重列下标，默认为2
    * PS分区个数：参数服务器模型的分区数量
    * 分隔符：每条边的起始顶点、目标顶点以及权重列之间的分隔符: `tab`, `空格`等

  - 算法参数
    * storageLevel：RDD存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`
    * 均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否
    * 均衡划分比例：0-1之间的浮点数，节点索引越不均衡，该值越小，建议0.7
    * tolerance：停止进行消息更新的精度阈值
    * 重定向概率：重定向概率
    * 是否带权：边是否带权重
    * 版本：图的切割方式，点切或者边切
    * 存储时分批次数：存储时的分批次数

  - spark conf参数
    * spark.angel.tmp.output.path.prefix：angel临时目录的前缀路径，为cos路径
    * saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为true

  - 资源参数
    * num-executors：任务启动的spark executor个数，可根据数据量来配置，一般训练数据量越大，需要的worker个数越多
    * executor-memory(g)：每个executor需要的内存，单位为g
    * executor-cores：每个executor需要的CPU核数
    * driver-memory(g)：spark driver需要的内存，单位为g
    * spark.ps.instances：angel ps个数，可根据模型大小来配置，一般模型越大，需要的ps个数越多
    * spark.ps.cores：每个angel ps需要的核数
    * spark.ps.memory(g)：每个angel ps需要的内存，单位为g

### demo实例
* **数据集准备**
  - 从 输入->数据源->cos数据集 拉取数据集组件
  - 配置数据集组件参数即训练数据的cos路径
![](https://main.qcloudimg.com/raw/9df099e81358623e51aad2f1e6d4e0be.png)

* **拉取算子组件配置参数**
  - 从 算法->图算法->PageRank on SONA 拉取算子组件，和数据集组件组成pipeline
![](https://main.qcloudimg.com/raw/493d88ea4967fc3a2be8937eb0923fe6.png)

  - 配置算子的io参数以及算法参数
![](https://main.qcloudimg.com/raw/1eeea3c55e00df86957a5b4297bc0284.png)

  - 配置算子的资源参数，包括spark和angel的资源参数
![](https://main.qcloudimg.com/raw/961886714583abb31abcee029777e7cd.png)

  - 点击运行按钮运行作业
![](https://main.qcloudimg.com/raw/a3d9c75d79ad493c5d7c250d9ee687fe.png)

  - 右键算子组件->日志信息->spark控制台 查看日志
![](https://main.qcloudimg.com/raw/d691cca01b89b4bf03705b9a0e64b110.png)

### 本算子主要解决了网络中节点的重要性评价的问题
* 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/5a51a80d9494aaf9cfac40283a907424.png)

* 运行算子后得到的结果输出格式为nodeId(long) | rank(float), rank值越大表示节点越重要
![](https://main.qcloudimg.com/raw/8b6f420c1c25d3250c876648648812b4.png)

##Triangle Counting on SONA ##
### 算法简介
统计有向图中每个顶点所在的三角形数量。
有向图中的三角形有[7种类型](https://arxiv.org/abs/1404.5874)，本算法对于每个顶点会分别统计7种三角形的数量。

### 参数说明
* **输入数据格式**

边表形式，每行一条边，每条边由起始顶点和终止顶点标识，如下所示：
```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

* **训练节点**
  - 算法IO参数
    * 图的边表路径：输入的边表所在的cos路径，每行一条边，每条边由起始顶点和终止顶点标识。
    * 结果输出路径：输出结果保存cos路径
    * 数据分隔符：每条边的起始顶点和终止顶点之间的分隔符: `tab`, `空格`等
    * RDD存储级别：`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`
    * checkpoint路径：模型的checkpoint保存cos路径

  - 算法参数
    * Spark分区数量：Spark RDD的分区数量
    * 参数服务器分区数量：参数服务器模型的分区数量
    * 数据中源顶点的列：输入数据的源顶点列下标，0是第一列，默认为0
    * 数据中目标顶点的列 输入数据的目标顶点列下标，默认为1

  - spark conf参数
    * spark.angel.tmp.output.path.prefix：angel临时目录的前缀路径，为cos路径
    * saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要设置为true

  - 资源参数
    * num-executors：任务启动的spark executor个数，可根据数据量来配置，一般训练数据量越大，需要的worker个数越多
    * executor-memory(g)：每个executor需要的内存，单位为g
    * executor-cores：每个executor需要的CPU核数
    * driver-memory(g)：spark driver需要的内存，单位为g
    * spark.ps.instances：angel ps个数，可根据模型大小来配置，一般模型越大，需要的ps个数越多
    * spark.ps.cores：每个angel ps需要的核数
    * spark.ps.memory(g)：每个angel ps需要的内存，单位为g

### demo实例
* **数据集准备**
  - 从 输入->数据源->cos数据集 拉取数据集组件
  - 配置数据集组件参数即训练数据的cos路径
![](https://main.qcloudimg.com/raw/a83591f6f9d95b23c2d83de901bd57ad.png)

* **拉取算子组件配置参数**
  - 从 算法->图算法->Triangle Counting on SONA 拉取算子组件，和数据集组件组成pipeline
![](https://main.qcloudimg.com/raw/d573e4933e0f6e809e06ba1a3aae3778.png)

  - 配置算子的io参数以及算法参数
![](https://main.qcloudimg.com/raw/e30196a93bdba1558fe61d294b8bccd6.png)

  - 配置算子的资源参数，包括spark和angel的资源参数
![](https://main.qcloudimg.com/raw/0746dc191237d2ec64c8ca27e9ad5575.png)

  - 点击运行按钮运行作业
![](https://main.qcloudimg.com/raw/ff9cb6fc54827749276cb65125594bb0.png)

  - 右键算子组件->日志信息->spark控制台 查看日志
![](https://main.qcloudimg.com/raw/c0af7b8a861c8ba62eb096c6f709343b.png)

### 本算子主要解决了判断社会网络的成熟度或者社区的年龄的问题
三角形越多，代表图中节点关联程度越高，组织关系越严密，则更像一个成熟的社区网络。
* 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/874e20c893c0be022ed9b2a56bda37de.png)

* 运行算子后得到的结果输出格式为第一列是顶点，后面七列是有向图每个顶点所在的7种三角形数量，具体是哪7种三角形可参考算法简介章节
![](https://main.qcloudimg.com/raw/357896760d504c2448f15e625c2fdc95.png)
## [2.0]LPA
LPA（Label Propagation Algorithm）是最简单的社区发现算法，通过标签扩散发掘网络的社区关系。

#### 输入
- 输出数据路径：输出文件所在路径。
- 输入文件类型：格式包括以下三种：
  - csv：csv 文件
    - 输入数据包含 header 信息
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet
  
#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下三种：
  - csv：csv 文件
    - 输出数据包含 header 信息
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet
  
算法结果保存路径，共两列，其中第一列为节点 ID，第二列为节点对应的社区 ID。社区 ID 相同表示属于同一个社区。
  

- **资源参数**
 - num-executors： 使用多少个 Spark 节点
 - driver-memory： Spark driver 的内存大小
 - executor-cores：每个 Spark 节点使用多少个 core
 - executor-memory：每个 Spark 节点使用的内存大小
 - spark-conf：Spark 的其他参数。 特别的，由于权限原因，需要用户额外提供 ugi 参数 spark.hadoop.hadoop.job.ugi=用户名：密码

#### 参数说明
- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。

## [2.0]EffectiveSize
EffectiveSize 是由结构空洞理论得到的网络度量指标，是 ego-network 中节点的重要衡量指标。

#### 输入
- 输入数据路径：输入文件所在路径。
- 输入文件类型：格式包括以下三种：
  - csv：csv 文件
    - 输入数据包含 header 信息
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet
  
#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下三种：
  - csv：csv 文件
    - 输出数据包含 header 信息
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet

算法结果保存路径，共三列，其中第一列为节点 ID，第二列为 effectiveSize 值，第三列为 redundancyCol 值。

- **资源参数**
 - num-executors： 使用多少个 Spark 节点
 - driver-memory： Spark driver 的内存大小
 - executor-cores：每个 Spark 节点使用多少个 core
 - executor-memory：每个 Spark 节点使用的内存大小
 - spark-conf：Spark 的其他参数。 特别的，由于权限原因，需要用户额外提供 ugi 参数 spark.hadoop.hadoop.job.ugi=用户名：密码

#### 参数说明
- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。
