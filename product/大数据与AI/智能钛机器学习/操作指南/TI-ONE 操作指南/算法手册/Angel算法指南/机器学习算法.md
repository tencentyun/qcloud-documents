## [Angel]LR on SonA 

#### 算法简介

LogisticRegression（LR）算法是一种常见的分类算法，因其模型简单、可解释性强等特点在工程领域得到广泛应用。

#### 参数说明

- **输入数据格式**
目前支持 libsvm、dummy 两种数据格式，分别如下所示：

```
libsvm格式: label index:value index:value index:value ......
dummy格式: index,index,index,......
```

>!libsvm 格式的 index 是从1开始的，以空格分隔，dummy 格式的 index 是从0开始的，以逗号分隔。

- **训练节点**
- 算法 IO 参数
   - 数据输入路径：训练数据存储 COS 路径。 
带预测的算子模块模型保存路径不需要用户填写，平台会自动生成。

- 算法参数  
    - 训练迭代次数：模型训练迭代的轮数。
    - 学习率：模型训练初始学习率，默认为0.5。
    - 特征数目：数据特征个数（最大的 featureID 值+1）。
    - validate 数据集比例：每次 validation 的样本比率，设为0时不做 validation。
    - 模型类型：模型的数据类型。
    - 学习率衰减速度：学习速率衰减系数, 默认值为 0.1。
    - 正则项系数：L2惩罚项系数。
    - 每个 mini-batch 样本采样率：每个 mini-batch 样本采样率，1.0表示不采样。
    - 数据标签转换类：数据标签转换类。

- 资源参数
    - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
    - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
    - drive 节点资源类型：请选择合适的 drive 节点机型。
    - executor 节点资源类型：请选择合适的 executor 节点机型。
    - master 节点资源类型：请选择合适的 master 节点机型。
    - ps 节点资源类型：请选择合适的 ps 节点机型。
    - spark conf 参数
      - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
      - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

- **预测节点**
  - 模型 IO 参数
   - 数据输入路径：预测数据输入路径，cos 路径。

  - 模型参数
    - 特征数目：数据特征个数（最大的 featureID 值+1）。
    - 资源参数：与训练节点意义相同。

#### 本算子主要解决了二分类问题

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/e7c8663c1b20e2de8625c7c58f3a71ad.png)
- 训练完成后模型保存路径下会生成分类模型。
![](https://main.qcloudimg.com/raw/a2388866e33431f75d61dc3ecb916570.png)
- 使用分类模型进行新的数据预测，得到分类结果，分类结果展示的是每个类别的概率。
![](https://main.qcloudimg.com/raw/787ebba0293f849802f0c7ddac3f91dc.png)



## [Angel]FM on SonA

#### 算法简介

FactorizationMachine（FM）一种基于矩阵分解的机器学习算法。它可对任意的实值向量进行预测。其主要优点包括： 
（1）可用于高度稀疏数据场景。
（2）具有线性的计算复杂度。

#### 参数说明

- **输入数据格式**
目前支持 libsvm、dummy 两种数据格式，分别如下所示：

```
libsvm格式: label index:value index:value index:value ......
dummy格式: index,index,index,......
```

>!libsvm 格式的 index 是从1开始的，以空格分隔；dummy 格式的 index 是从0开始的，以逗号分隔。

- **训练节点**
- 算法 IO 参数
   - 数据输入：训练数据存储 cos 路径。 
   - validate数据集比例：每次 validation 的样本比率，设为0时不做 validation。
   - ml.data.type：数据格式，支持 dummy、libsvm。
>!带预测的算子模块模型保存路径不需要用户填写，平台会自动生成。

- 算法参数  
   - 迭代次数：模型训练迭代的轮数。
   - 学习率：模型训练初始学习率，默认为 0.05。
   - FM 因子维度：embedding 维度。
   - 正则项参数：L2惩罚项系数。
   - 模型类型：模型的数据类型。
   - 特征数目：数据特征个数（最大的 featureID 值+1）。
   - 学习率衰减速度：学习速率衰减系数，默认值为 0.001。
   - 一个 epoch 中更新参数的次数：在实现时为了加速，每个 minibatch 只更本地参数，多个 minibatch 后会更新一次 PS 上的参数，该参数用于指定一个 epoch 中更新 PS 参数的次数。

- 资源参数
   - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
   - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
   - drive 节点资源类型：请选择合适的 drive 节点机型。
   - executor 节点资源类型：请选择合适的 executor 节点机型。
   - master 节点资源类型：请选择合适的 master 节点机型。
   - ps 节点资源类型：请选择合适的 ps 节点机型。
   - spark conf 参数
     - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
     - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

- **预测节点**
- 模型 IO 参数
    - 输入数据：预测数据输入路径，cos 路径。
    - 预测结果保存路径：预测结果保存路径，cos 路径。

- 模型参数
   - 特征数目：数据特征个数（最大的 featureID 值+1）。
   - ml.data.type：数据格式，支持 dummy、libsvm。
 
- 资源参数：与训练节点意义相同。

#### 本算子主要解决二分类问题

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/e7c8663c1b20e2de8625c7c58f3a71ad.png)
- 训练完成后模型保存路径下会生成分类模型。
![](https://main.qcloudimg.com/raw/d85ba40c0822f2cd8a01d54bdc85d3d2.png)
- 使用分类模型进行新的数据预测，得到分类结果，分类结果展示的是每个类别的概率。
![](https://main.qcloudimg.com/raw/6daef033a48d78789a75a5fe9db60d78.png)



## [Angel]GBDT on SONA 

#### 算法简介

GBDT（Gradient Boosting Decision Tree）：梯度提升决策树是一种集成使用多个弱分类器（决策树）来提升分类效果的机器学习算法，在很多分类和回归的场景中，都有不错的效果。

#### 参数说明

- **输入数据格式**
目前支持 libsvm、dummy 两种数据格式，分别如下所示：

```
libsvm格式: label index:value index:value index:value ......
dummy格式: index,index,index,......
```

>!libsvm 格式的 index 是从1开始的，以空格分隔；dummy 格式的 index 是从0开始的，以逗号分隔。

- **训练节点**
- 算法 IO 参数
   - 训练数据路径：训练数据存储 cos 路径。
   - 验证数据路径：验证数据存储 cos 路径。

- 算法参数  
   - 任务类型：分类，回归任务可选。
   - 损失函数：二分类 logistic， 多分类 logistic，均方根误差（用于回归任务）。
   - 评估指标：二分类 AUC（仅二分类使用），分类错误率，多分类交叉熵，均方根误差（用于回归任务）。
   - 树的数量：构建的树的个数（轮数）。
   - 候选分裂点数量：每个特征可分成的候选分裂点的个数。
   - 树的最大深度：每棵树的最大深度。
   - 学习速度：默认为0.1。
   - 类别数量：分类任务的类别数。
   - 特征数量：输入数据特征数+1。
   - 特征下采样比例：取值范围（0,1），为1时默认不采样。
   - 多分类策略：多分类训练策略，one-tree（一轮一棵树）或者 multi-tree（一轮多棵树），多分类时可选每轮建单棵树或多棵树（其中多棵树的输的个数是指类别个数）。
   - 树节点上训练数据的最少个数：每个树节点上最少的样本数。
   - 最大叶子权重：为0时表示无限制。
   - 节点最小权重：节点最小的权重。
   - 最小分裂损失：效果同 xgboost 中的 gamma。

- 资源参数
   - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
   - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
   - drive 节点资源类型：请选择合适的 drive 节点机型。
   - executor 节点资源类型：请选择合适的 executor 节点机型。
   - master 节点资源类型：请选择合适的 master 节点机型。
   - ps 节点资源类型：请选择合适的 ps 节点机型。
   - spark conf 参数
      - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
      - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

- **预测节点**
- 模型 IO 参数和模型参数。
   - 预测数据路径：预测数据输入 cos 路径。
   - 预测结果保存地址：预测结果保存 cos 路径。
  
- 资源参数：与训练节点意义相同。

#### 本算子主要解决二分类或者多分类的问题

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/72bba56adaf3ab17f42b99a00cc73cfc.png)
- 训练完成后模型保存路径下会生成特征重要度文件和分类模型文件。
![](https://main.qcloudimg.com/raw/b3dc08cccde010592e64d9cfd1defc5f.png)
- 使用分类模型进行新的数据预测，得到分类结果，分类结果形式为：原始 label 预测 score 值。
![](https://main.qcloudimg.com/raw/f0b92516231255e444af13a555ef439d.png)

## [Angel]FTRL-LR on SONA 

#### 算法简介

FTRL 是一种在线优化算法，这种优化算法不光更能适应海量数据的要求，同时还能比较轻松的学习到一个有效且稀疏的模型，自问世以来在学术界和工业界都倍受关注和好评。
我们在 Spark on Angel 平台实现了以 FTRL 进行优化的分布式 LR 算法。

#### 参数说明

- **输入数据格式**
目前支持“libsvm”、“dummy”两种数据格式，分别如下所示：

```
libsvm格式: label index:value index:value index:value ......
dummy格式: index,index,index,......
```

>!libsvm 格式的 index 是从1开始的，以空格分隔；dummy 格式的 index 是从0开始的，以逗号分隔。

- **训练节点**
- 算法 IO 参数
   - 数据的输入路径：训练数据存储 cos 路径。 
   - 输入数据的维度：数据特征个数（最大的 featureID 值+1）。
   - 迭代轮数：模型训练迭代的轮数。
   - batchSize：每个 batch 的样本数。
   - 模型加载地址：预训练的模型加载路径，cos 路径。
   - 任务类型：训练。
   - 输入数据格式：libsvm 或者 dummy。

>!带预测的算子模块模型保存路径不需要用户填写，平台会自动生成。

- 算法参数  
   - alpha：w 更新公式中的 alpha。
   - beta：w 更新公式中的 beta。
   - lambda1：w 更新公式中的 lambda1。
   - lambda2：w 更新公式中的 lambda2。

- 资源参数
   - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
   - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
   - drive 节点资源类型：请选择合适的 drive 节点机型。
   - executor 节点资源类型：请选择合适的 executor 节点机型。
   - master 节点资源类型：请选择合适的 master 节点机型。
   - ps 节点资源类型：请选择合适的 ps 节点机型。
   - spark conf 参数
     - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
     - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

- **预测节点**
- 模型 IO 参数
   - 输入数据的维度：数据特征个数（最大的 featureID 值+1）。
   - 数据的输入数据：预测数据输入路径，cos 路径。
   - 预测结果保存路径：预测结果保存路径，cos 路径。
   - 输入数据格式：libsvm 或者 dummy。
   - 数据是否有标签：预测数据是否带标签，true 或者 false。
   - 任务类型：预测。
 
- 资源参数：与训练节点意义相同。

#### 本算子主要解决了二分类问题

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/ad7847aa5000450ffc05aa11a73b83e3.png)
- 训练完成后模型保存路径下会生成分类模型。
![](https://main.qcloudimg.com/raw/c69b105cbcf1952e9df8938a759f51c9.png)
- 使用分类模型进行新的数据预测，得到分类结果，分类结果展示的是每个样本属于 label 类的概率。
![](https://main.qcloudimg.com/raw/4142c358bb569542f7f96d24831400ae.png)

## [Angel]FTRL-FM on SONA 

#### 算法简介

FTRL 是一种在线优化算法，这种优化算法不光更能适应海量数据的要求，同时还能比较轻松的学习到一个有效且稀疏的模型，自问世以来在学术界和工业界都倍受关注和好评。
我们在 Spark on Angel 平台实现了以 FTRL 进行优化的分布式 FM 算法。

#### 参数说明

- **输入数据格式**
目前支持 libsvm、dummy 两种数据格式，分别如下所示：

```
libsvm格式: label index:value index:value index:value ......
dummy格式: index,index,index,......
```

>!libsvm 格式的 index 是从1开始的，以空格分隔；dummy 格式的 index 是从0开始的，以逗号分隔。

- **训练节点**
- 算法 IO 参数
   - 数据的输入路径：训练数据存储 cos 路径。 
   - 输入数据的维度：数据特征个数（最大的 featureID 值+1）。
   - 迭代轮数：模型训练迭代的轮数。
   - batchSize：每个 batch 的样本数。
   - 模型加载地址：预训练的模型加载路径，cos 路径（如果没有预训练的模型，则为空）。
   - 任务类型：训练。
   - 输入数据格式：libsvm 或者 dummy。
 
>!带预测的算子模块模型保存路径不需要用户填写，平台会自动生成。

- 算法参数  
    - alpha：w 更新公式中的 alpha。
    - beta：w 更新公式中的 beta。
    - lambda1：w 更新公式中的 lambda1。
    - lambda2：w 更新公式中的 lambda2。
    - 因子数：因子分解超参。

- 资源参数
   - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
   - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
   - drive 节点资源类型：请选择合适的 drive 节点机型。
   - executor 节点资源类型：请选择合适的 executor 节点机型。
   - master 节点资源类型：请选择合适的 master 节点机型。
   - ps 节点资源类型：请选择合适的 ps 节点机型。
   - spark conf 参数
      - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
      - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

- **预测节点**
- 模型 IO 参数
   - 输入数据的维度：数据特征个数（最大的 featureID 值+1）。
   - 数据的输入数据：预测数据输入路径，cos 路径。
   - 预测结果保存路径：预测结果保存路径，cos 路径。
   - 输入数据格式：libsvm 或者 dummy。
   - 数据是否有标签：预测数据是否带标签，true 或者 false。
   - 任务类型：预测。
 
- 资源参数：与训练节点意义相同。

#### 本算子主要解决了二分类问题

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/ad7847aa5000450ffc05aa11a73b83e3.png)
- 训练完成后模型保存路径下会生成分类模型。
![](https://main.qcloudimg.com/raw/545cd778c054c25df1342cecc0118a8f.png)
- 使用分类模型进行新的数据预测，得到分类结果，分类结果展示的是每个样本属于 label 类的概率。
![](https://main.qcloudimg.com/raw/4142c358bb569542f7f96d24831400ae.png)
