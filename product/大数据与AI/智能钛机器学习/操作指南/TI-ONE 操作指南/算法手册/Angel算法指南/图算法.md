## [Angel]Closeness on SONA 
#### 算法简介
紧密中心度算法（Closeness Centrality）计算一个节点到所有其他可达节点的最短距离的倒数，进行累积后归一化的值。紧密中心度可以用来衡量信息从该节点传输到其他节点的时间长短。
节点的 Closeness Centrality 越小，其在所在图中的位置越靠近中心。紧密中心度算法（Closeness Centrality）适用于社交网络中关键节点挖掘等场景。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：

```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的 COS 路径，每行一条边。
  - 结果输出路径：输出结果保存 COS 路径。
  - 分区数：Spark RDD 的分区数量。
  - srcIndex：输入数据的源顶点列下标，0是第一列，默认为0。
  - dstIndex：输入数据的目标顶点列下标，默认为1。
  - PS分区个数：参数服务器模型的分区数量。
  - 分隔符：每条边的起始顶点、目标顶点以及权重列之间的分隔符：tab，空格等。
  - 输出额外信息：是否输出节点 cardinality 及以半径加权求和的 cardinality，true or false。
- **算法参数**
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - 均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否。
  - 精度：HyperLogLog counter 的精度（≥4）。精度会以指数形式影响算法性能，建议在资源允许的情况下尽量设为10。
  - 分批向 PS 更新数值的批数：每个 worker 分批向参数服务器传输数值更新的批次。
  - 图的类型：无向图或者有向图。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 ps 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决了网络中节点的重要性评价的问题
- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/3ce3ed12cb198529048beaae4a4434a7.png)
- 运行算子后得到的结果输出格式为 nodeId(long) | closeness(float) | 节点 cardinality | 半径加权求和的 cardinality， closeness 值越大表示节点越重要。
![](https://main.qcloudimg.com/raw/b815b9b1ee4eb1689c591df4e4ece269.png)

## [Angel]Common Friends on SONA

#### 算法简介
计算顶点与它的直接（一度）邻居之间的共同邻居数量。在社交网络中，可以全量计算网络中每个顶点的共同好友数量，也可以输入多对不存在好友关系的顶点对，计算这些顶点之间的共同好友数量。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，每条边由起始顶点和终止顶点标识，如下所示：

```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

- **算法 IO 参数**
  - 所有好友边：输入的边表所在的 COS 路径，每行一条边，每条边由起始顶点和终止顶点标识。
  - 需要计算的好友边：需要计算共同好友的顶点对（边）COS 路径，每行一条。
  - 结果输出路径：输出结果保存 COS 路径。
  - 数据分隔符：每条边的起始顶点和终止顶点之间的分隔符：tab，空格等。
  - checkpoint路径：模型的 checkpoint 保存 COS 路径。
  - RDD存储级别：`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
- **算法参数**
  - 分区数量：Spark RDD 的分区数量。
  - 参数服务器分区数量：参数服务器模型的分区数量。
  - 数据中源顶点的列：输入数据的源顶点列下标，0是第一列，默认为0。
  - 数据中目标顶点的列： 输入数据的目标顶点列下标，默认为1。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 ps 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决了计算两个好友的共同好友数的问题，某种程度上可以刻画两个节点之间的紧密程度

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/89b9e23ea4f013e81d89a0215b81b976.png)
- 运行算子后得到的结果输出格式为输出的格式为 srcId(long) | dstId(long) | count(int)。
![](https://main.qcloudimg.com/raw/66a5a2ce09cc13e2f0c11ce274c7cb4a.png)

## [Angel]FastUnfolding on SONA 

#### 算法简介
模块度成为度量社区划分优劣的重要标准，划分后的网络模块度值越大，说明社区划分的效果越好，Fast Unfolding 算法便是基于模块度对社区划分的算法。Fast Unfolding 算法是一种迭代的算法，主要目标是不断划分社区使得划分后的整个网络的模块度不断增大。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：
 
```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的 COS 路径，每行一条边。
  - 输出路径：输出结果保存 COS 路径。
  - checkpoint 路径：模型的 checkpoint 保存 COS 路径。
  - srcIndex：输入数据的源顶点列下标，0是第一列，默认为0。
  - dstIndex：输入数据的目标顶点列下标，默认为1。
  - 输入数据分隔符：每条边的起始顶点、目标顶点之间的分隔符：tab，空格等。
  - 是否带权：边是否带权重。
  - weightIndex：输入数据边的权重列下标，默认为2。
- **算法参数**
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - 数据分区数：Spark RDD 分区数目。
  - psPartitionNum：参数服务器模型的分区数量。
  - batchSize：每个 batch 数据大小。
  - numFold：折叠次数。
  - numOpt：每轮模块度优化次数。
  - eps：每次模块度优化提升下界。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决了社团发现的问题，目标是从图数据中挖掘节点之间的社群属性

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/874e20c893c0be022ed9b2a56bda37de.png)
- 运行算子后得到的结果输出的格式为 nodeId(long) | communityId(long)，communityId 一致表示属于同一个社区，编号不连续。
![](https://main.qcloudimg.com/raw/111beef2d49b6345605acf36ff47fc0b.png)

## [Angel]Kcore on SONA 

#### 算法简介
对输入的网络数据，获得每个节点的 coreness。Kcore 算法的最直观解释是剥洋葱，即首先将网络中度为1的节点剥离，
此时剩余的网络中可能会产生新的度为1的节点，再依次剥离，直到剩余的网络中所有节点的度都大于等于2。 那么之前被剥离的节点的 coreness 即为1。

之后再依次剥离得到 coreness 为2，3，...，n 的节点，直到网络中所有的节点都得到对应的 coreness。实际的分布式实现没有这么朴素，请参考论文 [Distributed k-Core Decomposition](https://arxiv.org/pdf/1103.5320.pdf)。coreness 越大表示节点属于越中心的位置，从而也越重要。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，每条边由起始顶点和终止顶点标识，如下所示：

```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的 COS 路径，每行一条边。
  - srcIndex：输入数据的源顶点列下标，0是第一列，默认为0。
  - dstIndex: 输入数据的目标顶点列下标，默认为1。
  - 输入数据分隔符：每条边的起始顶点、目标顶点之间的分隔符：tab，空格等
  - 输出路径：输出结果保存 COS 路径。
  - checkpoint 路径：模型的 checkpoint 保存 COS 路径。
- **算法参数**
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - 数据分区数：Spark RDD 分区数目。
  - ps 分区数：参数服务器模型的分区数量。
  - 是否使用均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决了网络中节点的重要性评价的问题
- 原始数据如下图所示：
  ![](https://main.qcloudimg.com/raw/28b7fdf06b4d1518c9febcbc3803bc85.png)
- 运行算子后得到的结果输出格式为 nodeId(long) | coreness(int)，coreness 值越大表示节点越重要。
  ![](https://main.qcloudimg.com/raw/37d76553da5c7bd155e89132c6eb9325.png)

## [Angel]LINE_V2 on SONA 

#### 算法简介
LINE [Large-scale Information Network Embedding](https://arxiv.org/abs/1503.03578) 算法，Network Embedding 领域著名的算法之一，重点在于设计了两个目标函数，分别刻画节点之间的一阶相似性（直接连边）和二阶相似性（相似邻居）。

#### 参数说明
- **输入数据格式**
无向图，节点需要从0开始连续编号，以空白符或者逗号分隔，如下所示：

```
0    2
2    1
3    1
3    2
4    1
... ...
... ...
```

- **算法 IO 参数**
  - 训练数据：训练数据所在的 COS 路径。
  - remapping：是否对节点 ID 进行重新映射。
  - 模型保存路径：训练结果保存 COS 路径。
- **算法参数**
  - Embedding 特征的维度：Embedding 向量的维度，是 ps 分区数的倍数。
  - ps 分区数：参数服务器模型的分区数量。
  - 负采样数：负采样节点个数。
  - 学习率：初始学习率。
  - BatchSize：每个 mini batch 数据大小。
  - 最大 epoch 数：最大迭代轮数。
  - Order：一阶或者二阶的 LINE。
  - subSample：是否对训练数据进行采样。
  - 每隔多少个 epoch 保存一次模型：每隔多少个 epoch 保存一次模型。
  - 每隔多少轮做一次 checkpoint：每隔多少轮做一次 checkpoint。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决了将难以处理的图数据转换为易于处理的向量型数据（将高维的图数据嵌入到低维的向量空间）的问题

- 原始数据如下图所示：
  ![](https://main.qcloudimg.com/raw/874e20c893c0be022ed9b2a56bda37de.png)
- 运行算子后得到的结果有节点向量文件和节点 ID 映射文件。
- ID 映射文件格式为：映射后的节点 ID：原节点 ID。
  ![](https://main.qcloudimg.com/raw/cd1533ea89061d44776399184f6eb8ea.png)
- 词向量文件格式为：映射后的节点 ID：节点向量。
  ![](https://main.qcloudimg.com/raw/479e4d760f7f97b23693cf528cc3dd00.png)

## [Angel]PageRank on SONA 

#### 算法简介
PageRank 算法可能是最著名的节点重要性评价算法，最初由拉里佩奇提出，被应用于 Google 搜索的网页排名。 详细算法细节参考论文 [The PageRank Citation Ranking:Bringing Order to the Web](http://ilpubs.stanford.edu:8090/422/1/1999-66.pdf)。

#### 参数说明
- **输入数据格式**
  边表形式，每行一条边，分为带权重和不带权重两种形式，如下所示：

```
边不带权重
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...

边带权重
srcId 分隔符 dstId 分隔符 weight
srcId 分隔符 dstId 分隔符 weight
... ... ...
... ... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的 COS 路径，每行一条边。
  - 结果输出路径：输出结果保存 COS 路径。
  - 分区数：Spark RDD 的分区数量。
  - srcIndex：输入数据的源顶点列下标，0是第一列，默认为0。
  - dstIndex：输入数据的目标顶点列下标，默认为1。
  - weightIndex：输入数据边的权重列下标，默认为2。
  - PS 分区个数：参数服务器模型的分区数量。
  - 分隔符：每条边的起始顶点、目标顶点以及权重列之间的分隔符：tab、空格等。
- **算法参数**
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
  - 均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否。
  - 均衡划分比例：0 - 1之间的浮点数，节点索引越不均衡，该值越小，建议0.7。
  - tolerance：停止进行消息更新的精度阈值。
  - 重定向概率：重定向概率。
  - 是否带权：边是否带权重。
  - 版本：图的切割方式，点切或者边切。
  - 存储时分批次数：存储时的分批次数。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决了网络中节点的重要性评价的问题

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/b40581907fad92cd0ef9d349065706e0.png)
- 运行算子后得到的结果输出格式为 nodeId(long) | rank(float)，rank 值越大表示节点越重要。
![](https://main.qcloudimg.com/raw/8b6f420c1c25d3250c876648648812b4.png)

## [Angel]Hindex on SONA 

#### 算法简介
HIndex 算法是计算一个节点 h-index 指数的算法。在一个 graph 中，一个节点的 h-index 值为 h 时，表示该节点至少有 h 个邻居的度大于或等于 h，通常来说，h-index 值越高，表明该节点的影响力越大，适用于社交网络中关键节点挖掘等场景。

#### 参数说明
- **输入数据格式**
边表形式，每行一条边，如下所示：

```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的边表所在的 COS 路径，每行一条边。
  - 出发节点所在列：输入数据的源顶点列下标，0是第一列，默认为0。
  - 目标节点所在列：输入数据的目标顶点列下标，默认为1。
  - 输入数据分隔符：每条边的起始顶点、目标顶点以及权重列之间的分隔符：`tab`，`空格`等。
  - 输出路径：输出结果保存 COS 路径。
- **算法参数**
  - 数据分区数：Spark RDD 数据的分区数量。
  - ps 分区数：参数服务器上模型的分区数量。
  - 是否使用均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否
  - storageLevel：RDD 存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`。
- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决了网络中节点的重要性评价的问题

- 原始数据如下图所示：
<img src="https://main.qcloudimg.com/raw/1f07ffa80157106afa88b1ad8f80dd78.png" style="zoom:50%;" />
- 运行算子后得到的结果输出格式为 nodeId(long) | HIndex值(Int) | GIndex值(Int) | WIndex值(Int)，index 值越大表示节点越重要
- [GIndex](https://en.wikipedia.org/wiki/G-index) 和 WIndex 值是与 hindex 相近的指标，可自行查阅了解。
![](https://main.qcloudimg.com/raw/5c81bdbb8880b3df1fc150386d0c3785.png)

## [Angel]LPA on SONA 

#### 算法简介
LPA 是一种基于标签传播的局部社区划分。对于网络中的每一个节点，在初始阶段，Label Propagation 算法对于每一个节点都会初始化一个唯一的一个标签。 
每一次迭代都会根据与自己相连的节点所属的标签改变自己的标签，更改的原则是选择与其相连的节点中所属标签最多的社区标签为自己的社区标签，这就是标签传播的含义了。随着社区标签不断传播。最终，连接紧密的节点将有共同的标签。

#### 参数说明

- **输入数据格式**
边表形式，每行一条边，如下所示：

```
srcId 分隔符 dstId
srcId 分隔符 dstId
... ...
... ...
```

- **算法 IO 参数**
  - 边输入路径：输入的-表所在的 COS 路径，每行一条边。
  - 出发节点所在列：输入数据的源顶点列下标，0是第一列，默认为0。
  - 目标节点所在列：输入数据的目标顶点列下标，默认为1。
  - 输入数据分隔符：每条边的起始顶点、目标顶点之间的分隔符: `tab`，`空格`等。
  - 输出路径：输出结果保存 COS 路径。
 - checkpoint 路径：模型的 checkpoint 保存 COS 路径。

- **算法参数**
  - storageLevel：RDD存储级别，`DISK_ONLY`/`MEMORY_ONLY`/`MEMORY_AND_DISK`
  - 数据分区数：Spark RDD 分区数目。
  - ps 分区数：参数服务器上模型的分区数量。
  - 是否使用均衡分区：参数服务器对输入数据节点存储划分是否均衡分区，如果输入节点的索引不是均匀的话建议选择否。

- **spark conf 参数**
  - spark.angel.tmp.output.path.prefix：Angel 临时目录的前缀路径，为 COS 路径。
  - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

- **资源参数**
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - executor-memory(g)：每个 executor 需要的内存，单位为 g。
  - executor-cores：每个 executor 需要的 CPU 核数。
  - driver-memory(g)：spark driver 需要的内存，单位为 g。
  - spark.ps.instances：angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - spark.ps.cores：每个 angel ps 需要的核数。
  - spark.ps.memory(g)：每个 angel ps 需要的内存，单位为 g。

#### 本算子主要解决了社团发现的问题，目标是从图数据中挖掘节点之间的社群属性

- 原始数据如下图所示：
<img src="https://main.qcloudimg.com/raw/1f07ffa80157106afa88b1ad8f80dd78.png" style="zoom:50%;" />
- 运行算子后得到的结果输出的格式为 nodeId(long) | communityId(long)、communityId 一致表示属于同一个社区，编号不连续。
![](https://main.qcloudimg.com/raw/3c75f4f96a1d3a0c2b6fd667ec9bbb1d.png)

## [Angel]GraphSage_Supervised 

#### 算法简介
GraphSAGE 全称是 Graph SAmple and aggreGate，由斯坦福大学提出，该算法旨在从图网络中学习出节点的特征表示，并以此为理论基础，斯坦福和 Pinterest 公司合作提出了第一个工业级别（数十亿节点和数百亿边）基于 GCN 的推荐系统，并在离线评估和 AB 实验选中取得了不错的效果。
Pytorch on Angel 为运行图卷积神经网络算法提供了能力。 我们遵循 [Pytorch-Geometric](https://github.com/rusty1s/pytorch_geometric)  来定义图卷积神经网络同时使用 Angel 参数服务器来存储网络结构及节点特征。

#### 参数说明

- **输入数据格式**
有三个输入需要准备：边表，节点特征表和节点标签表。  
边表：是一个文件或者路径，每一行是一条边，由源点和终点组成，中间以空格分开，每个节点被编码成一个 long 型数值。
特征表：是一个文件或者路径，每一行包含节点 ID 和节点特征，节点的特征支持稀疏和稠密两种格式。 
对于稀疏格式，每一行的格式如下：

```
node\tf1:v1 f2:v2 f3:v3
```

由于空格是特征内部之间的间隔符，因此节点与特征之间的间隔是 tab。
对于稠密格式如下：

```
node\tv1 v2 v3
```

标签表：是一个文件或路径，每一行包含节点 ID 和标签，并以空格间隔。由于该版本 graphsage 是半监督模型，因此标签数据可以不包含全部节点的标签。
>!图中出现的每一个点，在特征表中都需要有相应的特征。

- **算法 IO 参数**
  - 边路径：边数据的存储 COS 路径。
  - 特征路径：特征数据的存储 COS 路径。
  - 标签路径：标签数据的存储 COS 路径。
  - 预测值输出路径：预测值输出路径。
  - embedding 输出路径：表示向量输出路径。
  - 模型输出路径：模型保存路径。
  - 验证标签路径：验证集标签数据的存储 COS 路径，为空时表示不使用额外的验证集。

- **算法参数**  
  - batchSize：每个 batch 的样本数。
  - 学习率：算法学习率。
  - 数据分区数：数据分区个数。
  - ps 分区数：ps 分区数，只有在使用`均衡分区`时才会生效。
  - 均衡分区：是否使用 ps 均衡分区，为 true（是）表示使用 ps 均衡分区，此时设置的`ps分区数`才会生效，否则表示不使用，默认情况下为 false（否）。
  - epoch：模型训练迭代的轮数。
  - 验证集比例：当`验证标签路径`为空时，使用验证集比例对输入数据进行划分，一部分做训练，一部分做验证；当`验证标签路径`不为空时，该值将不起作用。
  - 特征格式：稠密，稀疏。
  - 采样邻居个数：每阶采样的邻居的个数。
  - RDD 存储级别：可选 MEMORY_ONLY、DISK_ONLY、MEMORY_AND_DISK。
  - 初始化特征分批次数：ps 分批初始化时的分批次数    。
  - Pytorch模型文件：用户使用 Python 脚本生成的 Pytorch 脚本模型。

用户需在自己本地安装-pytorch(1.3.1版本)，然后到 [python/graph](https://github.com/Angel-ML/PyTorch-On-Angel/tree/branch-0.2.0/python/graph) 下载算法文件 graphsage.py，执行如下命令生成可用于分布式训练的 Pytorch 模型文件：

```
 python graphsage.py --input_dim 602 --hidden_dim 128 --output_dim 41 --output_file sage_reddit_1.3.pt
```

其中，input_dim 为节点特征的维度，hidden_dim 为中间隐藏层的维度，output_dim 为类别数，output_file 是指生成脚本文件的名称，以'.pt'结尾，该名称可自己指定。该脚本是使用 [TorchScript](https://pytorch.org/docs/stable/jit.html) 生成的一个生成一个模型文件，其中包含 graphsage 的数据流图，生成的 pt 文件上传到自己的 COS 存储路径。

- 特征维度：输入数据节点特征的维度。
- 任务类型：训练，预测。
- 保存模型的周期 epoch 数：每隔多少 epoch 保存一次模型。
- 学习率衰减系数：学习率衰减参数。
- 评估指标：可选择 acc，binary_acc（二分类场景），auc，recall，precision，f1-score，rmse 等。
- 验证周期数：每隔 X 轮验证一次。


- **资源参数**
- num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
  - spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决的问题是学习网络图中节点的 embedding 向量

- 原始数据如下图所示：  
边数据
![](https://main.qcloudimg.com/raw/e5cad667f7c28e20ddc5ddfbfeece2b5.png)
特征数据
![](https://main.qcloudimg.com/raw/d7ca724c7f427ab584db49e6aadaf907.png)
标签数据
![](https://main.qcloudimg.com/raw/4fe43f257a60d8f78f059d6215ed6a69.png)
- 训练完成后会得到每个节点的 embedding 向量
 ![](https://main.qcloudimg.com/raw/00582394af613db76c500e9e630387ef.png)



## [Angel]Word2Vec on SONA 

#### 算法简介
Word2Vec 将文本中的词语映射到 k 维向量空间中，同时向量空间上的相似度可以用来表示词语语义上的相似度。

#### 参数说明
- **输入数据格式**
文档，每行一个句子（单词或者节点 ID），如下所示：

```
word1 word2 word3 ...
word4 word5 word6 ...
... ...
... ...
```

- 算法 IO 参数
  - 训练数据：训练数据所在的 COS 路径。
  - 模型保存路径：训练结果保存 COS 路径。
  - 模型加载路径：增量训练需要。

- 算法参数
  - Embedding 特征的维度：embedding 向量的维度。
  - ps 分区数：参数服务器模型的分区数量。
  - RDD 数据分区数：训练数据的分区数。
  - 负采样数：负采样节点个数。
  - 窗口大小：滑动窗口大小。
  - 最大 epoch 数：最大迭代轮数。
  - BatchSize：每个 mini batch 数据大小。
  - 学习率：初始学习率。
  - 学习率衰减率：学习率衰减率系数。
  - 每隔多少个 epoch 保存一次模型：您可按需设置。
  - 每隔多少轮做一次 checkpoint：您可按需设置。
  - 是否对数据进行采样操作：是否对训练数据进行采样。
  - 是否进行 ID 重映射：是否进行 ID 重映射，如果是单词需要重映射到 ID。
  - RDD 存储级别：选择 RDD 存储级别，DISK_ONLY、MEMORY_ONLY、MEMORY_AND_DISK。

- 资源参数
  - num-executors：任务启动的 spark executor 个数，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
  - spark.ps.instances：Angel ps 个数，可根据模型大小来配置，一般模型越大，需要的 PS 个数越多。
  - drive 节点资源类型：请选择合适的 drive 节点机型。
  - executor 节点资源类型：请选择合适的 executor 节点机型。
  - master 节点资源类型：请选择合适的 master 节点机型。
  - ps 节点资源类型：请选择合适的 ps 节点机型。
 -  spark conf 参数
    - spark.angel.tmp.output.path.prefix：angel 临时目录的前缀路径，为 COS 路径。
    - saprk.angel.output.path.deleteonexist：为了防止误删除模型，默认不自动删除模型输出路径的文件。如果需要，可设置为 true。

#### 本算子主要解决了词表示学习的问题，将高维稀疏的词表示嵌入到低维的向量空间

- 原始数据如下图所示：
![](https://main.qcloudimg.com/raw/bf974d864bd04a00ad2188d8f2862081.png)
-  运行算子后得到的结果有词向量文件和词映射文件。
- 词映射文件格式为：映射后的 ID：原单词。
![](https://main.qcloudimg.com/raw/bba3fde3f3eddfd71b8ce0612f65633e.png)
- 词向量文件格式为：映射后的 ID：词向量。
![](https://main.qcloudimg.com/raw/623fbd29687f8e4d117d87b5ee1f086f.png)
