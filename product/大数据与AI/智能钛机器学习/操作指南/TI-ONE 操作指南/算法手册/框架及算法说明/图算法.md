## [2.0]HyperAnf
估计网络的平均半径，参考论文 [HyperANF: Approximating the Neighbourhood Function of Very Large Graphs on a Budget](https://arxiv.org/pdf/1011.5599.pdf) 开发，详细细节请看论文。

#### 输入
- 输入数据路径：输入文件所在路径，无权网络数据, 数据格式为两列 `srcId(long) | dstId(long)`, 其中`|`为分隔符，分隔字段表示空白符或者逗号等。
- 输入文件类型：格式包括以下两种：
  - csv：csv 文件。
    - 输入数据包含 header 信息。
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。

#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下两种：
  - csv：csv 文件。
    - 输出数据包含 header 信息。
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。

 >算法结果保存路径，共两列，其中第一列为 round 值，第二列为 anf 值，其中round = -1对应的 anf 为最终估计值。

**参数说明**

- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。
- maxIter：最大迭代次数。

**资源参数**

* drive 节点资源类型：请选择合适的 drive 节点机型。
* executor 节点资源类型：请选择合适的 executor 节点机型。
* num-executors：分配计算节点数目，可根据数据量来配置，一般训练数据量越大，需要的 worker 个数越多。
* spark-conf：spark常用参数配置，如压缩、序列化、网络等。

## [2.0]LPA
LPA（Label Propagation Algorithm）是最简单的社区发现算法，通过标签扩散发掘网络的社区关系。
#### 输入
- 输入数据路径：输入文件所在路径。
- 输入文件类型：格式包括以下两种：
  - csv：csv 文件。
    - 输入数据包含 header 信息。
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。

#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下两种：
  - csv：csv 文件。
    - 输出数据包含 header 信息。
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。
  
 > 算法结果保存路径，共两列，其中第一列为节点 ID，第二列为节点对应的社区 ID。社区 ID 相同表示属于同一个社区。

**资源参数**
- num-executors：使用多少个 Spark 节点。
- driver-memory：Spark driver 的内存大小。
- executor-cores：每个 Spark 节点使用多少个 core。
- executor-memory：每个 Spark 节点使用的内存大小。
- spark-conf：Spark 的其他参数。 由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=用户名：密码。

#### 参数说明
- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。

## [2.0]EffectiveSize
EffectiveSize 是由结构空洞理论得到的网络度量指标，是 ego-network 中节点的重要衡量指标。

#### 输入
- 输入数据路径：输入文件所在路径。
- 输入文件类型：格式包括以下两种：
  - csv：csv 文件。
    - 输入数据包含 header 信息。
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - text：本文件。
  - parquet：列式存储格式 parquet。

#### 输出
- 输出数据路径：输出文件所在路径。
- 输出数据格式：格式包括以下两种：
  - csv：csv 文件。
    - 输出数据包含 header 信息
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符。
  - parquet：列式存储格式 parquet。
  > 算法结果保存路径，共三列，其中第一列为节点 ID，第二列为 effectiveSize 值，第三列为 redundancyCol 值。

**资源参数**
- num-executors：使用多少个 Spark 节点。
- driver-memory：Spark driver 的内存大小。
- executor-cores：每个 Spark 节点使用多少个 core。
- executor-memory：每个Spark节点使用的内存大小。
- spark-conf：Spark的其他参数。由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=用户名：密码。

#### 参数说明
- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。

## Angel 算法相关
Angel 算法相关内容请参考以下文档：
- [[Angel]Closeness on SONA](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dcloseness-on-sona)
- [[Angel]Common Friends on SONA](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dcommon-friends-on-sona)
- [[Angel]FastUnfolding on SONA ](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dfastunfolding-on-sona)
- [[Angel]Kcore on SONA](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dkcore-on-sona)
- [[Angel]LINE_V2 on SONA](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dline_v2-on-sona)
- [[Angel]PageRank on SONA](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dpagerank-on-sona)
- [[Angel]HIndex on SonA ](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dhindex-on-sona)
- [[Angel]LPA on SONA](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dlpa-on-sona)
- [[Angel]GraphSage_Supervised ](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dkcore-on-sona)
- [[Angel]Word2Vec on SONA](https://cloud.tencent.com/document/product/851/44040#.5Bangel.5Dword2vec-on-sona)

