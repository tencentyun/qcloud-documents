
## R-FCN 目标检测

分类需要特征具有平移不变性，检测则要求对目标的平移做出准确响应。现在的大部分 CNN 在分类上可以做的很好，但用在检测上效果不佳。SPP、Faster R-CNN 类的方法在 ROI pooling 前都是卷积，是具备平移不变性的，但一旦插入 ROI pooling 后，后面的网络结构就不再具备平移不变性了。因此，RFCN 提出来的 Position Sensitive Score Map 可以将目标的位置信息融合进 ROI pooling。

#### 算法 IO 参数

- 配置文件：配置模型具体结构的文件，可参考 [结果文件](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)。
- 训练数据输入：训练数据，tfrecord 形式，可由图像切分转换算子生成。
- 验证数据输入：验证数据，tfrecord 形式，可由图像切分转换算子生成。
- 标签类别映射：表明类别名和 ID 对应关系的文件，可由图像切分转换算子生成。
- 初始模型：选填，用于 finetune 的预训练模型。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。

#### 算法参数
- 类别个数：目标检测任务中需要检测的类别个数。
- 训练步数：训练的总步数。

#### 模型 IO 参数
- 配置文件：同算法 IO 参数。
- 数据输入：tfrecord 形式，可由图像切分转换算子生成。
- 标签类别映射：表明类别名和 ID 对应关系的文件，可由图像切分转换算子生成。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。

#### 模型参数
类别个数：目标检测任务中需要检测的类别个数。

## SSD 目标检测

SSD 算法是一种直接预测 bounding box 的坐标和类别的 object detection 算法，没有生成 proposal 的过程，即一阶段算法。SSD 主要特点在于采用了特征融合，详情请参见下文算法示例。

#### 算法 IO 参数
- 配置文件：配置模型具体结构的文件，可参考 [结构文件](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs) 。
- 训练数据输入：训练数据，tfrecord 形式，可由图像切分转换算子生成。
- 验证数据输入：验证数据，tfrecord 形式，可由图像切分转换算子生成。
- 标签类别映射：表明类别名和 ID 对应关系的文件，可由图像切分转换算子生成。
- 初始模型：选填，用于 finetune 的预训练模型。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。

#### 算法参数
- 类别个数：目标检测任务中需要检测的类别个数。
- 训练步数：训练的总步数。

#### 模型 IO 参数

- 配置文件：同算法 IO 参数。
- 数据输入：tfrecord 形式，可由图像切分转换算子生成。
- 标签类别映射：表明类别名和 ID 对应关系的文件，可由图像切分转换算子生成。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。

#### 模型参数
类别个数：目标检测任务中需要检测的类别个数。

## Faster RCNN 目标检测
Faster RCNN 是继 RCNN 和 Fast RCCN 之后的改进网络。Faster RCNN  是两阶段目标检测算法。第一阶段：提出区域建议网络 RPN，快速生成候选区域。第二阶段：通过交替训练，使 RPN 和 Fast-RCNN 网络共享参数。详情请参见下文的算法示例。

#### 算法 IO 参数
- 配置文件：配置模型具体结构的文件，可参考 [结构文件](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs) 。
- 训练数据输入：训练数据，tfrecord 形式，可由图像切分转换算子生成。
- 验证数据输入：验证数据，tfrecord 形式，可由图像切分转换算子生成。
- 标签类别映射：表明类别名和 ID 对应关系的文件，可由图像切分转换算子生成。
- 初始模型：选填，用于 finetune 的预训练模型。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。

#### 算法参数
- 类别个数：目标检测任务中需要检测的类别个数。
- 训练步数：训练的总步数。

#### 模型 IO 参数
- 配置文件：同算法 IO 参数。
- 数据输入：tfrecord 形式，可由图像切分转换算子生成。
- 标签类别映射：表明类别名和 ID 对应关系的文件，可由图像切分转换算子生成。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。

#### 模型参数
类别个数：目标检测任务中需要检测的类别个数。

## Inception 图片分类
从原理上来说更深和更宽的卷积神经网络具有更强的表征能力，但纯粹增大网络的缺点也显而易见，包括参数太多带来的复杂度太大，容易过拟合和梯度弥散等。Inception 的出现就是为了解决如何在增加网络深度和宽度的同时减小网络参数的问题。最开始的 inception 网络由一个个的 Inception 模块堆叠而成，inception 模块由1 x 1、3 x 3、5 x 5的卷积和3 x 3的 pooling 堆叠，一方面增加了网络的 width，另一方面也增加了网络对尺度的适应性。Inception 网络经过多次迭代和更新已经形成了四个版本，分别为 V1、V2、V3 和 V4。在 TI 的 Inception 模块中可以选择不同版本进行训练。

#### 算法 IO 参数
- 训练数据输入：用于训练的 tfrecord 数据，可以使用【输入】>【数据转换】>【图像切分转换】算子生成。
- 验证数据输入：用于模型训练时的验证数据，与训练集格式一致。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。 
- label_map 文件所在目录：记录标签和 ID 对应关系的 label_map.txt 文件所在目录。可以使用【输入】>【数据转换】>【图像切分转换】算子生成。 

#### 算法参数
- 模型名称：要使用的 Inception 版本。
- 学习率：训练过程的初始学习率。
- batch_size：训练过程中的 batch_size。
- 训练步数：训练过程的总迭代次数。
- 是否模型微调：支持在已有的训练好的模型上进行微调（通常用于迁移学习），如选“是”请在下方填写完整模型路径，并选择是否仅训练全连接层 。
- 优化器：用于优化模型参数的优化算法。

#### 模型 IO 参数
- 预测数据输入：包含要预测的图片的目录。如果要预测的图片有标签，则将对应类别的图片放在以标签名命名的目录下；如果要预测的图片无标签，则将所有要预测的图片全部放在该目录下。
- 预测结果输出路径：输出预测结果的 csv 文件的目录。csv 文件中，每行为一张图片的预测结果，每行中，第一列为图片的路径，第二列为图片的预测结果，第三列为图片的真实标签。

#### 模型参数
batch_size：预测时的 batch size。

## ResNet 图片分类
ResNet（残差网络）是在2015年为解决训练很深的网络的时候出现的梯度退化的问题而提出的。由于使用了 shortcut，ResNet 把原来需要学习逼近的未知函数 H(x) 进行恒等映射，变成了逼近 F(x) = H(x) - x 的一个函数，两种表达的效果相同，但 F(x) 的优化难度却比 H(x) 小的多。同时针对较深（层数大于等于50）的网络提出了 BottleNeck 结构，可以减少运算的时间复杂度。智能钛机器学习上集成的 resnet 模块有8种网络模式供选择，v1 和 v2 在 shortcut 结构体构建方式上有区别，50、100等数字表示不同的网络深度，具体可参见 resnet 论文。详情请参见下文算法示例。

#### 算法 IO 参数
- 训练数据输入：用于训练的tfrecord数据，可以使用【输入】>【数据转换】>【图像切分转换】算子生成。
- 验证数据输入：用于模型训练时的验证数据，与训练集格式一致。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。 
- label_map 文件所在目录：记录标签和 ID 对应关系的 label_map.txt 文件所在目录。可以使用【输入】>【数据转换】>【图像切分转换】算子生成。 

#### 算法参数
- 模型名称：要使用的 ResNet 版本。
- 学习率：训练过程的初始学习率。
- batch_size：训练过程中的 batch_size。
- 训练步数：训练过程的总迭代次数。
- 是否模型微调：支持在已有的训练好的模型上进行微调（通常用于迁移学习），如选“是”请在下方填写完整模型路径，并选择是否仅训练全连接层 。
- 优化器：用于优化模型参数的优化算法。

#### 模型 IO 参数
- 预测数据输入：包含要预测的图片的目录。如果要预测的图片有标签，则将对应类别的图片放在以标签名命名的目录下；如果要预测的图片无标签，则将所有要预测的图片全部放在该目录下。
- 预测结果输出路径：输出预测结果的 csv 文件的目录。csv 文件中，每行为一张图片的预测结果，每行中，第一列为图片的路径，第二列为图片的预测结果，第三列为图片的真实标签。

#### 模型参数
batch_size：预测时的 batch size。

## VGG 图片分类

VGG16 继承了 alexnet 的框架，但其通过加深卷积层数的方法获得了比 AlexNet 更高的图像识别率，是一种比 AlexNet 更深的网络结构。
AlexNet 与 VGG 相比有以下不同：
- 有较多的连续的 convolution 块和较小的 filter size（3 x 3），这样做的好处是减少权重个数，利于网络的训练和泛化。
- 通道数（channels)增多，使网络可以对输入提取更丰富的特征。VGG 论文发表时根据网络结构的复杂度提出了三种结构：VGG_a、VGG_16 和 VGG_19，您可以根据需要进行选择。

#### 算法 IO 参数
- 训练数据输入：用于训练的 tfrecord 数据，可以使用【输入】>【数据转换】>【图像切分转换】算子生成。
- 验证数据输入：用于模型训练时的验证数据，与训练集格式一致。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。 
- label_map 文件所在目录：记录标签和 ID 对应关系的 label_map.txt 文件所在目录。可以使用【输入】>【数据转换】>【图像切分转换】算子生成。 

#### 算法参数
- 模型名称：要使用的 VGG 版本。
- 学习率：训练过程的初始学习率。
- batch_size：训练过程中的 batch_size。
- 训练步数：训练过程的总迭代次数。
- 是否模型微调：支持在已有的训练好的模型上进行微调（通常用于迁移学习），如选“是”请在下方填写完整模型路径，并选择是否仅训练全连接层 。
- 优化器：用于优化模型参数的优化算法。

#### 模型 IO 参数
- 预测数据输入：包含要预测的图片的目录。如果要预测的图片有标签，则将对应类别的图片放在以标签名命名的目录下；如果要预测的图片无标签，则将所有要预测的图片全部放在该目录下。
- 预测结果输出路径：输出预测结果的 csv 文件的目录。csv 文件中，每行为一张图片的预测结果，每行中，第一列为图片的路径，第二列为图片的预测结果，第三列为图片的真实标签。

#### 模型参数
batch_size：预测时的 batch size。

## MobileNet 图片分类

MobileNet V2是一种小巧而高效的CNN模型，它的基本单元是深度级可分离卷积（depthwise separable convolution）。MobileNet训练精度高，推理速度快。可参见 [论文文档](https://arxiv.org/pdf/1707.07012.pdf)。

#### 算法 IO 参数
- 训练数据输入：用于训练的 tfrecord 数据，可以使用【输入】>【数据转换】>【图像切分转换】算子生成。
- 验证数据输入：用于模型训练时的验证数据，与训练集格式一致。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。 
- label_map 文件所在目录：记录标签和 ID 对应关系的 label_map.txt 文件所在目录。可以使用【输入】>【数据转换】>【图像切分转换】算子生成。 

#### 算法参数
- 模型名称：要使用的 MobileNet 版本。
- 学习率：训练过程的初始学习率。
- batch_size：训练过程中的 batch_size。
- 训练步数：训练过程的总迭代次数。
- 是否模型微调：支持在已有的训练好的模型上进行微调（通常用于迁移学习），如选“是”请在下方填写完整模型路径，并选择是否仅训练全连接层 。
- 优化器：用于优化模型参数的优化算法。

#### 模型 IO 参数
- 预测数据输入：包含要预测的图片的目录。如果要预测的图片有标签，则将对应类别的图片放在以标签名命名的目录下；如果要预测的图片无标签，则将所有要预测的图片全部放在该目录下。
- 预测结果输出路径：输出预测结果的 csv 文件的目录。csv 文件中，每行为一张图片的预测结果，每行中，第一列为图片的路径，第二列为图片的预测结果，第三列为图片的真实标签。

#### 模型参数
batch_size：预测时的 batch size。

## SqueezeNet 图片分类

SqueezeNet是Han等提出的一种轻量且高效的CNN模型，它参数比AlexNet少50倍，但模型性能（accuracy）与AlexNet接近。在可接受的性能下，小模型相比大模型，具有很多优势：（1）更高效的分布式训练，小模型参数小，网络通信量减少；（2）便于模型更新，模型小，客户端程序容易更新；（3）利于部署在特定硬件如FPGA，因为其内存受限。可参见 [论文文档](https://arxiv.org/pdf/1707.07012.pdf)。

#### 算法 IO 参数
- 训练数据输入：用于训练的 tfrecord 数据，可以使用【输入】>【数据转换】>【图像切分转换】算子生成。
- 验证数据输入：用于模型训练时的验证数据，与训练集格式一致。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。 
- label_map 文件所在目录：记录标签和 ID 对应关系的 label_map.txt 文件所在目录。可以使用【输入】>【数据转换】>【图像切分转换】算子生成。 

#### 算法参数
- 模型名称：要使用的 SqueezeNet 版本。
- 学习率：训练过程的初始学习率。
- batch_size：训练过程中的 batch_size。
- 训练步数：训练过程的总迭代次数。
- 是否模型微调：支持在已有的训练好的模型上进行微调（通常用于迁移学习），如选“是”请在下方填写完整模型路径，并选择是否仅训练全连接层 。
- 优化器：用于优化模型参数的优化算法。

#### 模型 IO 参数
- 预测数据输入：包含要预测的图片的目录。如果要预测的图片有标签，则将对应类别的图片放在以标签名命名的目录下；如果要预测的图片无标签，则将所有要预测的图片全部放在该目录下。
- 预测结果输出路径：输出预测结果的 csv 文件的目录。csv 文件中，每行为一张图片的预测结果，每行中，第一列为图片的路径，第二列为图片的预测结果，第三列为图片的真实标签。

#### 模型参数
batch_size：预测时的 batch size。

## ShuffleNet 图片分类

ShuffleNet是Face++提出的降低深度网络计算量的网络。它利用两个操作：逐点群卷积(pointwise group convolution)和通道混洗(channel shuffle)，与现有先进模型相比在类似的精度下大大降低计算量。可参见 [论文文档](https://arxiv.org/pdf/1707.07012.pdf)。

#### 算法 IO 参数
- 训练数据输入：用于训练的 tfrecord 数据，可以使用【输入】>【数据转换】>【图像切分转换】算子生成。
- 验证数据输入：用于模型训练时的验证数据，与训练集格式一致。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。 
- label_map 文件所在目录：记录标签和 ID 对应关系的 label_map.txt 文件所在目录。可以使用【输入】>【数据转换】>【图像切分转换】算子生成。 

#### 算法参数
- 模型名称：要使用的 ShuffleNet 版本。
- 学习率：训练过程的初始学习率。
- batch_size：训练过程中的 batch_size。
- 训练步数：训练过程的总迭代次数。
- 是否模型微调：支持在已有的训练好的模型上进行微调（通常用于迁移学习），如选“是”请在下方填写完整模型路径，并选择是否仅训练全连接层 。
- 优化器：用于优化模型参数的优化算法。

#### 模型 IO 参数
- 预测数据输入：包含要预测的图片的目录。如果要预测的图片有标签，则将对应类别的图片放在以标签名命名的目录下；如果要预测的图片无标签，则将所有要预测的图片全部放在该目录下。
- 预测结果输出路径：输出预测结果的 csv 文件的目录。csv 文件中，每行为一张图片的预测结果，每行中，第一列为图片的路径，第二列为图片的预测结果，第三列为图片的真实标签。

#### 模型参数
batch_size：预测时的 batch size。

## NasNet 图片分类

NasNet 是 google 使用自动机器学习技术搜索出来的图像分类算法。可参见 [论文文档](https://arxiv.org/pdf/1707.07012.pdf)。

#### 算法 IO 参数
- 训练数据输入：用于训练的 tfrecord 数据，可以使用【输入】>【数据转换】>【图像切分转换】算子生成。
- 验证数据输入：用于模型训练时的验证数据，与训练集格式一致。
- 模型目录：存放模型文件和日志文件的目录（如果目录中已有模型文件，下次训练时将加载目录中最新的模型文件。因此，如果改变了网络结构或更换了数据，请更换或清空模型目录）。 
- label_map 文件所在目录：记录标签和 ID 对应关系的 label_map.txt 文件所在目录。可以使用【输入】>【数据转换】>【图像切分转换】算子生成。 

#### 算法参数
- 学习率：训练过程的初始学习率。
- batch_size：训练过程中的 batch_size。
- 训练步数：训练过程的总迭代次数。
- 是否模型微调：支持在已有的训练好的模型上进行微调（通常用于迁移学习），如选“是”请在下方填写完整模型路径，并选择是否仅训练全连接层 。
- 优化器：用于优化模型参数的优化算法。

#### 模型 IO 参数
- 预测数据输入：包含要预测的图片的目录。如果要预测的图片有标签，则将对应类别的图片放在以标签名命名的目录下；如果要预测的图片无标签，则将所有要预测的图片全部放在该目录下。
- 预测结果输出路径：输出预测结果的 csv 文件的目录。csv 文件中，每行为一张图片的预测结果，每行中，第一列为图片的路径，第二列为图片的预测结果，第三列为图片的真实标签。

#### 模型参数
batch_size：预测时的 batch size。

## 模型量化压缩
图像分类任务的模型由于其参数量大，模型占用空间大，在 CPU 以及边缘设备上的推理速度较慢。模型量化压缩针对训练完成后的图像分类模型，将模型的权重以及算子的运算（一般为 float32 类型）转换为更紧凑的格式存储（int8 或者 float16）。在保持精度下降不多的条件下，压缩模型的存储所需空间，并且在 CPU 以及边缘设备上的推理速度加快。

#### 算法 IO 参数
- 输入模型目录：待量化的模型目录，对应于图像分类算法的模型目录。（如果目录中有若干个模型文件，算法将加载目录中最新的模型文件。）
- 模型目录：存放量化后的模型文件和日志文件的目录（如果改变了网络结构或更换了数据，请更换或清空模型目录）。
- 典型数据集输入：选填。典型数据集输入与图像分类算法的训练输入格式一致，tfrecord 形式，可由图像切分转换算子生成。如果在参数量化数据类型中选择了 Int8，并且在是否使用典型数据集中选择了是的条件下，该数据集才会生效。

#### 算法参数
- 量化数据类型：可选值为 Int8 或 Float16，量化压缩后模型存储的数据类型。Int8 的选项关联了更多参数，包括：是否使用典型数据集、典型数据集输入以及典型数据集选用的数量。
- 是否使用典型数据集：是否使用典型数据集对于 Int8 量化算法进行优化。量化数据类型参数为 Int8 时有效。
- 典型数据集选用的数量：整数，典型数据集使用的样本数量，填 -1 表示使用全部数据。是否使用典型数据集参数为是时有效。

#### 模型 IO 参数
- 预测数据输入：包含要预测的图片的目录。如果要预测的图片有标签，则将对应类别的图片放在以标签名命名的目录下，如果要预测的图片无标签，则将所有要预测的图片全部放在该目录下。
- 预测结果输出路径：输出预测结果的 csv 文件的目录。csv 文件中，每行为一张图片的预测结果，每行中，第一列为图片的路径，第二列为图片的预测结果，第三列为图片的真实标签。
