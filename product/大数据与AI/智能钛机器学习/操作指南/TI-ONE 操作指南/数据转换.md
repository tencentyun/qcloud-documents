
## 中文分词

#### 算法说明

分词，将中文句子划分成词语，词语之间用空格分隔。

#### 参数设置

**输入参数**

输入数据：未分词的中文文本，每行为一个句子。

**输出参数**

输出数据：分词后的中文文本，每行为一个句子，词与词之间用空格分隔。

#### 算法参数

标签分隔符：（可选）如行中有标签分隔符，则只对标签分隔符左侧的文本进行分词。

#### 实例生成	

1. 使用数据节点上传数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到分词节点，配置好输出数据路径和标签分隔符，单击【运行】开始分词。



## 去除停用词

#### 算法说明

去除文本中的停用词，文本需要预先分词。

#### 参数设置

**输入参数**

- 输入数据：分词后的中文文本，每行为一个句子，词语之间用空格分隔。
- 停用词表：要去除的停用词列表，每行为一个词。

**输出参数**

输出数据：去除停用词后的中文文本，每行为一个句子。

#### 算法参数

标签分隔符：（可选）如行中有标签分隔符，则只对标签分隔符左侧的文本进行去停用词。

#### 实例生成

1. 使用数据节点，上传输入数据和停用词表数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到去停用词节点，配置好输出数据路径和标签分隔符，单击【运行】开始去停用词。

## 句子转向量表示（Sentence2Vec）

#### 算法说明

Sentence2Vec 可以将句子转换为向量表示，转换方法有三种：
- 转换为词向量平均值。
- 转换为词向量加权平均值，权重由词频决定，词频越高，权重越低。
- 使用论文 [A simple but tough-to-beat baseline for sentence embeddings](https://openreview.net/pdf?id=SyK00v5xx) 的方法进行转换。

#### 输入参数
输入数据：文本文件，每一行为一个句子，词语之间使用空格分隔。

#### 输出参数
输出数据：文本文件，每一行为输入数据对应行的句子的向量表示，数字之间用空格分隔。

#### 算法参数
- 预训练词向量文本文件，格式请参考 word2vec 和 glove 算法的【输出参数】部分。
- 转换方式：三选一，average 对应词向量平均值、weighted_average 对应词向量加权平均值、svd 对应论文中的方法。

#### 实例生成
1. 使用数据节点上传数据，数据格式请参考【输入数据】部分。
2. 将数据节点连接到 sentence2vec 节点，配置好预训练词向量路径和转换方式，单击【运行】按钮开始训练。


## 图像数据切分

#### 算法说明

数据切分组件用于将已有的数据集切分为训练集和验证集。

组件支持用于图像识别和图像检测两种任务的数据切分。当“分类 or 检测任务”参数为“Classification”时，表明是图像识别任务，此时“图像存储路径”参数路径下需按类别将各个图像放在不同文件夹下（至少需要两个文件夹，也即至少需要两类），文件夹名字即为类别名。组件会在“输出路径”参数下生成 train.txt、valid.txt 和 label_map.txt，分别表示训练集集合，验证集集合和标签类别映射文件。

当“分类 or 检测任务”参数为“Detection”时，表明是图像检测任务。此时‘图像存储路径’目录下直接为各个图片（不像图像识别那样需按类别存放到不同文件夹），图像检测所需的标签文件（xml 文件）需另外准备。

组件根据“图像存储路径”参数获得该路径下的所有图片信息，然后按“验证集比例”参数随机选取其中一部分作为验证集，另一部分为训练集，分别用 valid.txt 和 train.txt 表示。这些 txt 文件可传给图片格式转换节点，用于生成训练集和验证集的 tfrecord 文件。


#### 参数设置

**输入参数**
图像存储路径：存储图像文件的路径，格式见算法说明部分。

**输出参数**
输出路径：存放 train.txt，valid.txt 和 label_map.txt 文件的路径。

#### 算法参数
- 分类 or 检测任务：Classification 为分类任务，Detection 为检测任务。
- 验证集比例：切分为验证集的数据比例。

#### 实例生成

1. 使用数据节点上传图片数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到图像数据切分节点，配置好输出数据路径，任务类别和验证集比例，单击【运行】开始。



## 图片格式转换（分类）

#### 算法说明

将原始的 jpg 或 png 图像转换为 tfrecord 格式，可作为算法节点的输入。同时支持有标签和无标签数据的转换。

“标签数据输入”参数可以是一个文件夹或一份单独的文件，当为一个文件夹目录时，该目录下需包含 train.txt 和 valid.txt 两份文件，分别按行记录了属于训练集和验证集的图像集合，每行表示一个样本，eg. image.jpg \_\_label\_\_ 1，其中， image.jpg 是图像名，\_\_label\_\_ 是图像名和标签之间的分隔符，1是该样本所属标签。当标签不存在时(可以理解为需要预测的样本)，只保留图像名。组件根据 train.txt 和 valid.txt 中记录的图像集合分别将其转成两份 tfrecord 文件，分别对应组件的第一个和第二个输出点。在数据量较大的情况下，每份 tfrecord 下可能包含多个文件分片，具体由 ‘images/split’ 参数控制，表示每个分片包含的图像个数。

当“标签数据输入”参数是一份文件时(文件格式需与 train.txt 或 valid.txt 相同)，表示单独对这一份文件中的图像做转换，输出为组件的第一个输出点。



#### 参数设置

**输入参数**

- 标签数据输入：存放 train.txt 和 valid.txt 文件的路径（一般是图像数据切分组件的输出）
- 图像存储路径：存储图像文件的路径，格式见算法说明部分。

**输出参数**

- tfrecord 输出：存放训练集 tfrecord 的目录。
- （验证集）tfrecord 输出：存放验证集 tfrecord 的目录。

#### 算法参数

- images/split：每份 tfrecord 文件中的样本数
- 分隔符：txt文件中分隔图片名和标签的分隔符。

#### 实例生成

1. 使用数据节点，上传图片数据，数据格式见图像数据切分节点【输入数据】部分。
2. 将图片数据连接到图像数据切分节点，进行切分。
3. 图片数据和图像数据切分节点的输出分别连接到图片格式转换节点的两个输入桩，配置好输出数据路径，单击【运行】开始。



## 图片格式转换（检测）

#### 算法说明

将原始的 jpeg 或 png 图像转换为 tfrecord 格式，可作为算法节点的输入。

“图像列表路径”参数需是一个目录，存在 train.txt 和 valid.txt 文件，分别按行存放训练集和验证集图像名称，每行一个样本。“标签路径”参数下存放各图像的 xml 标签文件，文件名需与图像名相同，方便组件按照图像名获得其对应的标签信息。

组件有两个输出，根据 train.txt 和 valid.txt 分别输出训练集和验证集 tfrecord。

“类别标签映射文件”表示各个检测框的类别名与数字标签的映射，需要提前根据数据集手动生成，格式参考 tensorflow models/research/object * detection 模块下的 pascal * label_map.pbtxt。



#### 参数设置

**输入参数**

- 图像列表路径：存储 train.txt 和 valid.txt 文件的目录
- 图像路径：图像存储路径，该目录下需要保存所有的图像
- 标签路径：存放 xml 标签文件的路径

**输出参数**

- 训练集输出：存放训练集 tfrecord 的目录
- 验证集输出：存放验证集 tfrecord 的目录

#### 算法参数
类别映射文件：从字符串类型的类别映射到整数类型的文件，可参考 object_detection 下的 pascal_label_map.pbtxt。

#### 实例生成

1. 使用数据节点，上传图片数据和标签数据，数据格式见图像数据切分节点【输入数据】部分。
2. 将标签数据连接到图像数据切分节点，进行切分。
3. 将标签数据，图片数据和图像数据切分节点的输出分别连接到图片格式转换节点的两个输入桩，配置好输出数据路径，单击【运行】开始。



## 文本数据切分

#### 算法说明

该模块将 NLP 任务的输入文件按一定比例切分成训练集和验证集两份文件。输入数据中每行为一个样本，用分隔符区分特征和标签，eg. spiderman rocks.\_\_label\_\_1，此时分隔符为'\_\_label\_\_'。



#### 参数设置

**输入参数**
数据输入：要切分的文本文件，每行为一个句子。

**输出参数**
- 切分后文件1：切分后的第一份文件。
- 切分后文件2：切分后的第二份文件。

#### 算法参数

- 切分比：第一份文件所占的比例。
- 分隔符：分隔一行中句子和标签的分隔符，如果某些标签仅在两份切分后文件之一中出现，则日志中会有提示。

#### 实例生成

1. 使用数据节点，上传文本数据，数据格式见上文【输入数据】部分。
2. 将数据节点连接到文本数据切分节点，配置好输出数据路径，切分比和分隔符，单击【运行】开始。



## 新词发现（基于 PMI 和熵的新词发现）

#### 算法说明
PMI（点互信息）和左右熵能够刻画一个文本片段的凝固程度和灵活运用程度，因此可以用于发现文本中不存在词库中的新词。

#### 输入参数
- 输入数据：未分词的中文纯文本文件。
- 词库：（可选）文本文件，每行为一个词。如发现的新词已经存在这个词库中，则跳过这一新词。

#### 输出参数
输出数据：算法发现的新词，每行为一个词。

#### 算法参数
- 最大词语长度：只考虑长度不超过这一长度的文本片段构成新词的可能性。
- 保留前 n 个新词：只保留可能性最大的前若干个新词。

#### 实例生成
1. 使用数据节点上传数据，数据格式请参考【输入数据】部分。
2. 将数据连接到【新词发现】节点的输入桩，设置好输出数据路径，单击【运行】开始发现新词。
