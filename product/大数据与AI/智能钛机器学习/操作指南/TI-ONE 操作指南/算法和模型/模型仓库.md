## 操作场景
模型仓库用于存放所有用户从任务流中保存的以及从外部导入的模型。在模型仓库页面用户可以对所有模型进行集中的管理，包括版本管理、服务部署、离线批量预测等。

## 操作步骤
### 保存模型到仓库
您可以通过两种方式将模型保存到模型仓库：新建模型、添加已有模型版本。
#### 新建模型
1. 在模型仓库页，单击页面右上角的【导入模型】。
2. 选择【新建服务】，填写模型名称。
3. 单击【保存】，将模型保存到 COS。

#### 添加已有模型版本
在任务流页面，右键单击模型组件，选择保存方式。
模型版本为自动版本管理，不可手动编辑，保存后的版本自动在现有最新版本上+1。
默认勾选自动保存预处理节点。预处理节点可用于离线批量预测作业。
![](https://main.qcloudimg.com/raw/02aeabc531935b483a56031acf448648.png)



### 查看模型信息
模型仓库页面中，所有保存过的模型将在此呈现。您可以对模型进行部署与离线预测设置。
![](https://main.qcloudimg.com/raw/b65ed7af132dbbc4e80c3c025070a714.png)
单击模型名称可以显示此模型的详细信息，在模型详情弹窗中单击【任务流快照】，可跳转至当前版本模型的任务流快照。
![](https://main.qcloudimg.com/raw/d6eeb6325eb05078110f40e47b3adb0d.png)
任务流快照：
![](https://main.qcloudimg.com/raw/a7504e42d6e42c014bc16e03ef84f8cf.png)

单击模型名称右侧的垃圾桶图标，弹窗确定后删除此版本模型，勾选【删除此模型下所有版本信息】清除所有版本信息。

### 导入模型
单击页面上方【导入模型】，可以将外部的模型导入平台进行统一管理，支持来源为用户的 COS 路径与本地上传，支持的格式为 PMML/ANGEL/TFServing。
与保存模型时一样，导入模型也需要设置模型的名称和版本。
![](https://main.qcloudimg.com/raw/40e04d804a7769bdf221bcb190df0606.png)

### 搜索与筛选
模型自动生成分类 TAG，用户可以通过搜索框对已有的模型名称进行搜索，也可以通过筛选框筛选模型的 TAG。
![](https://main.qcloudimg.com/raw/f2251047b4aad760a73542a75dd9b240.png)


### 调用模型
单击模型服务名称可查看此服务的访问地址与密钥，服务密钥会在后台自动生成，您可单击复制图标进行复制。
目前模型服务支持三种类型的模型部署：Angel、PMML、Pb。
公有云的服务部署后，可以在界面上测试，可也以通过 curl 在支撑环境进行调用。

- 调用 Angel/PMML 推理服务
```bash
curl \
-v \
-H "Content-Type: application/json" \
-H "Authorization: ${accessKey}" \
-H "Host: ${hostUri}"  \
-X POST \
-d '${data}' \
 ${gatewayUri}/v1/models/m:predict
```

- 调用 tfserving 推理服务
```bash
curl \
-v \
-H "Content-Type: application/json" \
-H "Authorization: ${accessKey}" \
-H "Host: ${hostUri}"  \
-X POST \
-d '${data}' \
 ${gatewayUri}/v1/models/m:predict
```

**变量说明**：
目前只有腾讯云支撑环境可以访问。具体调用时，请替换调用服务中的变量：
- `accessKey`：从模型服务界面获得的密钥，例如`a15fea3033ba4496d87cfa74bafdae8a1`。
- `hostUri`：从模型服务界面获得的链接，例如`e1wBicDrTaWAQ4D3gRQFOA.ti-test.com`。
- `data`：推理服务的输入数据，json 格式，例如`{"instances": [{"x1":6.2, "x2":2.2, "x3":1.1, "x4":1.2}]}`。
- `gatewayUri`：请求转发所需的地址，目前配置固定为`100.98.32.37:31292`。

#### 参考文档
- [Angel 模型服务文档](https://github.com/Angel-ML/serving/blob/master/docs/serving_doc.md)
- [TensorFlow 模型服务文档](https://www.tensorflow.org/tfx/serving/api_rest)





