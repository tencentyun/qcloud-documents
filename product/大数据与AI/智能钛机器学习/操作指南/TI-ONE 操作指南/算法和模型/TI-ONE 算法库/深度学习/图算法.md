## LabelPropagation

- **算法说明**

  Label Propagation算法是一种基于标签传播的局部社区划分算法。首先为每个节点分配唯一标识标签labelId（节点本身id作为初始labelId, 在接下来的每一次迭代中都将自己的labelId更新为其邻居中的众数标签。参考论文Community Detection via Semi–Synchronous Label Propagation Algorithms,或者KM文章

- **算法IO参数**

  - 输入路径： tdw/hdsf url, 对不带权的网络数据格式为srcId(long) | dstId(long), 对带权网络，数据格式为srcId(long) | dstId(long) | weight(float), 其中|为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 是否带权： 是/否
  - 结果输出路径： tdw/hdsf url, 输出的格式为nodeId(long) | communityId(long), communityId一致表示属于同一个社区, 编号不连续
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍

- **算法参数**

  - 放弃更新概率： 每次模块度优化，每个节点有个独立的概率放弃更新本身的社区为新的社区，放弃概率为放弃更新概率, 主要为了解决社区互换问题，通常不需要设置的太大
  - 随机扩散轮数： 算法开始阶段，节点不严格更新自己的标签为邻居中的众数标签，而是依概率选择，选择的概率正比于邻居中对应标签的邻居数。 设置为1时与原始的算法一致
  - 众数标签扩散轮数： 标准的标签传播算法的扩散轮数，每次选择邻居中的众数标签为自己新的标签

- **资源参数**

  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users

- **特殊参数**

  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

## COPRA

- **算法说明**

  LPA算法变化而来的overlapping社区发现算法，允许一个节点同时属于k个不同社区。算法过程与LPA类似

  1. 节点对邻居的所有标签（带权）的归属度进行归一化，保留归属度最大的前k个
  2. 过滤掉标签归属度小于1/k的标签（若所有标签均小于1/k,则保留归属度最大的一个)
  3. 对所有剩下标签再一次做归属度归一化
     详细原理参见论文[Finding overlapping communities in networks by label propagation](https://arxiv.org/ftp/arxiv/papers/0910/0910.5516.pdf)

- **算法IO参数**

  - 输入路径： tdw/hdsf url, 对不带权的网络数据格式为`srcId(long) | dstId(long)`, 对带权网络，数据格式为`srcId(long) | dstId(long) | weight(float)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 是否带权： 是/否
  - 结果输出路径： tdw/hdsf url, 输出的格式为`nodeId(long) | communityId1(long) | belongings1(float) | ... | communityIdk(long) | belongingsk(float)`, communityId一致表示属于同一个社区, 编号不连续, belongings表示社区的隶属度
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍

- **算法参数**

  - 扩散轮数： 算法执行的轮数
  - 最大重叠社区数： 每个节点最多属于多少个社区，对应于输出的社区个数
  - 放弃更新概率： 每次模块度优化，每个节点有个独立的概率放弃更新本身的社区为新的社区，放弃概率为`放弃更新概率`, 主要为了解决社区互换问题，通常不需要设置的太大

- **资源参数**

  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users

- **特殊参数**

  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

## FastUnfolding

- **算法说明**

  - 基本思路
    社区划分一般是无监督的学习，需要直接从图的拓扑信息中得到有效的社区划分。不同于监督学习从预测结果与真实标签的误差中寻找调整参数的方向，无监督学习经常直接给出判断一个模型好坏的标准。对FastUnfolding算法来说，评价一个社区划分好坏的标准是指标 [模块度(Modularity)](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.70.056131)：
    $$
    Q = \frac{1}{2m}\sum_{i,j=1}^n\left(A_{ij} - \frac{k_ik_j}{2m}\right)\delta(c_i,c_j).
    $$
    其中$$c_i(i=1,\dots,n)$$为节点$$n_i$$的社区标签，$$A_{ij}$$为节点$$n_i$$与节点$$n_j$$的连边权重。FastUnfolding算法的思路很直接：优化网络的模块度指标$$Q$$。

  - 算法步骤
    Fast Unfolding 算法分两个步骤，分别是

    1. **Modularity Optimization**
       在初始的时候，认为所有的节点各自属于一个社区，然后根据模块度增量来改变节点的社区归属，从而使得得到的社区划分朝着模块度上升的方向前进。Fast Unfolding算法采用了一个简单的策略：每个节点只能选择其自己或者邻居的社区作为自己的社区。
    2. **Graph folding**
       在Graph folding阶段，所有当前属于同一个社区的节点聚合为单个节点，新网络的节点数跟社区数目一致，新网络节点之间的连边为节点代表的社区之间节点的连边之和，并给新网络的节点赋予权重，其值等于原始网络社区内部的节点连边之和。看起来很绕口，其本质为将当前同一社区的节点绑在一起，使得下一步的Modularity Optimization过程以当前社区为基本单位。即每个社区可以选择邻居社区或者当前社区作为自己新的社区。
       具体的原理请参考论文[Fast unfolding of communities in large networks](https://arxiv.org/pdf/0803.0476.pdf), 实现的细节可以参考[km文章](http://km.oa.com/group/2430/articles/show/322720)

- **算法IO参数**

  - 输入路径： tdw/hdsf url, 对不带权的网络数据格式为`srcId(long) | dstId(long)`, 对带权网络，数据格式为`srcId(long) | dstId(long) | weight(float)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 是否带权： 是/否
  - 结果输出路径： tdw/hdsf url, 输出的格式为`nodeId(long) | communityId(long)`, communityId一致表示属于同一个社区, 编号不连续
  - partition数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍

- **算法参数**

  - 算法： FastUnfolding/FastUnfolding With Density, 后者请参考论文[Network community detection using modularity density measures](https://arxiv.org/abs/1708.06810)或者[km文章](http://km.oa.com/group/2430/articles/show/322720)的第4部分
  - 大循环总迭代次数: 折叠的次数上限
  - 小循环总迭代次数： 开始折叠之前模块度优化的次数上限
  - 小循环最小更新值： 开始折叠之前，每次模块度优化步骤增加的模块度值的
  - 大循环最小更新值： 每次折叠之前判断是否比上一次折叠后模块度增长该值的量，否则程序保存退出
  - 更新概率： 每次模块度优化，每个节点有个独立的概率放弃更新本身的社区为新的社区，放弃概率为`1-更新概率`，主要为了解决社区互换问题，通常不需要设置的太小
  - 是否使用"merge"策略： 不建议使用的策略，同样为了解决社区互换问题设置的，对FastUnfolding With Density算法无效

- **资源参数**

  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users

- **特殊参数**

  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误



### HANP

- **算法说明**

  LPA算法的改进，主要为了避免LPA算法可能产生“Monster”社区的问题（单个社区包含网络大部分节点），引入了标签的活跃度s。每个节点活跃度初始化为1.0，随着传播降低。当某个节点的活跃度小于0后，就不可能再将自身社区传播出去。标签的选择依据公式：
  $$
  L^{(k+1)}(n_i) = \arg\max_{l}\sum_{n_j\in Nei(n_i), L^{(k)}(n_j)=l} w_{ij}\cdot s_j^{(k)}(l)
  $$
  其中$$L^{(k)}(n_i)$$表示在第$$k$$轮时节点$$n_i$$的标签, $$s_j^{(k)}$$表示节点$$n_j$$在第$$k$$轮时, 对应标签$$l$$的活跃度(实际上对应的标签是唯一的，只有第$$k$$轮的真实标签会参与计算), $$w_{ij}$$表示节点$$n_i$$与节点$$n_j$$的连边权重。

  活跃度的更新公式为：
  $$
  s_i^{(k+1)} = \left(\max \left\{s_j^{(k)} |L^{(k)}(n_j) = L^{(k+1)}(n_i), n_j\in Nei(n_i)\right\}\right)-\delta
  $$
  $$\delta$$为每轮活跃度的衰减值

  详细算法细节参考论文[Near linear time algorithm to detect community structures in large-scale networks](https://arxiv.org/pdf/0709.2938v1.pdf)

- **算法IO参数**

  - 输入路径： tdw/hdsf url, 对不带权的网络数据格式为`srcId(long) | dstId(long)`, 对带权网络，数据格式为`srcId(long) | dstId(long) | weight(float)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 是否带权： 是/否
  - 结果输出路径： tdw/hdsf url, 输出的格式为`nodeId(long) | communityId(long)`, communityId一致表示属于同一个社区, 编号不连续
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍

- **算法参数**

  - 扩散轮数： 算法执行的轮数
  - 传播衰减量： 每轮传播活跃度的衰减量
  - 放弃更新概率： 每次模块度优化，每个节点有个独立的概率放弃更新本身的社区为新的社区，放弃概率为`放弃更新概率`, 主要为了解决社区互换问题，通常不需要设置的太大

- **资源参数**

  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users

- **特殊参数**

  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

### LocalClusterCoefficient

- **算法说明**

计算每个节点的局部聚类系数，参考Wiki[Clustering coefficient](https://en.wikipedia.org/wiki/Clustering_coefficient)

- **算法IO参数**
  - 输入路径： tdw/hdsf url, 无权网络, 数据格式为 `srcId(long) | dstId(long)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 输出路径： tdw/hdsf url, 输出的格式为 `id(long) | lcc(float)`
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍
- **资源参数**
  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users
- **特殊参数**
  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

### HyperAnf

- **算法说明**

估计网络的平均半径，参考论文[HyperANF: Approximating the Neighbourhood Function of Very Large Graphs on a Budget](https://arxiv.org/pdf/1011.5599.pdf)开发，详细细节请看论文。

- **算法IO参数**
  - 输入路径： tdw/hdsf url, 无权网络, 数据格式为 `srcId(long) | dstId(long)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 输出路径： tdw/hdsf url, 输出的格式为 `round(int) | anf(float)`, 其中round = -1对应的anf为最终估计值
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍
- **算法参数**

- 最大迭代次数： 迭代轮数
- 计数器位数： 位数越高越准确，但速度越慢

- **资源参数**
  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users
- **特殊参数**
  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

### GlobalClusterCoefficient

- **算法说明**

计算每个节点的全局聚类系数，参考Wiki[Clustering coefficient](https://en.wikipedia.org/wiki/Clustering_coefficient)

- **算法IO参数**
  - 输入路径： tdw/hdsf url, 无权网络, 数据格式为 `srcId(long) | dstId(long)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍
- **资源参数**
  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users
- **特殊参数**
  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误
- **查看结果**

运行成功后，右键控件，选择Spark控制台，点击stdout即可看到结果



## AdamicAdar

- **算法说明**
  基于共同邻居度信息的著名指标之一，由 [Lada Adamic](https://en.wikipedia.org/wiki/Lada_Adamic) 和[Eytan Adar](https://en.wikipedia.org/w/index.php?title=Eytan_Adar&action=edit&redlink=1)提出。指标考虑到这样一个事实：度小的共同邻居贡献要大于度大的共同邻居的贡献。比如说，两个用户都关注了某个大V，并不能说明这两个用户有很强的相似性；但是如果两个用户都关注了某个很小众的节点（度小），那么这两个用户之间有某种相似性的可能性就要大的多。从公式上看，需要计算的分数为：
  $$AA(x,y) = \sum_{s\in\Gamma(x) \cup\Gamma(y)}\frac{1}{\log_2(|\Gamma(s) |)}$$

  详细请参考论文 ["Friends and neighbors on the web"](https://pdfs.semanticscholar.org/4c7c/743f8bb0ce9a9fb74d30019266a53e684c20.pdf)。

- **算法IO参数**

  - 输入路径： tdw/hdsf url, 格式为`srcId(string) | dstId(string)`，`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 输入网络无重边： 是/否， 算法需要的输入格式是无权无权边的网络，如果网络经过预处理了，可以避免内部预处理的代价
  - 输出路径： tdw/hdsf url, 输出的格式为`srcId(string) | dstId(string) | AAScore(float)`
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍

- **算法参数**

  - 截断阈值(T)： 大于等于截断阈值的节点不贡献AA值，即修改AA指标为：
    $$AA'(x,y) = \sum_{s\in\Gamma(x) \cup\Gamma(y), \left|\Gamma(s)\right| < T }\frac{1}{\log_2(|\Gamma(s) |)}$$

    由于度大的节点对邻居对的贡献较低，而计算量又特别大（度的平方），合理的截断可以大大减小算法的运行时间

- **资源参数**

  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小

- **特殊参数**

  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误



## ResourceAllocation

- 算法说明
  与AA指标类似，通过网络资源分配过程推导而来。从公式上看，需要计算的分数为：

  $$AA(x,y) = \sum_{s\in\Gamma(x) \cup\Gamma(y)}\frac{1}{|\Gamma(s) |}$$

  详细请参考论文 ["Power-law strength-degree correlation from resource-allocation dynamics on weighted networks"](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.75.021102)。

- 算法IO参数

  - 输入路径： tdw/hdsf url, 格式为srcId(string) | dstId(string)，|为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 输入网络无重边： 是/否， 算法需要的输入格式是无权无权边的网络，如果网络经过预处理了，可以避免内部预处理的代价
  - 输出路径： tdw/hdsf url, 输出的格式为srcId(string) | dstId(string) | AAScore(float)
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍

- 算法参数

  - 截断阈值(T)： 大于等于截断阈值的节点不贡献AA值，即修改AA指标为：
    AA'(x,y) = \sum_{s\in\Gamma(x) \cup\Gamma(y), \left|\Gamma(s)\right| < T }\frac{1}{\log_2(|\Gamma(s) |)}
    由于度大的节点对邻居对的贡献较低，而计算量又特别大（度的平方），合理的截断可以大大减小算法的运行时间

- 资源参数

  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小

- 特殊参数

  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

### CommonFriends

- **算法说明**

计算两个好友的共同好友数，某种程度上可以刻画两个节点之间的紧密程度

- **算法IO参数**
  - 输入路径： tdw/hdsf url, 无权网络, 数据格式为 `srcId(long) | dstId(long)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 结果输出路径： tdw/hdsf url, 输出的格式为 `srcId(long) | dstId(long) | count(int)`
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍

- **资源参数**
  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users
- **特殊参数**
  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

### PageRank

- **算法说明**
  可能是最著名的节点重要性评价算法，最初由拉里佩奇提出，被应用于Google搜索的网页排名。 详细算法细节参考论文[The PageRank Citation Ranking:Bringing Order to the Web](http:ilpubs.stanford.edu:8090/422/1/1999-66.pdf)。 这里提供GraphX官方两个实现（静态迭代和差值迭代）的带权版本。
- **算法IO参数**
  - 输入路径： tdw/hdsf url, 对不带权的网络数据格式为`srcId(long) | dstId(long)`, 对带权网络，数据格式为`srcId(long) | dstId(long) | weight(float)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 是否带权： 是/否
  - 结果输出路径： tdw/hdsf url, 输出的格式为`nodeId(long) | rank(float)`, rank值越大表示节点越重要
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍
- **算法参数**
  - 实现方式： 静态迭代/差值迭代，前者迭代固定的轮数，后者在达到给定精度之后提早退出
  - 迭代次数： 算法迭代轮数，对静态迭代，算法会迭代该轮次，对插值迭代，该值为迭代轮数上界
  - reset probability： 重定向概率，在PageRank的网上冲浪者解释模型中，表示用户跳出超链接点击，而是从所有网页中随机选择一个网页作为新的开始的概率，Google的推荐值为0.15
  - 精度： 对插值迭代算法有效，在所有节点的前后Rank插值低于该值的时候，算法提早终止
- **资源参数**
  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users
- **特殊参数**
  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误



### ReIndex

- **算法说明**

对网络节点从0开始连续编号，输出重编号后的网络和映射关系

- **算法IO参数**
  - 输入路径： tdw/hdsf url, 对无权网络, 数据格式为 `srcId(long) | dstId(long)`, 对有权网络，数据格式为`srcId(long) | dstId(long) | weight(float)`。 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 是否带权：是/否 
  - 输出路径： tdw/hdsf url, 对无权网络, 格式为 `srcId(long) | dstId(long)`, 对有权网络，格式为`srcId(long) | dstId(long) | weight(float)`
  - 映射关系保存路径： tdw/hdsf url, 格式为`originalId(long) | newId(long)`
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍

- **资源参数**
  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users
- **特殊参数**
  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

### Sample

- **算法说明**

对网络节点进行随机抽样, 保持抽样得到的网络的连通性(若第一个连通分支的节点数达不到采样比例，可能出现多个连通分支)

- **算法IO参数**
  - 输入路径： tdw/hdsf url, 无权网络, 数据格式为 `srcId(long) | dstId(long)`。 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 输出路径： tdw/hdsf url, 格式为 `srcId(long) | dstId(long)`
  - 子图所属连通分支(可选)： tdw/hdsf url, 格式为`nodeId(long) | componentId(long)`
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍
- **算法参数**
  - 采样率： 随机采样后网络的节点数占原始网络节点数的比例
- **资源参数**
  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users
- **特殊参数**
  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

### KCore

- **算法说明**

对输入的网络数据，获得每个节点的coreness。 Kcore算法的最直观解释是`剥洋葱`，即首先将网络中度为1的节点剥离，此时剩余的网络中可能会产生新的度为1的节点，再依次剥离，直到剩余的网络中所有节点的度都大于等于2。 那么之前被剥离的节点的coreness即为1。 之后再依次剥离得到coreness为2,3,...,n的节点，直到网络中所有的节点都得到对应的coreness。 当然，实际的分布式实现没有这么朴素， 请参考论文[Distributed k-Core Decomposition](http://arxiv.org/pdf/1103.5320.pdf)。 coreness越大表示节点属于`越中心`的位置, 从而也越重要。

- **算法IO参数**
  - 输入路径： tdw/hdsf url, 网络数据格式为`srcId(long) | dstId(long)`, 其中`|`为分隔符，对tdw表来说表示分隔字段，对hdfs文件来说表示空白符或者逗号
  - 结果输出路径： tdw/hdsf url, 输出的格式为`nodeId(long) | coreness(int)`, coreness值越大表示节点越重要
  - 分区数: Spark的数据分区数, 一般为使用的总核数的2 ~ 10倍
- **资源参数**
  - num-executors： 使用多少个Spark节点
  - driver-memory： Spark driver的内存大小
  - executor-cores: 每个Spark节点使用多少个core
  - executor-memory: 每个Spark节点使用的内存大小
  - spark-conf： Spark的其他参数。 特别的，由于权限原因，需要用户额外提供ugi参数 spark.hadoop.hadoop.job.ugi=tdw_用户名:密码,users
- **特殊参数**
  - 集群： 选择的集群
  - Spark版本： 不支持1.6版本，请选择tdw 3.11-2.2.x版本，否则会出现奇怪的错误

## [2.0] LPA

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`LPA（Label Propagation Algorithm）`是最简单的社区发现算法，通过标签扩散发掘网络的社区关系。

#### 输入

- 输入数据路径：输入文件所在路径。
- 输入文件类型：格式包括以下三种：
  - csv： csv 文件
    - 输入数据包含header信息
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet

#### 输出

- 输出数据路径：输出文件所在路径。

- 输出数据格式：格式包括以下三种：

  - csv： csv 文件
    - 输出数据包含header信息
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet

  > 算法结果保存路径，共两列，其中第一列为节点 ID，第二列为节点对应的社区 ID。社区 ID 相同表示属于同一个社区。

#### 参数说明

- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。

## [2.0] EffectiveSize

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`EffectiveSize`是由结构空洞理论得到的网络度量指标，是 `ego-network` 中节点的重要衡量指标。

#### 输入

- 输入数据路径：输入文件所在路径。
- 输入文件类型：格式包括以下三种：
  - csv： csv 文件
    - 输入数据包含header信息
    - 输入数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet

#### 输出

- 输出数据路径：输出文件所在路径。

- 输出数据格式：格式包括以下三种：

  - csv： csv 文件
    - 输出数据包含header信息
    - 输出数据分割符：主要包括逗号、空格、分号、星号等分割符
  - text：文本文件
  - parquet：列式存储格式 parquet

  > 算法结果保存路径，共三列，其中第一列为节点 ID，第二列为 effectiveSize 值，第三列为 redundancyCol 值。

#### 参数说明

- src：源节点列。
- dst：目标节点列。
- numPartition：分区数。
