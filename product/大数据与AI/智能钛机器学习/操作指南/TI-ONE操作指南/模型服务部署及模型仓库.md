# 模型服务部署及模型仓库

智能钛机器学习平台为用户提供模型仓库功能，用户能进行**模型部署**并可以将模型部署为**Restful API**、**离线批量预测**、**导入第三方模型**等服务，后文将分别介绍：

### 模型部署

提供两种方式：**任务流页面快捷部署**、**将模型保存至模型仓库页面进行部署**

**任务流页面快捷部署**

1. 在任务流上方单击部署模型<img src="https://main.qcloudimg.com/raw/bcfef224b06e499553e5272c14813518.png" style="margin:0;">图标
2. **选择模型**并保存至**模型仓库**
3. 点击**下一步**进行部署设置（需要选择运行环境、以及模型资源配置）
4. 点击**部署**按钮

**将模型保存至模型仓库页面进行部署**

1. 右键单击**模型**组件，选择**保存**到模型仓库

<img src="https://main.qcloudimg.com/raw/e77f71408e5c6b9c17139b28db07dbc6.png" style="zoom:80%">

2. 输入**模型名称**

3. 页面将跳转至**模型仓库**页面，点击**部署**按钮

4. 进行**部署设置**（需要选择运行环境、以及模型资源配置）

   

### 调用模型说明

   单击模型服务名称可查看此服务的访问地址与密钥，服务密钥会在后台自动生成，您可单击复制图标进行复制。
   目前模型服务支持三种类型的模型部署：Angel、PMML、tfserving。
   公有云的服务部署后，可以在界面上测试，可也以通过 curl 在支撑环境进行调用。

   - 调用 Angel/PMML 推理服务

   ```bash
   curl \
   -v \
   -H "Content-Type: application/json" \
   -H "Authorization: ${accessKey}" \
   -H "Host: ${hostUri}"  \
   -X POST \
   -d '${data}' \
    ${gatewayUri}/v1/models/m:predict
   ```

   - 调用 tfserving 推理服务

   ```bash
   curl \
   -v \
   -H "Content-Type: application/json" \
   -H "Authorization: ${accessKey}" \
   -H "Host: ${hostUri}"  \
   -X POST \
   -d '${data}' \
    ${gatewayUri}/v1/models/m:predict
   ```

   **变量说明**：
   目前只有腾讯云支撑环境可以访问。具体调用时，请替换调用服务中的变量：

   - `accessKey`：从模型服务界面获得的密钥，例如`a15fea3033ba4496d87cfa74bafdae8a1`。
   - `hostUri`：从模型服务界面获得的链接，例如`e1wBicDrTaWAQ4D3gRQFOA.ti-test.com`。
   - `data`：推理服务的输入数据，json 格式，例如`{"instances": [{"x1":6.2, "x2":2.2, "x3":1.1, "x4":1.2}]}`。
   - `gatewayUri`：请求转发所需的地址，目前配置固定为`100.98.32.37:31292`。

   ##### 参考文档

   - [Angel 模型服务文档](https://github.com/Angel-ML/serving/blob/master/docs/serving_doc.md)

   - [TensorFlow 模型服务文档 ](https://www.tensorflow.org/tfx/serving/api_rest)



#### 模型部署完成后，可在**模型服务**的**操作**列中，进行如下操作：

1. **测试**：页面内对服务进行小数量级的测试。支持的任务类型为**图像分类、图像目标识别**和**机器学习**。
 - 图像分类和图像目标识别的数据支持用户通过 COS 和本地上传。
 - 机器学习任务的数据支持的提交格式为 JSON（用户需要先在任务流界面右击组件选择导出模型并找到对应txt文件）。
2. **升级/回退**：用户可对实例进行部分/全量的版本**升级与回退**。
3. **负载均衡**：单击列表的流量数，分配此服务各个版本的流量百分比，新建的模型版本默认流量为0。
4. **监控**：用户可在界面上查看某一段时间的响应、请求、使用率等情况
5. **删除**：在弹框中确认删除后模型将不再对外进行服务

​     

​     

### 离线批量预测

1. 进入**模型仓库**页面，选择相应的模型点击**离线批量预测**

   ![https://main.qcloudimg.com/raw/1f3ea805b7b175940dc7903d615c3f17.png](https://main.qcloudimg.com/raw/1f3ea805b7b175940dc7903d615c3f17.png)

2. 在跳转的离线批量预测页面对**作业类型**、**调度周期**与**开始时间**进行设置。并对预处理环节进行编辑，如果删除预处理节点，请重新在组件间完成连线。

3. 成功开启作业后，您将进入批量预测作业列表页面，可以对所有作业进行查看和管理。
   作业的运行状态有三种：运行中、已完成、已失败。单击**运行中**，可以打开任务流视图，查看离线预测作业的运行详情。



### 导入模型

1. 进入**模型仓库**页面，点击右上角**导入模型**按钮

2. 填写COS路径、模型名称、选择模型类型等信息
3. 点击**确定**，导入模型



