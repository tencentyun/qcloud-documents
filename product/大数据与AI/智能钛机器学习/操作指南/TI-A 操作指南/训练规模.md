## 预设定的训练规模

使用 scaletier 参数，可以定义训练任务的规模。规模越大，价格越高。目前预设的规模有：

| 运行方式  | 基础规模  | 小规模  | 中等规模  | 大规模  |
|---|---|---|---|---|
| 使用 CPU 的单机任务 | BASIC |  SMALL |  MIDDLE |  LARGE |
| 使用 GPU 的单机任务 | BASIC_GPU |  SMALL_GPU |  MIDDLE_GPU |  LARGE_GPU |
| 使用 CPU 的分布式任务 | BASIC_DIST |  SMALL_DIST |  MIDDLE_DIST |  LARGE_DIST |
| 使用 GPU 的分布式任务 | BASIC_GPU_DIST |  SMALL_GPU_DIST |  MIDDLE_GPU_DIST |  LARGE_GPU_DIST |

由于 Spark 任务的特殊性，Spark 任务只支持 DIST 版本的 scaletier 参数。如果不设置 scaletier，默认会为 Spark 任务设置为一个单 driver + 单 executor 的运算集群进行运算。

## 自定义的训练规模

当 scaletier 参数的值为 CUSTOM 时，用户可使用以下参数自定义自己的训练规模：

- mt：即 master type，指定 master/driver 节点的机器类型。
- wt：即 worker type，指定 worker/executor 节点的机器类型。
- pt：即 parameter server type，指定 parameter server 节点的机器类型 (对于 Spark 任务，这个参数会被忽略)。
- wcount：即 worker count，指定 worker/driver 节点的个数。
- pscount：即 parameter server count，指定 parameter server 节点的个数 (对于 Spark 任务，这个参数会被忽略)。

机器类型使用形如 `1U2G1P` 的方式描述，表示使用的 CPU，内存，以及 GPU 的数量。更多举例如下：

| 机器类型                  |  CPU | 内存 | GPU |
| :------------------- | :------ | :---- | :-----|
| 1U2G1P               |  单核 | 2G | 1 张卡 |
| 2U4G0P               |  双核 | 4G | 0 张卡 |


自定义运行举例：

```bash
tictl job create custom-job \
--packagedir="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/estimator:/estimator" \
--command=python \
--args="-m trainer.task \
        --job-dir custom_output \
        --train-files /estimator/data/adult.data.csv \
        --eval-files /estimator/data/adult.test.csv \
        --train-steps 1000 \
        --eval-steps 100" \
--scaletier=CUSTOM \
--mt=2U4G0P \
--wt=2U4G0P \
--pt=2U4G0P \
--pscount=2 \
--wcount=2
```
