在开始训练之前，您需要了解使用 TI-A 平台的一般工作流：

1. 在本地利用小规模数据集，调通训练模型的程序；
2. 将本地准备好的数据和程序上传到我们的对象存储（COS）中；
3. 利用 `tictl` 工具，充分利用 TI-A 平台支持的 **单机/分布式**，**CPU/GPU** 等多种能力，高效省心地完成训练；
4. 可选直接部署模型，对外提供服务。

## 深度学习任务示例一：单机训练任务
### 准备数据

这里采用 [MNIST For ML Beginner](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_saved_model.py) 的 TensorFlow 程序作为示例。我们在 COS 上提供修改了数据源的程序，以方便使用。

1.使用 `coscmd` 将示例下载到本地，来作为本地准备好的程序：

```bash
coscmd -b tia-demo-1255502019 -r ap-shanghai download -r mnist_example mnist_example
```

2.在 `mnist_example` 文件夹所在目录，使用 coscmd 将上述示例上传到同样名为 `mnist_example` 的 COS 目录下：

```bash
coscmd upload -r mnist_example mnist_example
```

返回结果：
```
upload mnist_example/mnist_client.py   =>   cos://mybucket/mnist_example/mnist_client.py  [100%]
upload mnist_example/mnist_input_data.py   =>   cos://mybucket/mnist_example/mnist_input_data.py  [100%]
upload mnist_example/mnist_saved_model.py   =>   cos://mybucket/mnist_example/mnist_saved_model.py  [100%]
1 folders, 3 files successful, 0 files failed
```

### 开启使用 CPU 的单机任务

利用 `tictl` 来开启训练任务，只需执行下面的命令：

> **注意：**
> job 命名只能使用小写字母、数字、以及 ‘.’ 和 ‘-’ 的组合，且开头必须是小写字母或者数字。

```bash
tictl job create cpu-job \
--packagedir="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/mnist_example:/data/mnist_example" \
--command=python \
--args="mnist_saved_model.py cpu_model" \
--runtime=tia-1.6.0 \
--scaletier=BASIC
```

返回结果：
```
create job success.
NAME       CREATED                                                       END    STATE    MESSAGE
cpu-job    2018-05-03 20:06:40.109664331 +0800 CST m=+16304.376036037                    creating
```

参数说明：

- **--packagedir：**由 **程序来源** 和 **加载路径** 两部分组成，由 ‘：’ 连接。详细介绍，请见 [文件路径](https://cloud.tencent.com/document/product/851/17318)。
- **--command：**运行脚本所需的命令或程序
- **--args：**开启训练需要的参数
  - **mnist_saved_model.py**：第一个参数，是被执行的程序脚本文件。
  - **cpu_model**：第二个以及之后的参数，是程序脚本自身需要的参数，本例中的参数指定的是导出模型的存放地址。
- **--runtime：**由 TI-A 平台提供好的程序的运行环境，带有不同的标签，对应不同的环境。详细介绍，请见 [运行环境](https://cloud.tencent.com/document/product/851/17320)。
- **--scaletier：**用以指定训练的方式和规模，这里采用最基本的单机训练方式。详细介绍，请见 [训练规模](https://cloud.tencent.com/document/product/851/17319)。

### 开启使用 GPU 的单机任务

不用修改代码，只要修改 args, runtime 和 scaletier 三个参数，即可开启使用 GPU 的训练任务：

```bash
tictl job create gpu-job \
--packagedir="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/mnist_example:/data/mnist_example" \
--command=python \
--args="mnist_saved_model.py gpu_model" \
--runtime=tia-1.6.0-gpu \
--scaletier=BASIC_GPU
```

返回结果：
```
create job success.
NAME       CREATED                                                       END    STATE    MESSAGE
gpu-job    2018-05-03 20:06:49.258482625 +0800 CST m=+16313.524854326                    creating
```

## 深度学习任务示例二：分布式训练任务
TI-A 平台同时支持运行分布式任务（目前仅支持 TensorFlow 中的 Estimator 模式），这里使用 [Custom Estimator](https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/census/estimator/trainer) 作为例子。我们在 COS 上提供修改了数据源的数据，以方便使用。

1.使用 `coscmd` 将示例下载到本地，来作为我们本地准备好的程序：

```bash
coscmd -b tia-demo-1255502019 -r ap-shanghai download -r estimator estimator
```

2.在 `estimator`文件夹所在目录，我们使用 `coscmd` 把它上传到同样名为 `estimator` 的 COS 目录下：

```bash
coscmd upload -r estimator estimator
```

3.运行以下命令，开启分布式训练：

```bash
tictl job create dist-job \
--packagedir="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/estimator:/estimator" \
--command=python \
--args="-m trainer.task \
        --job-dir output \
        --train-files /estimator/data/adult.data.csv \
        --eval-files /estimator/data/adult.test.csv \
        --train-steps 1000 \
        --eval-steps 100" \
--scaletier=BASIC_DIST
```

返回结果：
```
create job success.
NAME        CREATED                                                       END    STATE    MESSAGE
dist-job    2018-05-03 21:17:00.907763737 +0800 CST m=+20525.174135470                    creating
```


## Spark 任务示例
TIA 平台目前支持 2.4.* 的 Spark Java，Scala 或 Python 任务运行，下面的例子运行了一个单 Driver，单 Excutor 的训练任务。

```
tictl job create sparkjob1 \
--runtime=tia-spark-2.4.0  \
--command='local:///opt/spark/examples/src/main/python/wordcount.py /opt/spark/examples/src/main/resources/people.txt'
```

Spark 任务也支持挂载 COS 目录，下面的例子运行了一个 Python 任务，挂载位于 COS 的一端文本作为数据来源，同时选择多机进行训练。

```
tictl job create sparkjob2 --runtime=tia-spark-2.4.0  \
--packagedir="cos://data-beijing-1255502019.cos.ap-beijing.myqcloud.com/:/data/" \
--command='local:///opt/spark/examples/src/main/python/wordcount.py /data/shakespeare.txt'  \
--scaletier=BASIC_DIST
```
