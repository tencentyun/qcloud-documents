训练好的模型可以作为一个服务对外部署，使模型快速投入使用。

## 部署服务

*MNIST For ML Beginner* 示例中，训练后存储在 COS 的模型可以作为服务直接部署：

```bash
tictl model create mnist-model \
--description=mnist-model \
--model="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/mnist_example/cpu-job:/data/mnist"
```

返回结果：
```
create model success.
NAME           CREATED                          URL    STATE    MESSAGE
mnist-model    2018-05-04 13:49:52 +0800 CST                    creating
```

查看模型服务部署状态：

```bash
tictl model list
```

返回结果：
```
NAME           CREATED                          URL                STATE      MESSAGE
mnist-model    2018-05-04 13:49:52 +0800 CST    193.112.231.182    Running    Deployment has minimum availability.
```

从 URL 字段我们看到服务对外暴露的 IP，同时暴露的还有 80(http) 和 9000(rpc) 端口。

## 测试服务是否部署成功

测试 http 接口, 直接访问 URL，可以收到如 'Pong' 的返回，表明服务整体已经处于运行状态。访问 URL/model/`<modelname>`:meta ，如果成功返回 model 的元信息，表明模型已经可以进行 serving 服务。

运行：

```bash
curl 193.112.231.182
```

返回结果：
```
Pong%
```

运行：

```bash
curl http://193.112.231.182/model/mnist-model:meta
```

返回结果：
```
{"serving_default": {"inputs": {"inputs": {"dtype": "DT_STRING", "name": "tf_example:0", "tensorShape": {"unknownRank": true}}}, "methodName": "tensorflow/serving/classify", "outputs": {"classes": {"dtype": "DT_STRING", "name": "index_to_string_Lookup:0", "tensorShape": {"dim": [{"size": "-1"}, {"size": "10"}]}}, "scores": {"dtype": "DT_FLOAT", "name": "TopKV2:0", "tensorShape": {"dim": [{"size": "-1"}, {"size": "10"}]}}}}, "predict_images": {"inputs": {"images": {"dtype": "DT_FLOAT", "name": "x:0", "tensorShape": {"dim": [{"size": "-1"}, {"size": "784"}]}}}, "methodName": "tensorflow/serving/predict", "outputs": {"scores": {"dtype": "DT_FLOAT", "name": "y:0", "tensorShape": {"dim": [{"size": "-1"}, {"size": "10"}]}}}}}%
```

## 测试服务

这里我们使用例子中的测试脚本测试服务（目前还在 beta 阶段，如果环境准备有困难，请跳过此部分）：

1.环境准备

- [安装 TensorFlow](https://tensorflow.google.cn/install/)

- 安装 Serving API：

```bash
pip install tensorflow-serving-api
```

2.查看测试结果

>**注意：**
>这里需要将 mnist_client.py 文件中的 model 名称改为之前创建的模型名，此处为 mnist-model。

```bash
python mnist_client.py --num_tests=100 --server=193.112.231.182:9000
```

返回结果：
```
...
Inference error rate: 7.0%
```

现在，您已完成用 `tictl` 来部署一个服务了！
