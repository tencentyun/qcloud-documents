


训练加速中的通信加速能力通过兼容原生的 DDP、PS 工具提供，用户无需修改原生的使用代码可直接进行使用，数据 IO 优化、自适应 FP16 都通过封装好的简单函数/类进行提供，用户仅需增加几行代码便可使用。

## 使用 DDP 分布式训练通信优化（PyTorch+DPP）

以兼容原生 DDP 的方式启动训练脚本，无需进行训练代码的修改，启动命令参考示例如下：
```
python3 -u -m tiacc_training.torch.distributed.launch --nproc_per_node $GPUS_PER_NODE --nnodes $NNODES --node_rank $NODE_RANK --master_addr $MASTER_ADDR --master_port $MASTER_PORT main.py
```
DDP 分布式训练通信优化实测效果：
（加速效果在多机多卡场景方有体现，单机多卡场景与原生 DDP 性能无异。）

<table>
<thead>
<tr>
<th>硬件环境</th>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生DDP(examples/sec per V100)</th>
<th>TI-ACC通信优化(examples/sec per V100)</th>
</tr>
</thead>
<tbody><tr>
<td rowspan="3">腾讯云GN10Xp.20XLARGE320</td>
<td rowspan="3">resnext50_32x4d</td>
<td>1（单机）</td>
<td>227</td>
<td>227</td>
</tr>
<tr>  
<td>8（单机）</td>
<td>215</td>
<td>215</td>
</tr>
<tr>  
<td>16（双机）</td>
<td>116</td>
<td>158.6</td>
</tr>
</tbody></table>


## 使用自适应混合精度优化（PyTorch）
```
import torch.cuda.amp as amp 
import tiacc_training.torch
scaler = amp.GradScaler() 
#实例化自适应混合精度策略类的对象
policy = tiacc_training.torch .tiacc_torch_warp.MixedPrecision_TrainingPolicy(policy,start_step,hold_step,end_step,interval_time,interval_hold_time)
#根据输入的参数得到当前epoch是否需要开启混合精度
mixed_precision = policy.enable_mixed_precision(epoch,lr=lr,loss=loss,scaler=scaler)
with amp.autocast(enabled=mixed_precision):
     outputs = model(inputs)
     loss = criterion(outputs, targets)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

自适应混合精度优化实测效果：

<table>
<thead>
<tr>
<th>硬件环境</th>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生PyTorch(examples/sec per V100)</th>
<th>TI-ACC 数据 IO 优化(examples/sec per V100)</th>
<th>TI-ACC 数据 IO+自适应混合精度优化(examples/sec per V100)</th>
</tr>
</thead>
<tbody><tr>
<td rowspan="2">腾讯云GN10Xp.20XLARGE320</td>
<td>resnet50  mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
<td>379.2</td>
</tr>
<tr> 
<td>centernet              mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
<td>30.6</td>
</tr>
</tbody></table>

## 使用优化后的 embedding 变量构造（TensorFlow+PS）

```
# 启动容器
docker run -itd --name tiacc-rec-fm --network=host --ipc=host ccr.ccs.tencentyun.com/ti-platform/tensorflow:1.15.5-py3-rec-0121
# 进入容器
docker exec -it tiacc-rec-fm bash
# 原生tensorflow embedding使用方法
cd wideanddeep && bash start_all.sh --fm
# tiacc lookup优化使用方法
cd wideanddeep && bash start_all.sh --tiacc --fm
```

embedding 变量构造+lookup 计算优化实测效果：

<table>
<thead>
<tr>
<th>硬件环境</th>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生 TensorFlow(global_steps/sec per V100)</th>
<th>TI-ACC 优化后(global_steps/sec per V100)</th>
</tr>
</thead>
<tbody><tr>
<td rowspan="2">腾讯云GN10Xp.20XLARGE320</td>
<td>DeepFM</td>
<td>16（双机）</td>
<td>41.9 - 56</td>
<td>96.1 - 103.3</td>
</tr>
<tr> 
<td>Wide &amp; Deep</td>
<td>16（双机）</td>
<td>49.9 - 69</td>
<td>120 - 128</td>
</tr>
</tbody></table>
