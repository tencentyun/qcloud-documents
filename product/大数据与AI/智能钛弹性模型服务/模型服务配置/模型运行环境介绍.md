目前，TI-EMS 提供五种模型运行环境：
- TF-Serving：业界流行的 TensorFlow Serving 模型服务，支持 SavedModel 模型。
- PMML：通用标准的 PMML 模型服务，支持标准 PMML 模型。
- TensorRT：支持模型自动优化的 Tensorflow 模型服务镜像，支持 SavedModel 模型。
- OpenVINO：专门针对 CPU 优化的模型服务镜像，支持 Intermediate Representation(IR) 模型。
- Angel：[腾讯自研的 Angel 框架](https://github.com/Angel-ML/angel)。

### TF-Serving
TI-EMS 提供的 Tfserving 推理运行环境可以加载 Tensorflow SavedModel 模型，
### PMML  
[PMML](https://www.ibm.com/developerworks/cn/opensource/ind-PMML1/)（Predictive Model Markup Language），一种预测模型标记语言，TI-EMS 可以加载标准的 PMML 模型。
### TensorRT
TensorRT 镜像是支持模型自动优化的 Tensorflow 模型服务镜像,支持用户使用 gRPC 和 HTTP 访问模型服务，访问方式兼容 TF-serving 镜像。TensorRT 支持用户上传 Tensorflow saved_model 模型，系统自动对模型进行优化。对8种主流分类模型测试，TensorRT 镜像推理性能相对 TF-serving 镜像平均提升60%以上。对5种主流目标识别模型测试，平均性能提升40%以上。

**使用 TensorRT 镜像可能遇到问题说明**：
- 模型启动时间较长：因为需要做模型优化，模型启动时间可能会比较长。对于某些大模型，例如 NASNET，模型启动时间可能需要3到5分钟。
- 模型首次推理时间较长：系统会根据用户上传数据大小生成最优代码，模型首次推理时间（仅限首次推理时间）可能需要0.5-5分钟。
- 模型加载失败：因为 Tensorflow 对读取 protobuf 文件大小限制，单个 protobuf 文件大于1GB会读取失败。即使上传模型小于1GB，模型优化过程也可能会生成大与1GB模型文件而导致加载失败。
- 模型服务失败：Tensorflow自动模型优化功能在快速迭代中，某些优化后的 saved_model 可能会服务失败，请通过 [智能钛 AI 开发者社区](https://cloud.tencent.com/developer/timl/ask) 讨论相关问题，腾讯云 AI 专家会及时帮助解答。 
- TensorRT 镜像相对 TF-serving 镜像推理性能提升不明显。请联系腾讯云客服，针对大客户，腾讯云 AI 专家可以针对具体模型深度优化。

### OpenVINO
OpenVINO 镜像是专门针对 CPU 优化的模型服务镜像，支持用户上传 OpenVINO Intermediate Representation（IR）模型，支持 HTTP 和 gRPC 访问模型服务，模型访问方式兼容 TF-serving 镜像。 对5种主流分类模型测试，OpenVINO 镜像推理性能相对 TF-serving 镜像平均提升2.4倍以上。对4种主流目标识别模型测试，OpenVINO 镜像推理性能相对TF-serving镜像平均性能提升30%以上。

**使用 OpenVINO 镜像可能遇到问题说明**：
- 模型推理结果有误：因为 OpenVINO 模型转换包括数据预处理，请检查模型转换过程参数设置，本地验证 IR 推理结果正确后再长传模型。
- OpenVINO 镜像推理性能问题。请联系腾讯云客服，针对大客户，腾讯云 AI 专家可以针对具体模型深度优化。
- 如何将 Tensorflow/Caffe/MXNET/ONNX 等模型转换为 OpenVINO IR 模型，请参考 [模型格式转换](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html)。
- HTTP 接口调用仅支持数值数据类型，详情请参考：[OpenVINO 接口调用说明](https://github.com/IntelAI/OpenVINO-model-server)。

### Angel
腾讯自研深度学习框架，Angel 相关内容请访问 [腾讯自研的 Angel 框架](https://github.com/Angel-ML/angel)。

### 自定义运行环境
TI-EMS 可支持用户使用自定义运行环境，您可以在 TI-EMS 上导入自定义镜像，并且使用您的镜像加载模型。该功能需要联系 TI-EMS 工程师进行开通，请单击 [联系我们](https://cloud.tencent.com/apply/p/nx0bbybrhuf)。