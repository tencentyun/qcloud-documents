目前，TI-EMS 提供五种模型运行环境：
- TF-Serving：Tensorflow v1.13.1，业界流行的 TensorFlow Serving 模型服务，支持 SavedModel 模型。
- PMML：通用标准的 PMML 模型服务，支持标准 PMML 模型。
- TensorRT：Tensorflow v1.13.1，支持模型自动优化的 Tensorflow 模型服务镜像，支持 SavedModel 模型。
- OpenVINO：OpenVINO-model-server v2019.1.1，专门针对 CPU 优化的模型服务镜像，支持 OpenVINO Intermediate Representation(IR) 模型。
- Angel：[腾讯自研的 Angel 框架](https://github.com/Angel-ML/angel)，支持 PMML 和 Angel 模型。

### TF-Serving
TI-EMS 提供的 TF-Serving 推理运行环境可以加载 Tensorflow SavedModel 模型。
### PMML  
[PMML](https://www.ibm.com/developerworks/cn/opensource/ind-PMML1/)（Predictive Model Markup Language），一种预测模型标记语言，TI-EMS 可以加载标准的 PMML 模型。
### TensorRT
TensorRT 镜像是支持模型自动优化的 Tensorflow 模型服务镜像,支持用户使用 gRPC 和 HTTP 访问模型服务，访问方式兼容 TF-Serving 镜像。TensorRT 支持用户上传 Tensorflow SavedModel 模型，系统自动对模型进行优化。对8种主流分类模型测试，TensorRT 镜像推理性能相对 TF-Serving 镜像平均提升60%以上。对5种主流目标识别模型测试，平均性能提升40%以上。
上述测试模型详情如下：

| 模型类型 | 模型名称 |
|---------|---------|
| 分类 | Inception_v3、Inception_V4、MobileNet_V1、NasNet_Mobile、NasNet_Large、ResNet_V2_50、Xception、DenseNet169 | 
| 目标检测 | IFaster_R-CNN_Nas、Mask_R-CNN_ResNet_50、SSD_Inception_V2、SSD_MobileNet_V1、SSD_ResNet_50_FPN | 

**使用 TensorRT 镜像可能遇到问题说明**：
- 模型启动时间较长：因为需要做模型优化，模型启动时间可能会比较长。对于某些大模型，例如 NasNet，模型启动时间可能需要3到5分钟。
- 模型首次推理时间较长：系统会根据用户上传数据大小生成最优代码，模型首次推理时间（仅限首次推理时间）可能需要0.5 - 5分钟。
- 模型加载失败：因为 Tensorflow 对读取 protobuf 文件大小限制，单个 protobuf 文件大于1GB会读取失败。即使上传模型小于1GB，模型优化过程也可能会生成大于1GB模型文件而导致加载失败。
- 模型服务失败：Tensorflow 自动模型优化功能在快速迭代中，某些优化后的 SavedModel 可能会服务失败，请通过 [智能钛 AI 开发者社区](https://cloud.tencent.com/developer/timl/ask) 讨论相关问题，腾讯云 AI 专家会及时帮助解答。 
- TensorRT 镜像相对 TF-Serving 镜像推理性能提升不明显。请联系腾讯云客服，针对大客户，腾讯云 AI 专家可以针对具体模型深度优化。

### OpenVINO
OpenVINO 镜像是专门针对 CPU 优化的模型服务镜像，支持用户上传 OpenVINO Intermediate Representation（IR）模型，支持 HTTP 和 gRPC 访问模型服务，模型访问方式兼容 SavedModel 镜像。 对5种主流分类模型测试，OpenVINO 镜像推理性能相对 TF-Serving 镜像平均提升2.4倍以上。对4种主流目标识别模型测试，OpenVINO 镜像推理性能相对 TF-Serving 镜像平均性能提升30%以上。
上述测试模型详情如下：

| 模型类型 | 模型名称 |
|---------|---------|
| 分类 | Inception_v1、Inception_v3、VGG-19、ResNet_V1_50、NasNet_Large | 
| 目标检测 |Mask_R-CNN_Inception_V2_COCO、RFCN_ResNet_101_COCO、MobileNet-SSD_V1_COCO、Faster_R-CNN_Inception_V2_COCO  | 

**使用 OpenVINO 镜像可能遇到问题说明**：
- 模型推理结果有误：因为 OpenVINO 模型转换包括数据预处理，请检查模型转换过程参数设置，本地验证 IR 推理结果正确后再上传模型。
- OpenVINO 镜像推理性能问题。请联系腾讯云客服，针对大客户，腾讯云 AI 专家可以针对具体模型深度优化。
- 如何将 Tensorflow/Caffe/MXNET/ONNX 等模型转换为 OpenVINO IR 模型，请参考： [模型格式转换](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html)。
- HTTP 接口调用仅支持数值数据类型，详情请参考：[OpenVINO 接口调用说明](https://github.com/IntelAI/OpenVINO-model-server)。

### Angel
腾讯自研深度学习框架，Angel 相关内容请访问 [腾讯自研的 Angel 框架](https://github.com/Angel-ML/angel)。





