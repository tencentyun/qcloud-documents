<dx-accordion>
::: Mysql 数据源
## 读取
### 配置参数说明

| 参数 | 说明 | 
|---------|---------|
| 数据源	| 选择已经配置好的 MySQL 数据源，此处仅支持 MySQL Binlog 方式同步（如果未配置数据源，请单击右侧的**新建数据源**，进入**项目管理 > 数据源管理**页面进行新建）<br> ![](https://qcloudimg.tencent-cloud.cn/raw/748208bc5dbcb4ca87c22725a3b38f20.png)| 
| 表	| 选择当前数据源下需要同步的表名称。MySQL 同步支持实现分库分表的场景，配置的库和表会在该任务中同时进行实时同步（分库分表中的数据表的 Schema 请保持一致，以避免执行报错）| 
| 格式	| 指定 MySQL 日志编码格式。当前版本支持 UTF-8、GBK、LATIN1、UTF8MB4四种格式| 

### 字段类型转换

| Kafka Schema 设定数据类型 | 同步任务转换类型 | 
|---------|---------|
| TINYINT	| TINYINT| 
| SMALLINT	| SMALLINT| 	
| INT	| INT	| 
| BIGINT	| BIGINT	| 
| FLOAT	| FLOAT	| 
| DOUBLE	| DOUBLE| 	
| DECIMAL	| DECIMAL	| 
| BOOLEAN	| BOOLEAN	| 
| DATE	| DATE	| 
| TIMESTAMP	| TIMESTAMP	| 
| CHAR(n)	| CHAR(n)| 	
| STRING	| STRING| 	
| BYTES	| BYTES| 	

## 分库分表
通过单击**分库分表**可以选择多个不同数据库下需要执行数据读取任务的库表，每次点击都会生成新的库表选择框，但分库分表需要保证所有表 schema 一致。
![](https://qcloudimg.tencent-cloud.cn/raw/ab18663115d320f642f8d768dccef28e.png)

:::
::: kafka 数据源
## 读取
### 参数信息说明

| 参数 | 说明 | 
|---------|---------|
| 数据源	| 选择已经配置好的 Kafka 数据源（如果未配置数据源，请单击右侧的**新建数据源**，进入**项目管理 > 数据源管理**页面进行新建）<br> ![](https://qcloudimg.tencent-cloud.cn/raw/52ba1e646ee25b56361d2bfacd193b2f.png)| 
| Topic	| Kafka 的 Topic 名称，是 Kafka 处理资源的消息源的不同分类。每条发布至 Kafka 集群的消息都有一个类别，该类别被称为 Topic，一个 Topic 是对一组消息的归纳（同步任务中，一个 Ckafka 数据源仅支持选择一个 Topic 作为数据输入）| 
| 消息输出格式	| 选择 Kafka 消息解析格式配置。当前版本支持 Canal Json、Json、CSV、avro| 
| 启动位点	| 控制实时同步任务开始同步数据的启始位点：<li>Latest：默认，从每个分区最新的位置开始读取	<li>Earliest：从每个分区最开始的位置开始读取| 
| Schema	| 选择 Topic 对应的 Schema，选填。此处 Schema 来自于腾讯云 Wedata 的 Schema 管理器，仅在腾讯云 Wedata 中进行过 MySQL 到 Kafka 数据同步的 topic 有相应的 Schema 信息（Schema 的产生及配置操作请参见【第5节-5.4数据去向配置-Ckafka数据去向】）|

### 字段类型转换

| Kafka Schema 设定数据类型 | 同步任务转换类型 | 
|---------|---------|
| TINYINT	| TINYINT| 
| SMALLINT	| SMALLINT| 
| INT	| INT	| 
| BIGINT	| BIGINT| 	
| FLOAT| 	FLOAT	| 
| DOUBLE	| DOUBLE	| 
| DECIMAL	| DECIMAL| 	
| BOOLEAN	| BOOLEAN	| 
| DATE| 	DATE	| 
| TIMESTAMP| 	TIMESTAMP	| 
| CHAR(n)	| CHAR(n)	| 
| STRING| 	STRING| 	
| BYTES	| BYTES	| 

## 写入
### 参数信息说明

| 参数 | 说明 | 
|---------|---------|
| 数据源	| 选择已经配置好的 afka 据源（如果未配置数据源，请单击右侧的**新建数据源**，进入**项目管理 > 数据源管理**页面进行新建）<br> ![](https://qcloudimg.tencent-cloud.cn/raw/ef36d526bea96595bd3c0f65f9c095be.png) | 
| Topic	| Kafka 的 Topic 名称，是 Kafka 处理资源的消息源的不同分类。每条发布至 Kafka 集群的消息都有一个类别，该类别被称为 Topic，一个 Topic 是对一组消息的归纳（同步任务中，一个 Ckafka 数据源仅支持选择一个 Topic 作为数据输入）| 
| 数据序列号格式	| 选择 Kafka 消息转换写入的格式。当前版本支持 Canal Json、Json、CSV、avro| 
| 保存 Schema	| 配置是否保存 Kafka 中 Topic 的 Schema 结构，该结构将于数据来源段表结构保持一致。保存该 Schema 信息可在后续 Ckafka 作为数据来源的同步任务中使用（该 Schema 命名方式为：${TableName}(${DBName})_${TopicName}(${CkafkaName})）| 

### 字段类型转换

| 同步任务转换类型 | Kafka Schema 设定数据类型 | 
|---------|---------|
| TINYINT| 	TINYINT| 
| SMALLINT	| SMALLINT	| 
| INT	| INT| 	
| BIGINT	| BIGINT| 	
| FLOAT| FLOAT	| 
| DOUBLE	| DOUBLE| 	
| DECIMAL	| DECIMAL	| 
| BOOLEAN	| BOOLEAN	| 
| DATE| 	DATE| 	
| TIMESTAMP	| TIMESTAMP	| 
| CHAR(n)	| CHAR(n)	| 
| STRING	| STRING	| 
| BYTES	| BYTES	| 

:::
::: EMR Hive 数据源
## 写入
### 参数信息说明

| 参数 | 说明 | 
|---------|---------|
| 数据源	| 选择项目下绑定的 EMR Hive 数据源| 
|目标 DB	| 选择当前数据源下需要同步的数据库名称| 
| 目标表名	| 选择当前数据源下需要同步的表名称，可单击**一键生成目标表**根据源表结构快速构建 Hive 表| 


### 字段类型转换

| Kafka Schema 设定数据类型 | 同步任务转换类型 | 
|---------|---------|
| TINYINT	| TINYINT| 
| SMALLINT	| SMALLINT| 
| INT	| INT	| 
| BIGINT	| BIGINT| 	
| FLOAT| 	FLOAT	| 
| DOUBLE	| DOUBLE	| 
| DECIMAL	| DECIMAL| 	
| BOOLEAN	| BOOLEAN	| 
| DATE| 	DATE	| 
| TIMESTAMP| 	TIMESTAMP	| 
| CHAR(n)	| CHAR(n)	| 
| STRING| 	STRING| 	
| BYTES	| BYTES	| 

:::
</dx-accordion>
