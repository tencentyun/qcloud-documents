数据湖计算 DLC 提供了基于原生 Spark 的批处理、流计算能力，支持用户通过数据任务进行复杂的数据处理、ETL 等操作。
目前数据作业的 Spark 相关版本支持如下：
- Scala 2.12.*版本。
- Spark 3.1.2版本。

## 使用准备
>? 数据作业目前为邀请内测阶段，如您需使用体验可 [提交工单](https://console.cloud.tencent.com/workorder/category) 联系我们开通体验。
>
在开始使用数据作业前，为了保证您的数据安全，您需要先创建数据访问策略，详细配置说明请参见 [配置数据访问策略](https://cloud.tencent.com/document/product/1342/74583)。
同时，我们支持使用 Ckafka 作为数据源进行数据作业配置，详细配置说明请参见 [数据源 Ckafka 配置](https://cloud.tencent.com/document/product/1342/74586)。后续我们也将持续丰富数据源支持，为您提供更全面的数据作业使用场景。

## 计费模式
数据作业将根据使用数据引擎进行计费，目前支持按量计费和包年包月两种模式。详情可参见 [数据引擎说明](https://cloud.tencent.com/document/product/1342/74173)。
- 按量计费：适合数据作业量较少或周期性使用的场景，创建作业后拉起使用，作业运行完成后自动挂起不再产生费用。
- 包年包月：适合数据作业量较大同时很稳定使用的场景，按月付费预留资源，无需等待数据引擎拉起。
>! 由于数据作业与 SQL 作业的计算引擎类型差异，需要单独购买 Spark 作业类型的数据引擎，无法使用 SparkSQL 类型的数据引擎运行数据作业。
>

## 作业管理
通过**数据作业**管理菜单，您可以对数据作业进行创建、启动、修改、删除。
1. 登录 [数据湖计算控制台](https://console.cloud.tencent.com/dlc)，单击左侧菜单**数据作业**进入数据作业管理页。
2. 单击**创建数据作业**按钮，即可创建新的数据作业，详细步骤请参见 [创建数据作业](https://cloud.tencent.com/document/product/1342/74584)。
3. 在列表内可以查看数据作业当前任务的状态，同时支持管理数据作业，详细步骤请参见 [管理数据作业](https://cloud.tencent.com/document/product/1342/74585)。
