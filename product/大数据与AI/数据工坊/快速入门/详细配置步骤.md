## 第一步：创建工程和配置基本信息

登录 TDF 后，首先进入总览页面。如果是初次进入，则无工程和表信息。
单击创建工程，如下图，输入工程名（例如 game_log）。工程标识前缀为系统唯一标识符自动生成。工程管理员默认为用户本人；计算引擎为系统默认设置。

创建成功后，可在总览视图看到所创建的工程基本信息,如下图所示：

![](//mc.qcloudimg.com/static/img/06c8eceab547787d14ea1a9676bfb93d/image.png)

## 第二步：创建数据表

数据表可理解为数据处理过程中在 TDF 所存放的位置。

在本示例中，需要用到两个表：原始数据表（用于存放从 CDB MySQL 导入的数据，例如 game_tdf_raw），以及结果表（用于存放分析后的结果，例如 game_tdf_dest），过程如下：

### 创建原始数据表

单击管理控制台，在【数据管理–表管理】单击屏幕右侧【新建表】按钮，开始创建数据表。填写表名 game_tdf_raw，选择刚刚创建的工程 game_log。

在高级设置中，选择表的记录格式和对应文件格式，按照默认设置即可。

![](//mc.qcloudimg.com/static/img/397ecacfe32cc7830fdb13bbda5456b9/image.png)

单击下一步，设置表中的字段。本例中不使用分区，在本例子中，我们只打算分析用户接入日志中不同 http_code 类型的数量，因此，仅选择如下8个字段进行分析：

access_time,host,http_code,ip,isp,province,request_time,request_uri

初始编辑界面类似如下图所示：

![](//mc.qcloudimg.com/static/img/3469746d6316a4a4ae8e4f1022720141/image.png)

创建后，可在【数据管理-表管理】中，查询表结构，如下：

![](//mc.qcloudimg.com/static/img/57609ebae37fd255913a915587bc5683/image.png)

### 创建结果表

单击管理控制台，在【数据管理 –表管理】单击屏幕右侧【新建表】按钮，开始创建数据表。

填写表名 game_tdf_dest，选择刚刚创建的工程 game_log。

在高级设置中，选择表的记录格式和对应文件格式，按照默认设置即可，

单击下一步，设置表中的字段。在本例子中，我们只打算记录不 http_code类型的数量结果，因此，仅选择如下两个个字段且不使用分区：http_code，count

创建后，可在【数据管理-表管理】中，查询表结构，如下图所示：

![](//mc.qcloudimg.com/static/img/d83b3b7bc23c283831e46598223effe6/image.png)

此结构需同最终计算完毕后，拟用于存放结果的 CDB MySQL表game_result结构相同。

## 第三步：设置数据源

在【工程管理-数据源管理】，单击【+新建配置】。

选择服务器类型：云数据库 CDB-MySQL，编辑服务器标识（前缀由系统自动生成，自行输入部分例如【game_log_raw】），和服务器说明（例如【game_log原数据】），责任人默认为当前用户，下拉选择 CDB 数据库实例【game_analysis】（之前在 CDB 配置），下拉选择数据库名称【game】（之前在 CDB 配置），并输入对应用户名密码，连接后，即完成数据库配置。

![](//mc.qcloudimg.com/static/img/1f01893105ddf88c750c0986cb47d4c4/image.png)

## 第四步：创建工作流

在【数据开发-工作流开发】界面，下拉选择刚刚创建的工程【game_log】，然后选择新创建工作流列表。

![](//mc.qcloudimg.com/static/img/35caf2fae2d402d324a92780a1de6305/image.png)

## 第五步：创建数据接入任务

拖拽任务节点【数据接入-CDB MySQL导入Hive】，并单击右键编辑，基本信息配置，任务名称命名为【导入game_log任务】，类型默认为【CDB MySQL导入Hive】，责任人为默认当前用户，输入输出配置。

源数据库：选择之前创建的后缀为【game_log_raw】数据库。

源数据库查询 SQL 语句：例如如下语句

select access_time,host,http_code,ip,isp,province,reques
t_time,request_uri from game_log。

即仅检索以上8个字段，顺序和字段名严格按照CDB MySQL的顺序和字段名。

目标表所在工程：选择当前TDF工程game_log

目标表：选择之前建立的TDF表game_tdf_raw

目标表列名映射：

access_time,host,http_code,ip,isp,province,request_time,request_uri

分区格式选择【无分区】，其余设置按照默认值。

![](//mc.qcloudimg.com/static/img/ca4a0a593314aa3d27d0065fbc24ad8e/image.png)

## 第六步：创建 HQL 计算任务

该任务为计算日志中不同的 http_code 对应的记录数量。任务脚本参数如下图所示：

![](//mc.qcloudimg.com/static/img/6992a1f4a31e7c8251517e741e456f16/image.png)

其中，SQL脚本代码如下：

use 数据库名称;
insert overwrite table game_tdf_dest select http_code,count(http_code) from game_tdf_raw group by http_code。

其中数据库名称需填入文本框上方的数据库名。此语句将TDF日志原始表中的记录按照 http_code 不同类别计数，并将结果存放回TDF分析结果表game_tdf_dest。

## 第七步：创建数据导出任务

拖拽任务节点【数据导出-Hive导出CDB MySQL】，并单击右键编辑。
基本信息配置，任务名称命名为【game导出任务】，类型默认为【Hive导出CDB MySQL】，责任人为默认当前用户。

输入输出配置中，选择源数据库所在工程【game_log】，查询语句为 select * from game_tdf_dest，即将上一个任务节点 Hive 计算得到的结果表 game_tdf_dest 内容全部回写到 CDB MySQL，下拉选择目标数据库以及目标表（即 CDB 已有数据库和目标表），目标表列名映射为：

http_code,count，其余按照默认值即可。即如下配置：

![](//mc.qcloudimg.com/static/img/3558fe2fadb61c801514b7e02750b09f/image.png)

## 第八步：保存工作流并发布

任务节点编辑完毕后，检查节点见的依赖关系，如下图连线可见。

![](//mc.qcloudimg.com/static/img/55d6b168909868d1cced8faa2adbebb7/image.png)

单击保存，和发布任务按钮，系统将提示确认调度信息，如下，选择单次执行。

![](//mc.qcloudimg.com/static/img/e1d3e278d98bf1ceafc6f324f80923c9/image.png)

发布后，在运维中心的任务列表视图可以按照工程维度查看当前的工作流的实时状态。当工作流状态切换为成功后，任务即全部运行成功（根据数据量和系统负载不同，任务运行时间将会略有区别）。

![](//mc.qcloudimg.com/static/img/429a867562f9d9dae082b504a28d58c1/image.png)

## 第九步：分析结果展示

按照前序设定，查询结果将首先写入TDF 表，随后再写入 CDB 对应数据库。当工作流状态成功后，可使用数据库管理客户端，对 CDB 表进行查询。例如，执行完如下语句 select * from game_result 后，系统显示结果如下：

![](//mc.qcloudimg.com/static/img/d611efa7a3b7eea8de75f0bea8f2a025/image.png)

即在所有日志中，http_code 不同类型类型对应的计数结果如上。

也可以选择通过可视化报表软件，将最终结果进行图形化展示。







