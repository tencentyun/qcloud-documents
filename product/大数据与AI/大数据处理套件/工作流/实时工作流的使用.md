## 1、示例任务介绍  ##
本示例以一个实时任务流介绍实时任务处理的操作方法。
数据流向：kafka—>JStorm—>MySQL
kafka 作为消息缓存队列，JStorm 做逻辑处理，MySQL 做数据永久存储。
按照【快速入门->创建工作流】的做法，新建一个工作流。

## 2、数据导入与计算  ##
2.1 这里默认消息已经导入到 kafka 里，故基于实时消息接入后，数据计算直接使用 JStorm 落地
JStorm 的示例代码如下：
![示例代码](https://i.imgur.com/dGFVEVw.png)
代码即消费kafka消息后，再存入到 MySQL 的方式。代码需要打包为 jar 包的形式。

2.2 在工作流画布新建一个 JStorm 任务，右击【编辑】，详细配置如下：
![参数配置](https://i.imgur.com/BdoigtZ.png)    
填入 JStorm 的 Topology 名称，Topology 类以及参数,程序包从本地上传脚本即可。（Storm相关编程知识可通过搜索引擎查询）

## 3、数据导出 ##
**3.1 数据导出示例介绍**
本示例中直接用 JStorm 落地存储，故没有使用到工作流的实时数据导出。如下为实时数据导出的示例，在工作流画布新建一个 **KAFKA导出HDFS** 任务。
![hdfs任务](https://i.imgur.com/iZ3QhgD.png)    
右击【编辑】，填写详细配置信息。
![HDFS配置](https://i.imgur.com/LyY97dY.png)
详细配置如下：
（1）任务名称，责任人，任务说明和所有工作流任务一致
（2）任务类型：目前支持 tube（kafka）导出到 HDFS 和 HBase，本例以导出到 HDFS 为例
（3）周期类型：实时任务只可选择一次性非周期
（4）消息中间件 topic：即 tube（kafka）的 topic 名称
（5）消息中间件group：即 tube（kafka）的消费组名称
（6）HDFS 目标目录：导出到 HDFS 的目录
（7）HDFS 地址：即 HDFS 的 activenamenode 地址（本套件已做了 HA，地址为 hdfsCluster）
（8）文件最大落地大小：即消息中间件的消息积累的消息量才落地的 HDFS 的最大值

**3.2 其他实时数据导出方式**
目前支持的其他实时导出方式为导出到HBase，首先新建一个 **KAFKA导出HBASE**  任务。
![Hbase](https://i.imgur.com/aVX0wpD.png)     
右击选择【编辑】，填写详细配置信息。
![HBase配置](https://i.imgur.com/LVnf7NC.png)
详细配置如下：
（1）消息中间 topic，消息中间件 group 和导出到 HDFS 类似
（2）HBase 表名，行主键，列簇，字段描述，分隔符即 HBase 表相关信息
（3）Zookeeper 根节点：即 HBase 在上 zookeeper 上注册的 znode 名称
