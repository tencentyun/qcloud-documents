## 1 实时数据接入应用介绍

### 1.1 方案介绍

**适用场景**

用户业务系统的实时的结构化数据需要保存到 Hive 表中，以供存储、查询或者离线分析，不适合需要低延迟的应用，例如实时分析系统。

**模块介绍**

图1-1 系统模块图

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-5.png)

**Nginx（"engine x"） ：**是一个高性能的 HTTP 和反向代理服务器，其稳定性好、占有内存少，并发能力强。本系统利用其反向代理能力供外部网络的客户访问 DSE 服务，同时利用了它的软负载能力。

**DSE（Data Service Engine）：**是腾讯自研的服务运行容器，提供统一化的通讯协议与调用接口，支持 RPC 和 Servlet 协议，可以降低分布式服务的开发成本，使得开发人员只专注于业务逻辑，无需考虑通讯协议、容灾、负载均衡等通用逻辑。本系统基于 DSE 开发一插件，接受用户的 HTTP 请求，并把数据保存到 kafka。

**Kafka：**是一个高性能跨语言分布式的发布/订阅的消息队列系统，具有很好的扩展性、消息峰值处理能力、可恢复性、冗余性、异步通信能力等，具有较高的吞吐率，在一台普通服务器上的可以达到10W/s的吞吐速率，是完全的分布式系统，其 Broker、Producer、Consumer 都原生自动支持分布式，自动实现负载均衡。本系统利用其解耦数据生产者和数据消费者，把用户生产的实时数据写入到离线系统 Hive 表中。

**Lhotse：**是腾讯自研的大数据任务调度系统，提供55余种调度任务插件，并提供灵活的任务插件扩展机制，支持 Java、C++、PHP、Python、Shell 等常见编程语言。调度时间周期灵活多样，支持分钟、小时、日、周、月等级别，且可支持多个周期设置。目前 Lhotse 已经能支撑每日调度百万次，超过淘宝每日10万次的调度，属于业内领先。本系统采用 Lhotse 调度 camus 插件，周期性的把数据从 kafka 导入到 HDFS 中。

**Camus：**是 LinkedIn 的开源项目，负责把数据从 kafka 导入到 HDFS，它自己维护 kafka topic 的偏移量，采用 Mapreduce Job，周期性把 kafka 里的实时数据分批导出到 HDFS。本系统对其进行了改造，让其作为 Lhotse 的一个插件，被 Lhotse 周期性的调度执行；对于每一个调度周期，都支持重复导入该周期的数据。Camus 把数据导入到 HDFS 后，再加载到 Hive 外表中。

**Hive：**是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sql 语句转换为 MapReduce 任务进行运行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用，十分适合数据仓库的统计分析。

本系统有两条主线，即数据生产者主线和数据消费者主线。数据生产者主线：用户向 Nginx 发送 HTTP 请求，发送数据， Nginx 把请求转发到 DSE，由 DSE 把数据写入到 Kafka。数据消费者主线：Lhotse 定期调度 camus 插件，由 camus 插件从 kafka 读取数据，保存到 HDFS，再加载到 Hive 外表中。 用户与本系统的数据交互流程如图1-2所示：

图1-2 用户使用交互图

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-6.png)

### 1.2 资源评估

**服务器配置要求**

腾讯大数据套件默认使用腾讯云提供的云服务器，企业也可根据自己需求灵活选择机型。安装腾讯大数据套件的服务器配置要求如表2-1所示。

表2-1 服务器最低配置

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>硬件</b>
</th><th> <b>推荐配置</b>
</th></tr>
<tr>
<td> CPU
</td><td> 最低配置：1路8核 Intel 处理器或者双路4核 Intel 处理器。<br>推荐配置：双路8核 Intel 处理器。
</td></tr>
<tr>
<td> Bit-mode
</td><td> 64位
</td></tr>
<tr>
<td> 内存
</td><td> &gt;= 64GB<br>如果有条件可以选择更大的内存，以提升集群的计算能力。
</td></tr>
<tr>
<td> 磁盘空间
</td><td> 磁盘空间要求：操作系统所在盘 &gt;= 8G,每个非操作系统盘 &gt;= 500GB。
</td></tr></tbody></table>

**运行环境要求**

保障腾讯大数据套件系统正常运行的本地环境要求如表2-2所示。

表2-2 软件环境要求

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>软件</b>
</th><th> <b>要求</b>
</th></tr>
<tr>
<td> 操作系统
</td><td> 目前支持如下操作系统，一个集群中的所有服务器需要采用同一种操作系统：<br>CentOS-6.2-x86_64
</td></tr>
<tr>
<td> 浏览器
</td><td> Google Chrome 21及以上版本
</td></tr>
<tr>
<td> JDK
</td><td> 1.7及以上版本
</td></tr></tbody></table>

**软件部署方案**

需要安装的软件清单如表2-3所示。

表2-3软件清单

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>服务名称</b>
</th><th> <b>版本号</b>
</th></tr>
<tr>
<td> Ambari
</td><td> 2.0
</td></tr>
<tr>
<td> Nginx
</td><td> 0.1.0
</td></tr>
<tr>
<td> DSE（自研）
</td><td> 0.1.0
</td></tr>
<tr>
<td> Kafka
</td><td> 0.8.1.2.2
</td></tr>
<tr>
<td> Hive
</td><td> 0.14.0.2.2
</td></tr>
<tr>
<td> ZooKeeper
</td><td> 3.4.6.2.2
</td></tr>
<tr>
<td> Yarn
</td><td> 2.6.0.2.2
</td></tr>
<tr>
<td> Mapreduce2
</td><td> 2.6.0.2.2
</td></tr>
<tr>
<td> Lhotse（自研）
</td><td> 1.0.0
</td></tr>
<tr>
<td> HDFS
</td><td> 2.6.0.2.2
</td></tr></tbody></table>

软件部署原则如表2-4所示。

表2-4 软件部署原则

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>服务</b>
</th><th> <b>服务组件</b>
</th><th> <b>部署个数</b>
</th><th> <b>备注</b>
</th></tr>
<tr>
<td> Nginx
</td><td> Nginx Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td rowspan="2">DSE（自研）
</td><td> Dse Database
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> DSE Server
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td rowspan="2">Kafka
</td><td> Kafka Manager
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Kafka Broker
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td rowspan="4">Hive
</td><td> Hive Metastore
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> HiveServer2
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> MySQL Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> WebHCat Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> ZooKeeper
</td><td> ZooKeeper Server
</td><td> 3
</td><td> 部署奇数个，集群大于三个节点，建议不小于3个
</td></tr>
<tr>
<td rowspan="3">Yarn
</td><td> App Timeline Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> ResourceManager
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> NodeManager
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td> Mapreduce2
</td><td> History Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td rowspan="6">Lhotse（自研）
</td><td> Lhotse Base
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse Database
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse FTP
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse Service
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse Web
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse Runners
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td rowspan="3">HDFS
</td><td> NameNode
</td><td>
</td><td>
</td></tr>
<tr>
<td> SNameNode
</td><td>
</td><td>
</td></tr>
<tr>
<td> DataNodes
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr></tbody></table>

>?各个服务的安装方法请参考《大数据套件用户手册》。


关键组件部署个数评估如表2-5所示。

表2-5 关键组件部署评估

<table>
<tbody>
<tr>
<th> <b>组件</b>
</th><th> <b>考虑因素</b>
</th><th> <b>部署个数</b>
</th></tr>
<tr>
<td> DataNode
</td><td> 业务数据量
</td><td> DataNode 为集群中各个组件提供基础的数据存储能力，部署越多，存储容量越大，建议每个节点都部署一个。
</td></tr>
<tr>
<td> NodeManager
</td><td> 运行性能
</td><td> 与客户的性能需求有关，理论上部署的越多，可以提供越多的计算资源，至少部署一个，建议每个节点都部署一个。
</td></tr>
<tr>
<td> Lhotse Runner
</td><td> 调度任务业务量
</td><td> 最小配置1个，在实际生产环境中，可根据调度任务量适当部署。
</td></tr>
<tr>
<td> Kafka Broker
</td><td> 业务数据量
</td><td> 不小于 topoic 最大的 replication 数。如所有的 topic 中，最大的 replication 为 n，则 Broker 个数 &gt;= n。为保障数据的可靠性，建议 broker 个数不小于3个。
</td></tr></tbody></table>

**集群节点个数评估**

集群节点个数主要从业务数据规模角度进行评估，假设客户的总业务量为 M, 每天的业务量为 N。
在数据接入过程中，需要用到集群存储的主要环节有：Kafka 存储 topic 数据、camus 跑 MR 任务 shuffle 流程占用空间和最终保存在 HDFS 上的 hive 表数据。 
为保障业务数据保存在分布式系统上的可靠性，kafka 和 hdfs 的数据副本数一般都设置为3（建议配置），且 kafka 上的数据只保存3天，超过3天，其空间会被循环利用，那么 kafka 需要的最大空间为3N；而 MR 的 shuffle 流程，数据有膨胀，膨胀系数估算为2，当任务完成后，空间即被释放，假设每个任务都是当天完成，则需要的存储空间为2N。

综上分析，数据接入过程中，主要环节需要的存储空间为：3M + 3N + 2N，再加上其他服务所需的存储空间，乘以一个系数1.2，则需要的集群节点数为：(3M + 3N + 2N) * 1.2 / 500GB。 假设业务数据量有5T，每天的业务量为500G,那么需要的节点数为：(3 * 5T + 3 * 500G + 2 * 500G) * 1.2 / 500G = 42

>?
1. 该评估建立的前提是：仅仅是数据接入需要的节点数，如果该集群还有其他业务，还需要增加节点数（根据其他业务情况评估）。
2. MR shuffle 占用的空间，只是临时空间，MR 任务跑完后即释放，接入任务完成后，其实只需要3M + 3N的存储空间，因此其3M + 3N + 2N是需要的峰值存储空间。
3. 当前的评估是基于存储空间进行评估的，若想降低节点数，可以增加每个节点的硬盘数。若想提升系统导入性能，可以加强硬件配置，或者增加节点数。

### 1.3 系统参数配置
各个服务的参数使用系统默认配置即可，这里主要介绍创建 Lhotse 任务的参数配置。在 lhotse 系统的任务管理标签里单击新增任务，创建一个新增任务，任务类型选择数据导入 Kafka 入库 hive，弹出如图3-1页面。

图3-1 Kafka 入库 hive 配置页面

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-7.png)

各参数含义如下：

**任务名称：**该任务的名称，不能与其他任务名称重名。

**周期类型：**调度支持的周期类型：月、周、日、小时、分钟和非周期，其中非周期指任务只执行一次。
起始数据时间：数据导入的起始时间。

**调度时间：**每个任务在到达调度周期后，延迟多长时间开始执行任务。

**超时时间：**任务执行的超时时间，单位为秒。

**Hive表名：**Hive 表名,默认加到 default 数据库；若想指定到特定数据库，其格式为：databaseName.tableName。在创建该 lhotse 任务之前，该表不能存在，由系统自动创建该表。

**Hive表分区字段名：**Hive 表的分区字段名，类型为 string，一个 Hive 表只支持一个分区。

**Hive表字段名：**Hive 表的字段名,多字段之间以逗号分割，不包括分区字段名。每个字段为 string 类型。

**读并发度：**需要多少个进程同时导入数据。

**Kafka Broker列表：**集群中的所有 Kafka Broker 集合，格式为：brokerIp:brokerPort；多个 borker 之间以逗号分割，如：brokerIp1:port,brokerIp2:port。

**Topic：**kafka 的 topic，需要从哪个 topic 消费数据。

**字段分隔符：**用户产生的源数据和 Hive 表的字段分隔符，二者保持一致，目前只支持单字符。
