离线工作流即对实时性要求不高，可接受 T+1 的数据计算结果的任务类型，下面以一个实际的离线工作流为例子进行介绍。
## 示例任务介绍 ##
首先创建一个 FTP 导入 HDFS 任务。
![](//mc.qcloudimg.com/static/img/0207d1ed6b33ce9a4afb76dc2161aa3f/image.png)
- 离线工作流以某业务场景下的按天处理测速日志为例。
- 数据流向为测速 agent—>FTP—>HDFS—>HIVESQL—>MySQL。
- 原始日志已采集并按天存入到 FTP。（集群内 FTP，也可以外部数据源，设置方法参见【服务器配置】）
- HIVESQL 做运营商维度的 PV 统计，并最终导出到 MySQL 结果数据库。
- FTP 存储位置：`/FTP/origin_stat/in/${YYYYMMDD}`。（注:这里变量表示按日期分目录）

## 数据接入 ##
### 数据接入示例说明
右击新建的离线接入任务模块，然后选择【编辑】，根据详细说明设置离线接入的相关内容。
![](//mc.qcloudimg.com/static/img/7d0ef40b50d24ae41f84324d98f6f0ce/image.png)
![](//mc.qcloudimg.com/static/img/3f9206b307b9ee60c016e1420b8d1a2f/image.png)
![](//mc.qcloudimg.com/static/img/e44604148060275c1a781036fe82b4a5/image.png)
![](//mc.qcloudimg.com/static/img/aed90c8d865636bd5a07527ae9fdf826/image.png)
详细说明：
（1）任务名称：任务标识名称。
（2）任务类型：数据导入集群的方式。
（3）告警：即依据任务状态设置告警，目前支持任务失败或执行超时告警。
（4）周期类型：数据导入任务的执行周期。支持每月，每周，每天，每小时，每分钟或一次性非周期和持续性非周期方式。
（5）起始数据时间：以数据的更新时间作为任务执行的起始时间。例如现在是 8 月 21 日，但任务需要从昨天的（8 月 20 日产生的数据）数据开始计算，那么这里选择起始数据时间为 8 月 20 日。
（6）自身依赖：同一个任务不同周期产生的调度任务之间是否有依赖关系。例如离线导入任务按天执行，那每天都会生成一个数据导入任务，如果这里选择“是”，那只有前一天的导入任务成功完成，第二天的才会顺序执行。
（7）调度时间：与任务周期相关的参数，即任务下发的相对时间，例如这里选择 0 点 0 分，任务周期选为“天”时，则每天的 0 点 0 分下发任务执行，以此类推。
（8）责任人：工作流负责人，可修改删除工作流。
（9）任务说明：备注信息。
（10）基础设置-源服务器：【服务器设置】里增加的服务器配置，这里直接选择即可。介绍示例为 FTP 导入到 HDFS，故这里选择事先加入的 FTP 服务器即可。
（11）基础配置-目标服务器：【服务器配置】里增加的服务器配置，这里直接选择即可。介绍示例为 FTP 导入到 HDFS，故这里选择事先加入的 HDFS  服务器即可。
（12）源目录：由于这里的选择是 FTP 导入到 HDFS，故选择的是 FTP 的目录。这里支持时间内置变量 ${YYYYMMDDhhmm}，即年，月，日，小时，分钟。
（13）目标目录：由于这里选择的是 FTP 导入到 HDFS，故填的是 HDFS 的主目录。这里同样支持内置时间变量 ${YYYYMMDDhhmm} 。
（14）其他配置：其他配置里选项默认即可。

### 其他离线数据导入方式介绍
多种导入方式的基础配置基本类似，任务周期选择均相同。差异点即取源数据的方式不同，根据需要选择不同方式即可。
目前离线数据导入的方式支持如下图所示：
![](//mc.qcloudimg.com/static/img/7feedeacc277df18a442f7310fec4e21/image.png)

## 数据计算 ##
### 数据计算示例说明
本示例以 HIVESQL 进行数据计算，首先新建一个 HIVE SQL脚本 任务。
![](//mc.qcloudimg.com/static/img/52ab9a39310128f8e8ed2ad32e741a17/image.png)
右键单击【编辑】之后，根据详细说明填写相关参数信息。
![](//mc.qcloudimg.com/static/img/6502e6b70167d85c0ace48442c5245be/image.png)
![](//mc.qcloudimg.com/static/img/1fa9cc6184a57a523775d07387e99a2f/image.png)
![](//mc.qcloudimg.com/static/img/78da694e638db78598b929b4e2f1c117/image.png)
详细说明：
（1）任务名称、类型、周期类型、起始数据时间等和数据导入类似，不再赘述。
（2）源服务器：即在【服务器设置】里增加的服务器配置，这里为 HIVESQL 计算，故选择之前配置的 HIVEserver 即可。
（3）SQL脚本：即该任务执行的 SQL** **脚本，单击【上传脚本】，选择本任务执行的脚本即可。
示例脚本如下：           
```
use demo_stat_db;
ALERT TABLE demo_stat_tb_day ADD PARTITION(date_id = '${YYYYMMDD}')
LOCATION 'hdfs://hdfsCluster/project/demo/in/${YYYYMMDD}/';

insert into table demo_stat_db.isp_conn_total_times
SELECT date_id,isp,sum(conn_succ)
	FROM demo_stat_tb_day
	WHERE 1.date_id = '${YYYYMMDD}'
GROUP BY isp,1.date_id;
```
简单解释：第一步使用外部表的方式使 HDFS 与 HIVE 建立关联；第二步即常用的SQL语法（详细使用可通过搜索引擎学习），进行简单的运算并存入到 HIVE 结果表。

### 其他数据计算方法说明
目前支持的计算方法包括 HIVESQL，Map-Reduce，Shell 脚本，Spark 和 JStorm，每种计算方法的基础配置如周期性等均完全一样。
![](//mc.qcloudimg.com/static/img/06802f422b9a529d1229d661e9963e9b/image.png) 
差异在于 Spark 和 JStorm 上传脚本时，可以自定义参数，同时 JStorm 需要指定 Topology 类和名称，如下图所示：
![](//mc.qcloudimg.com/static/img/724ab046809172a211edd59c71e0e3aa/image.png)

## 数据导出 ##
### 数据导出示例说明
本示例中，到目前为止，数据经过计算已经将结果存入到 HIVE 表，即 HDFS 的文件中，导出即选择从 HDFS 导出到 MySQL 永久存储。
首先新建一个 HDFS 导出 MYSQL 任务。
![](//mc.qcloudimg.com/static/img/606f762467ef383e5ed5d0c67bcb6a47/image.png)   
右键单击【编辑】，填写相关配置信息。
配置说明：
（1）任务名称，周期类型，起始数据时间，自身依赖，调度时间，责任人，任务说明均与数据导入，数据计算的含义一致。
（2）任务类型：本例使用 HDFS 导出到 MySQL，其他可使用的导出方式后面后续介绍。
（3）源服务器：即【服务器配置】里增加的服务器，这里示例中选择配置好的 HDFS 服务器即可。
（4）目标服务器：即【服务器配置】里增加的服务器，这里示例中选择配置好的 MySQL 服务器即可。
（5）源目录：即源服务器中 HIVESQL 表在 HDFS 上目录位置。
（6）目标表：即目标 MySQL 服务器的数据库中对应 table。
（7）目标表列名：目标 MySQL 服务数据库中 table 的表名称列表以,分隔，注意需要和 HIVESQL 表的列数量一一对应。
（8）分隔符：HIVESQL 表的字段之间的分隔符，这里要注意的是 HIVESQL 表在创建时指定好这里的分隔符。
（9）是否分区：即导出到 MySQL 表时，MySQL 表是否需要分区，目前支持按照时间分区，分区的格式支持 P_${YYYYMM}，P_${YYYYMMDD}和P_${YYYYMMDDHH}。
（10）数据库入库模式：目前支持两种入库模式：TRUNCATE 和 APPEND，其中 TRUNCATE 每次都会清理掉目标 MySQL 数据表全表，将 HIVESQL 全表重新导入；APPEND 方式会在 MySQL 表中增加一个 etl_timestamp 字段，填入数据导入时间戳，当导出任务重跑时会根据这个时间戳来进行覆盖。
![](//mc.qcloudimg.com/static/img/bfe81466a57e816053f4e4c54709372a/image.png)
![](//mc.qcloudimg.com/static/img/ae709bc64aa6d01acd7322d20ac5f0e9/image.png)
![](//mc.qcloudimg.com/static/img/6a5aca0d2bf4c362595778eb01aebff7/image.png)

### 其他数据导出方法说明
目前支持的数据导出方法如下图所示：
![](//mc.qcloudimg.com/static/img/9dc3500970611cebe80b402b51cc644d/image.png)  
任务基本信息的设置均一致，差异如下：
数据导出到 HBase，列的对应信息填写准确即可。（其余均为导出到类 SQL 数据库）
![](//mc.qcloudimg.com/static/img/c7eec2c42dbe4c5806be4822f398c8cc/image.png)
