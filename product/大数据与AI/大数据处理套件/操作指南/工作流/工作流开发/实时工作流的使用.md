## 示例任务介绍 ##
本示例以一个实时任务流介绍实时任务处理的操作方法。
数据流向：kafka—>JStorm—>MySQL。
kafka 作为消息缓存队列，JStorm 做逻辑处理，MySQL 做数据永久存储。
按照【快速入门->创建工作流】的做法，新建一个工作流。

## 数据导入与计算 ##
1. 这里默认消息已经导入到 kafka 里，故基于实时消息接入后，数据计算直接使用 JStorm 落地，存入到 MySQL。
JStorm 代码需要打包为 jar 包的形式，示例代码如下：
```
public class StormKafkaMysql{
	public static void main(String []args) throws Exception{
	//配置Zookeeper地址
	//BrokerHosts brokerHosts = new ZkHosts("a:2181,b:2181,c:2181,d:2181,e:2181");
	BrokerHosts brokerHosts = new ZkHosts("192.168.100.25:2181,192.168.100.64:2181,192.168.100.97:2181");
	//配置Kafka订阅的的Topic,以及zookeeper中数据节点目录和名字
	SpoutConfig spoutConfig = new SpoutConfig(brokerHosts,"cd123","/zkkafkaspout-tim","kafkaspout");

	//配置KafkaBolt中的kafka.broker.properties
	Config conf = new Config();
	HashMap<String,String> map = new HashMap<String,String>();
	//配置Kafka,broker地址	
	//map.put("metadata.broker.list","cloud203:9092,cloud204:9092,cloud206:9092,cloud207:9092,cloud208:9092")
	map.put("metadata.broker.list","192.168.100.117:6667,192.168.100.131:6667,192.168.100.159:6667,192.168.100.166:6667")
	//serializer.class为消息的序列化类
	map.put("serializer.class","kafka.serializer.StringEncoder");
	conf.put("kafka.broker.properties",map);

	spoutConfig.scheme = new SchemeAsMultiScheme(new MessageScheme());
	TopologyBuilder builder = new TopologyBuilder();
	builder.setSpout("spout",new KafkaSpout(spoutConfig));
	builder.setBolt("MysqlBolt",new MysqlBolt()).shuffleGrouping("spout");
	conf.setNumberWorker(3);
	StormSubmitter.submitTopology(StormKafkaMysql.class.getSimpleName()+"-timtest",conf,builder.creatTopology());
	}
}
```

2. 在工作流画布新建一个 JStorm 任务，右击【编辑】，详细配置如下：
![](//mc.qcloudimg.com/static/img/09dc3ff2b51470130a252c15f52df70a/image.png)   
填入 JStorm 的 Topology 名称，Topology 类以及参数，程序包从本地上传脚本即可。（Storm相关编程知识可通过搜索引擎查询）

## 数据导出 ##
### 数据导出示例介绍
本示例中直接用 JStorm 落地存储，故没有使用到工作流的实时数据导出。如下为实时数据导出的示例，在工作流画布新建一个 KAFKA 导出 HDFS 任务。
![](//mc.qcloudimg.com/static/img/6806835b5330e4b3c18d61d2de4fdb76/image.png) 
右击【编辑】，填写详细配置信息。
配置说明：
（1）任务名称，责任人，任务说明和所有工作流任务一致。
（2）任务类型：目前支持 tube（kafka）导出到 HDFS 和 HBase，本例以导出到 HDFS 为例。
（3）周期类型：实时任务只可选择一次性非周期。
（4）消息中间件 topic：即 tube（kafka）的 topic 名称。
（5）消息中间件group：即 tube（kafka）的消费组名称。
（6）HDFS 目标目录：导出到 HDFS 的目录。
（7）HDFS 地址：即 HDFS 的 activenamenode 地址（本套件已做了 HA，地址为 hdfsCluster）。
（8）文件最大落地大小：即消息中间件的消息积累的消息量才落地的 HDFS 的最大值。
![](//mc.qcloudimg.com/static/img/e01aa69cf22575a6c676d146d4b82b76/image.png)

### 其他实时数据导出方式
目前支持的其他实时导出方式为导出到 HBase，首先新建一个 KAFKA 导出 HBASE 任务。
![](//mc.qcloudimg.com/static/img/fff75859fbfcc81b1da22fa519a7fadf/image.png)   
右击选择【编辑】，填写详细配置信息。
配置说明：
（1）消息中间 topic，消息中间件 group 和导出到 HDFS 类似。
（2）HBase 表名，行主键，列簇，字段描述，分隔符即 HBase 表相关信息。
（3）Zookeeper 根节点：即 HBase 在上 zookeeper 上注册的 znode 名称。
![](//mc.qcloudimg.com/static/img/28faa8569913dba1e22cc6ecdcda095c/image.png)

