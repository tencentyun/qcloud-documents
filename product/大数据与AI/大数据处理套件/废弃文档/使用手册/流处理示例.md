## 1 实时流处理应用介绍

### 1.1 方案介绍

**1.1.1 适用场景**

本系统采用JStorm进行实时数据处理，用户可以根据自己的业务特点编写storm topology。它主要有三大作用领域：1）信息流处理（Stream Processing），用来实时处理新数据和更新数据库，兼具容错性和可扩展性；2）连续计算（Continuous Computation）,进行连续查询并把结果即时反馈给客户，比如Twitter上的热门话题实时发送到客户端；3）分布式远程过程调用（DRPC）,JStorm可以用来并行处理密集查询，其拓扑结构是一个等待调用信息的分布函数，当他收到一条调用信息后，会对查询进行计算，并返回结果。

**1.1.2 模块介绍**

图1-1 系统模块图

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-8.png)

**Nginx：**Nginx ("engine x") 是一个高性能的 HTTP 和反向代理服务器,其稳定性好、占有内存少，并发能力强。本系统利用其反向代理能力供外部网络的客户访问DSE服务，同时利用了它的软负载能力。

**DSE(Data Service Engine)：**DSE是腾讯自研的服务运行容器，提供统一化的通讯协议与调用接口，支持RPC和Servlet协议，可以降低分布式服务的开发成本，使得开发人员只专注于业务逻辑，无需考虑通讯协议、容灾、负载均衡等通用逻辑。本系统基于DSE开发一插件，接受用户的http请求，并把数据保存到kafka。

**Kafka：**Kafka是一个高性能跨语言分布式的发布/订阅的消息队列系统，它具有很好的扩展性、消息峰值处理能力、可恢复性、冗余性、异步通信能力等，具有较高的吞吐率，在一台普通服务器上的可以达到10W/s的吞吐速率，是完全的分布式系统，其Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡。本系统利用其解耦数据生产者和数据消费者，用户产生的实时数据保存在Kafka中，由JStorm去实时消费。

**JStorm：**Storm是个实时的、分布式以及具备高容错的计算系统。同Hadoop一样Storm也可以处理大批量的数据，然而Storm在保证高可靠性的前提下还可以让处理进行的更加实时，也就是说，所有的信息都会被处理。Storm同样还具备容错和分布计算的特性，可以方便的扩展到不同的机器上进行大批量的数据处理。但是开源的Storm有一些隐藏很深的bug，同时是由clojure语言实现，加大了维护排错的难度。JStorm 是基于Strom开源社区版本，用Java代码重构Storm内核的一个项目，它比Storm更稳定，更强大，更快速，Storm上跑的程序，不用改变一行代码就可以运行在JStorm上，除此之外，还扩展了一些Storm上没有的新功能。因此本系统选用JStorm作为流计算引擎。

本系统有两条主线，即数据生产者主线和数据消费者主线。数据生产者主线：用户向Nginx发送http请求，发送数据，Nginx把请求转发到DSE，由DSE把数据写入到Kafka。数据消费者主线：JStorm实时去Kafka读取数据，经过实时分析后，保存结果到MySQL数据库。本系统的交互流程如图1-2所示：

图1-2 用户使用交互图

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-9.png)

### 1.2 资源评估

**1.2.1 服务器配置要求**

腾讯大数据套件默认使用腾讯云提供的云服务器，企业也可根据自己需求灵活选择机型。安装腾讯大数据套件的服务器配置要求如表2-1所示。

表2-1 服务器最低配置

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>硬件</b>
</th><th> <b>推荐配置</b>
</th></tr>
<tr>
<td> CPU
</td><td> 最低配置：1路8核Intel处理器或者双路4核Intel处理器。<br>推荐配置：双路8核Intel处理器。
</td></tr>
<tr>
<td> Bit-mode
</td><td> 64位
</td></tr>
<tr>
<td> 内存
</td><td> &gt;= 64GB<br><b>说明：</b><br>如果有条件可以选择更大的内存，以提升集群的计算能力。
</td></tr>
<tr>
<td> 磁盘空间
</td><td> 磁盘空间要求：操作系统所在盘&gt;= 8G,每个非操作系统盘&gt;=500GB。
</td></tr></tbody></table>

**1.2.2 运行环境要求**

保障腾讯大数据套件系统正常运行的本地环境要求如表2-2所示。

表2-2 软件环境要求

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>软件</b>
</th><th> <b>要求</b>
</th></tr>
<tr>
<td> 操作系统
</td><td> 目前支持如下操作系统，一个集群中的所有服务器需要采用同一种操作系统：<br>CentOS-6.2-x86_64
</td></tr>
<tr>
<td> 浏览器
</td><td> Google Chrome 21及以上版本
</td></tr>
<tr>
<td> JDK
</td><td> 1.7及以上版本
</td></tr></tbody></table>

**1.2.3 软件部署方案**

需要安装的软件清单如表2-3所示。

表2-3软件清单

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>服务名称</b>
</th><th> <b>版本号</b>
</th></tr>
<tr>
<td> Ambari
</td><td> 2.0
</td></tr>
<tr>
<td> Nginx
</td><td> 0.1.0
</td></tr>
<tr>
<td> DSE(自研)
</td><td> 0.1.0
</td></tr>
<tr>
<td> Kafka
</td><td> 0.8.1.2.2
</td></tr>
<tr>
<td> ZooKeeper
</td><td> 3.4.6.2.2
</td></tr>
<tr>
<td> JStorm
</td><td> 1.0.3
</td></tr>
<tr>
<td> MySQL
</td><td> 5.1.73
</td></tr></tbody></table>

软件部署原则如表2-4所示。

表2-4 软件部署原则

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>服务</b>
</th><th> <b>服务组件</b>
</th><th> <b>部署个数</b>
</th><th> <b>备注</b>
</th></tr>
<tr>
<td> Nginx
</td><td> Nginx Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td rowspan="2">DSE(自研)
</td><td> Dse Database
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> DSE Server
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td rowspan="2">Kafka
</td><td> Kafka Manager
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Kafka Broker
</td><td> &gt;=1
</td><td> 不小于topoic 最大的replication数。如所有的topic中，最大的replication为n,则Broker个数&gt;=n。为了保障数据的可靠性，建议broker个数不小于3个。
</td></tr>
<tr>
<td> ZooKeeper
</td><td> ZooKeeper Server
</td><td> 3
</td><td> 部署奇数个，集群大于三个节点，建议不小于3个
</td></tr>
<tr>
<td rowspan="3">JStorm
</td><td> Jstorm Nimbus
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Jstorm UI Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Jstorm Supervisor
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td> MySQL
</td><td> MySQL Server
</td><td> 1
</td><td>
</td></tr></tbody></table>

>注：各个服务的安装方法请参考《大数据套件用户手册》。

**1.2.4 集群节点个数评估**

集群节点个数主要从业务数据规模角度进行评估，每天的业务量为N。在数据接入过程中，需要用到集群存储的主要是Kafka，需要存储topic数据。为保障业务数据保存在分布式系统上的可靠性，kafka数据副本数一般都设置为3（建议配置），且kafka上的数据只保存3天，超过3天，其空间会被循环利用，那么kafka需要的最大空间为3*3N。再加上其他服务所需的存储空间，乘以一个系数1.2，则需要的集群节点数为：9N *1.2/ 500GB。 假设每天的业务量为500G,那么需要的节点数为：9*500G*1.2/500G = 10.8

>注：
1）该评估建立的前提是：仅仅是流处理业务需要的节点数，如果该集群还有其他业务，还需要增加节点数（根据其他业务情况评估）。
2）当前的评估是基于存储空间进行评估的，若想降低节点数，可以增加每个节点的硬盘数。若想提升系统导入性能，可以加强硬件配置，或者增加节点数。

### 1.3 系统参数配置及对外接口

**1.3.1 系统参数配置**

采用系统默认参数即可。

**1.3.2 对外接口**

对外接口主要是实现用户向该实时数据接入Hive系统发送数据，主要包含两个：1）添加任务配置；2）向系统发送数据。

**1.3.2.1 添加任务配置**

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>功能</b>
</th><th colspan="3"> <b>添加任务配置</b>
</th><th>
</th><th>
</th></tr>
<tr>
<td> 请求URL
</td><td colspan="3">http://nginxIp:nginxPort/dataImportor-tdbs/BusinessConfigService?m=addConfig&amp;p=["task identifier","kafka topic","kafka"]
</td></tr>
<tr>
<td> HTTP请求方式
</td><td colspan="3">POST
</td></tr>
<tr>
<td> 字符编码
</td><td colspan="3">UTF-8
</td></tr>
<tr>
<td rowspan="3"> 请求参数
</td><td> 参数名称
</td><td> 值
</td><td> 是否必须
</td></tr>
<tr>
<td> m
</td><td> 值必须为固定的addConfig，表示该请求的作用是添加一项配置
</td><td> 是
</td></tr>
<tr>
<td> p
</td><td> 共有三项值，以逗号分割。第一个值：任务标识，标识是哪个发送任务；第二个值：要向kafka的哪个topic发送数据；第三个值：必须固定为kafka，表示数据是写入到kafka
</td><td> 是
</td></tr>
<tr>
<td rowspan="3">返回结果
</td><td> 返回值
</td><td colspan="2">{"retCode":"0","retMsg":null,"retObj":"12"}
</td></tr>
<tr>
<td> 类型
</td><td colspan="2">Json字符串
</td></tr>
<tr>
<td> 描述
</td><td colspan="2">当retCode和retObj都为0时，添加配置成功，否则失败
</td></tr>
<tr>
<td> 请求示例
</td><td colspan="3">http://10.151.135.208:8086/dataImportor-tdbs/BusinessConfigService?m=addConfig&amp;p=["task1","testtopic","kafka"]
</td></tr></tbody></table>

**1.3.2.2 发送数据**

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>功能</b>
</th><th colspan="3"><b>向系统发送数据</b>
</th><th>
</th><th>
</th></tr>
<tr>
<td> 请求URL
</td><td colspan="3">http://nginxIp:nginxPort/dataImportor-tdbs/DataImportService?m=sendDataSync&amp;p=["task identifier","user data","500"]
</td></tr>
<tr>
<td> HTTP请求方式
</td><td colspan="3">POST
</td></tr>
<tr>
<td> 字符编码
</td><td colspan="3">UTF-8
</td></tr>
<tr>
<td rowspan="3"> 请求参数
</td><td> 参数名称
</td><td> 值
</td><td> 是否必须
</td></tr>
<tr>
<td> m
</td><td> 值必须为固定的sendDataSync，表示向系统发送一条数据
</td><td> 是
</td></tr>
<tr>
<td> p
</td><td> 共有三项值，以逗号分割。第一个值：任务标识，标识是哪个发送任务，该值要和添加任务配置接口中的该项值保持一致；第二个值：要向系统发送的数据；第三个值：请求超时时间，单位为毫秒
</td><td> 是
</td></tr>
<tr>
<td rowspan="3">返回结果
</td><td> 返回值
</td><td colspan="2">{"retCode":"0","retMsg":null,"retObj":"12"}
</td></tr>
<tr>
<td> 类型
</td><td colspan="2">Json字符串
</td></tr>
<tr>
<td> 描述
</td><td colspan="2">当retCode和retObj都为0时，添加配置成功，否则失败
</td></tr>
<tr>
<td> 请求示例
</td><td colspan="3">http://10.151.135.208:8086/dataImportor-tdbs/DataImportService?m=sendDataSync&amp;p=["task1","I am chinese","500"]
</td></tr></tbody></table>

### 1.4 运行示例

**1.4.1 示例说明**

实现一单词统计应用，用户通过DSE（经过Nginx代理）发送英文句子到kafka，然后由storm从kafka读取数据，进行流处理后，把单词统计结果保存到mysql数据库，用户可在mysql查询单词统计结果。

如用户发送英文语句：I am chinese. 经过实时处理后，可在mysql数据库里查到每个单词的个数。

**1.4.2 运行步骤**

1）按照表2-3软件清单安装大数据套件的服务，安装方法参考《大数据套件用户手册》。假设Nginx Server安装在10.151.135.208节点，Zookeeper安装在10.151.135.208、10.151.135.217、10.151.135.219上，Jstorm Nimbus安装在10.151.139.102上。

2）安装mysql数据库，或者安装Lhotse服务，使用lhotse的mysql数据库。创建mysql数据表，执行如下命令：

```
DROP TABLE IF EXISTS `word_count`;
CREATE TABLE `word_count` (
  `word` varchar(255) NOT NULL COMMENT '单词',
  `count` int(11) DEFAULT '1',  
  PRIMARY KEY (`word`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
```

3）向实时接入系统发送数据。参见3.2章节的对外接口向系统发送数据。
a.	向系统添加一项发送数据的配置，使用curl命令来发送http请求，调用命令：

```
    curl http://10.151.135.208:8086/dataImportor-tdbs/BusinessConfigService
-d'm=addConfig&p=["teststorm","teststorm","kafka"]'
```

b.	等待两分钟后（添加配置命令需要等待两分钟才能生效），向系统发送数据，调用命令：

```
curl http://10.151.135.208:8086/dataImportor-tdbs/DataImportService
-d'm=sendDataSync&p=["teststorm","I am chinese","500"]'。反复调用该命令，向系统发送
一定量的数据。
```

3）启动JStorm任务。
a.	登录Jstorm Nimbus安装节点，切换到jstorm用户，进入/usr/local/jstorm/lib目录，把示例程序jar包（见4.2章节的jar包）上传到该目录。
b.	进入/usr/local/jstorm/bin目录，执行命令：

```
sh /usr/local/jstorm/bin/storm jar 
/usr/local/jstorm/lib/StormExample-0.0.1-SNAPSHOT-shaded.jar 
org.shirdrn.storm.examples.WordCountTopology -d lhotse_open -h 10.151.135.224 
-n 10.151.139.102 -P 3306 -p 2181 -T teststorm -t word_count -u lhotse -w lhotse -z 
10.151.135.208,10.151.135.217,10.151.135.219
```

>注：各参数含义如下：

```
usage: WordCountTopology.java
 -d <arg>   the mysql database
 -h <arg>   the mysql host ip
 -n <arg>   the storm nimbus host ip
 -P <arg>   the mysql port
 -p <arg>   the zookeeper port
 -T <arg>   the kafka topic name
 -t <arg>   the mysql table name
 -u <arg>   the mysql user name
 -w <arg>   the mysql password
 -z <arg>   the zookeeper list, separated by comma,such as:
            zookeeper1,zookeeper2
```

4）登录mysql数据库，在数据表中查看结果，执行以下命令：select * from lhotse_open.word_count; 显示结果如下：

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-10.png)

**1.4.3 示例程序jar包**

http://qzonestyle.gtimg.cn/qzone/vas/opensns/res/doc/StormExample-0.0.1-SNAPSHOT-shaded.jar

**1.4.4 实例源代码**

http://qzonestyle.gtimg.cn/qzone/vas/opensns/res/doc/WordCountTopology.java
