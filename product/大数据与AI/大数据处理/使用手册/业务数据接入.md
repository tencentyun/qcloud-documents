## 1 实时数据接入应用介绍

### 1.1 方案介绍

**1.1.1 适用场景**

用户业务系统的实时的结构化数据需要保存到Hive表中，以供存储、查询或者离线分析，不适合那些需要低延迟的应用，如实时分析系统。

**1.1.2 模块介绍**

图1-1 系统模块图

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-5.png)

**Nginx：**Nginx ("engine x") 是一个高性能的 HTTP 和反向代理服务器,其稳定性好、占有内存少，并发能力强。本系统利用其反向代理能力供外部网络的客户访问DSE服务，同时利用了它的软负载能力。

**DSE(Data Service Engine)：**DSE是腾讯自研的服务运行容器，提供统一化的通讯协议与调用接口，支持RPC和Servlet协议，可以降低分布式服务的开发成本，使得开发人员只专注于业务逻辑，无需考虑通讯协议、容灾、负载均衡等通用逻辑。本系统基于DSE开发一插件，接受用户的http请求，并把数据保存到kafka。

**Kafka：**Kafka是一个高性能跨语言分布式的发布/订阅的消息队列系统，它具有很好的扩展性、消息峰值处理能力、可恢复性、冗余性、异步通信能力等，具有较高的吞吐率，在一台普通服务器上的可以达到10W/s的吞吐速率，是完全的分布式系统，其Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡。本系统利用其解耦数据生产者和数据消费者，把用户生产的实时数据写入到离线系统Hive表中。

**Lhotse：**Lhotse是腾讯自研的大数据任务调度系统，提供55余种调度任务插件，并提供灵活的任务插件扩展机制，支持Java、C++、PHP、Python、Shell等常见编程语言。调度时间周期灵活多样，支持分钟、小时、日、周、月等级别，且可支持多个周期设置。目前Lhotse已经能支撑每日调度百万次，超过淘宝每日10万次的调度，属于业内领先。本系统采用Lhotse调度camus插件，周期性的把数据从kafka导入到HDFS中。

**Camus：**Camus是LinkedIn的开源项目，负责把数据从kafka导入到HDFS，它自己维护kafka topic的偏移量，采用Mapreduce Job，周期性的把kafka里的实时数据分批导出到HDFS。本系统对其进行了改造，让其作为Lhotse的一个插件，被Lhotse周期性的调度执行；对于每一个调度周期，都支持重复导入该周期的数据。Camus把数据导入到HDFS后，再加载到Hive外表中。

**Hive：**Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。

本系统有两条主线，即数据生产者主线和数据消费者主线。数据生产者主线：用户向Nginx发送http请求，发送数据，Nginx把请求转发到DSE，由DSE把数据写入到Kafka。数据消费者主线：Lhotse定期调度camus插件，由camus插件从kafka读取数据，保存到HDFS，再加载到Hive外表中。 用户与本系统的数据交互流程如图1-2所示：

图1-2 用户使用交互图

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-6.png)

### 1.2 资源评估

**1.2.1 服务器配置要求**

腾讯大数据套件默认使用腾讯云提供的虚拟机，企业也可根据自己需求灵活选择机型。安装腾讯大数据套件的服务器配置要求如表2-1所示。

表2-1 服务器最低配置

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>硬件</b>
</th><th> <b>推荐配置</b>
</th></tr>
<tr>
<td> CPU
</td><td> 最低配置：1路8核Intel处理器或者双路4核Intel处理器。<br>推荐配置：双路8核Intel处理器。
</td></tr>
<tr>
<td> Bit-mode
</td><td> 64位
</td></tr>
<tr>
<td> 内存
</td><td> &gt;= 64GB<br><b>说明：</b><br>如果有条件可以选择更大的内存，以提升集群的计算能力。
</td></tr>
<tr>
<td> 磁盘空间
</td><td> 磁盘空间要求：操作系统所在盘&gt;= 8G,每个非操作系统盘&gt;=500GB。
</td></tr></tbody></table>

**1.2.2 运行环境要求**

保障腾讯大数据套件系统正常运行的本地环境要求如表2-2所示。

表2-2 软件环境要求

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>软件</b>
</th><th> <b>要求</b>
</th></tr>
<tr>
<td> 操作系统
</td><td> 目前支持如下操作系统，一个集群中的所有服务器需要采用同一种操作系统：<br>CentOS-6.2-x86_64
</td></tr>
<tr>
<td> 浏览器
</td><td> Google Chrome 21及以上版本
</td></tr>
<tr>
<td> JDK
</td><td> 1.7及以上版本
</td></tr></tbody></table>

**1.2.3 软件部署方案**

需要安装的软件清单如表2-3所示。

表2-3软件清单

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>服务名称</b>
</th><th> <b>版本号</b>
</th></tr>
<tr>
<td> Ambari
</td><td> 2.0
</td></tr>
<tr>
<td> Nginx
</td><td> 0.1.0
</td></tr>
<tr>
<td> DSE(自研)
</td><td> 0.1.0
</td></tr>
<tr>
<td> Kafka
</td><td> 0.8.1.2.2
</td></tr>
<tr>
<td> Hive
</td><td> 0.14.0.2.2
</td></tr>
<tr>
<td> ZooKeeper
</td><td> 3.4.6.2.2
</td></tr>
<tr>
<td> Yarn
</td><td> 2.6.0.2.2
</td></tr>
<tr>
<td> Mapreduce2
</td><td> 2.6.0.2.2
</td></tr>
<tr>
<td> Lhotse(自研)
</td><td> 1.0.0
</td></tr>
<tr>
<td> HDFS
</td><td> 2.6.0.2.2
</td></tr></tbody></table>

软件部署原则如表2-4所示。

表2-4 软件部署原则

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>服务</b>
</th><th> <b>服务组件</b>
</th><th> <b>部署个数</b>
</th><th> <b>备注</b>
</th></tr>
<tr>
<td> Nginx
</td><td> Nginx Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td rowspan="2">DSE(自研)
</td><td> Dse Database
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> DSE Server
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td rowspan="2">Kafka
</td><td> Kafka Manager
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Kafka Broker
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td rowspan="4">Hive
</td><td> Hive Metastore
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> HiveServer2
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> MySQL Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> WebHCat Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> ZooKeeper
</td><td> ZooKeeper Server
</td><td> 3
</td><td> 部署奇数个，集群大于三个节点，建议不小于3个
</td></tr>
<tr>
<td rowspan="3">Yarn
</td><td> App Timeline Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> ResourceManager
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> NodeManager
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td> Mapreduce2
</td><td> History Server
</td><td> 1
</td><td>
</td></tr>
<tr>
<td rowspan="6">Lhotse(自研)
</td><td> Lhotse Base
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse Database
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse FTP
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse Service
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse Web
</td><td> 1
</td><td>
</td></tr>
<tr>
<td> Lhotse Runners
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr>
<tr>
<td rowspan="3">HDFS
</td><td> NameNode
</td><td>
</td><td>
</td></tr>
<tr>
<td> SNameNode
</td><td>
</td><td>
</td></tr>
<tr>
<td> DataNodes
</td><td> &gt;=1
</td><td> 与业务量有关，随业务量增加，适当增加
</td></tr></tbody></table>

注：各个服务的安装方法请参考《大数据套件用户手册》


关键组件部署个数评估如表2-5所示。

表2-5 关键组件部署评估

<table style="display:table;width:80%;"class="t">
<tbody><tr>
<th> <b>组件</b>
</th><th> <b>考虑因素</b>
</th><th> <b>部署个数</b>
</th></tr>
<tr>
<td> DataNode
</td><td> 业务数据量
</td><td> DataNode为集群中各个组件提供基础的数据存储能力，部署越多，存储容量越大，建议每个节点都部署一个。
</td></tr>
<tr>
<td> NodeManager
</td><td> 运行性能
</td><td> 与客户的性能需求有关，理论上部署的越多，可以提供越多的计算资源，至少部署一个，建议每个节点都部署一个。
</td></tr>
<tr>
<td> Lhotse Runner
</td><td> 调度任务业务量
</td><td> 最小配置1个，在实际生产环境中，可根据调度任务量适当部署。
</td></tr>
<tr>
<td> Kafka Broker
</td><td> 业务数据量
</td><td> 不小于topoic 最大的replication数。如所有的topic中，最大的replication为n,则Broker个数&gt;=n。为了保障数据的可靠性，建议broker个数不小于3个。
</td></tr></tbody></table>class="t">
<tbody><tr>
<th> <b>组件</b>
</th><th> <b>考虑因素</b>
</th><th> <b>部署个数</b>
</th></tr>
<tr>
<td> DataNode
</td><td> 业务数据量
</td><td> DataNode为集群中各个组件提供基础的数据存储能力，部署越多，存储容量越大，建议每个节点都部署一个。
</td></tr>
<tr>
<td> NodeManager
</td><td> 运行性能
</td><td> 与客户的性能需求有关，理论上部署的越多，可以提供越多的计算资源，至少部署一个，建议每个节点都部署一个。
</td></tr>
<tr>
<td> Lhotse Runner
</td><td> 调度任务业务量
</td><td> 最小配置1个，在实际生产环境中，可根据调度任务量适当部署。
</td></tr>
<tr>
<td> Kafka Broker
</td><td> 业务数据量
</td><td> 不小于topoic 最大的replication数。如所有的topic中，最大的replication为n,则Broker个数&gt;=n。为了保障数据的可靠性，建议broker个数不小于3个。
</td></tr></tbody></table>

**1.2.4 集群节点个数评估**

集群节点个数主要从业务数据规模角度进行评估，假设客户的总业务量为M, 每天的业务量为N。在数据接入过程中，需要用到集群存储的主要环节有：Kafka存储topic数据、camus跑MR任务shuffle流程占用空间和最终保存在HDFS上的hive表数据。 为保障业务数据保存在分布式系统上的可靠性，kafka和hdfs的数据副本数一般都设置为3（建议配置），且kafka上的数据只保存3天，超过3天，其空间会被循环利用，那么kafka需要的最大空间为3N；而MR的shuffle流程，数据有膨胀，膨胀系数估算为2，当任务完成后，空间即被释放，假设每个任务都是当天完成，则需要的存储空间为2N。

综上分析，数据接入过程中，主要环节需要的存储空间为：3M + 3N + 2N，再加上其他服务所需的存储空间，乘以一个系数1.2，则需要的集群节点数为：(3M+3N+2N) *1.2/ 500GB。 假设业务数据量有5T，每天的业务量为500G,那么需要的节点数为：(3*5T + 3*500G + 2*500G)*1.2/500G = 42

>注：
1）该评估建立的前提是：仅仅是数据接入需要的节点数，如果该集群还有其他业务，还需要增加节点数（根据其他业务情况评估）。
2）MR shuffle占用的空间，只是临时空间，MR任务跑完后即释放，接入任务完成后，其实只需要3M+3N的存储空间，因此其3M+3N+2N是需要的峰值存储空间；
3）当前的评估是基于存储空间进行评估的，若想降低节点数，可以增加每个节点的硬盘数。若想提升系统导入性能，可以加强硬件配置，或者增加节点数。

### 1.3 系统参数配置
各个服务的参数使用系统默认配置即可，这里主要介绍创建Lhotse任务的参数配置。在lhotse系统的任务管理标签里点击新增任务，创建一个新增任务，任务类型选择数据导入-Kafka入库hive，弹出如图3-1页面。

图3-1 Kafka入库hive配置页面

![](//qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/TBDSjs-7.png)

各参数含义如下：

**任务名称：**该任务的名称，不能与其他任务名称重名。

**周期类型：**调度支持的周期类型：月、周、日、小时、分钟和非周期，其中非周期指任务只执行一次。
起始数据时间：数据导入的起始时间。

**调度时间：**每个任务在到达调度周期后，延迟多长时间开始执行任务。

**超时时间：**任务执行的超时时间，单位为秒。

**Hive表名：**Hive表名,默认加到default数据库；若想指定到特定数据库，其格式为：databaseName.tableName。在创建该lhotse任务之前，该表不能存在，由系统自动创建该表。

**Hive表分区字段名：**Hive表的分区字段名，类型为string，一个Hive表只支持一个分区。

**Hive表字段名：**Hive表的字段名,多字段之间以逗号分割，不包括分区字段名。每个字段为string类型。

**读并发度：**需要多少个进程同时导入数据。

**Kafka Broker列表：**集群中的所有Kafka Broker集合，格式为：brokerIp:brokerPort；多个borker之间以逗号分割，如：brokerIp1:port,brokerIp2:port

**Topic：**kafka的topic，需要从哪个topic消费数据。

**字段分隔符：**用户产生的源数据和Hive表的字段分隔符，二者保持一致，目前只支持单字符。