## 简介
### 组件介绍

DeScheduler 组件是容器服务 TKE 基于 Kubernetes 原生社区 [DeScheduler](https://github.com/kubernetes-sigs/descheduler)  实现的一个基于 Node 真实负载进行重调度的插件。在 TKE 集群中安装该插件后，该插件会和 Kube-scheduler 协同生效，实时监控集群中高负载节点并驱逐低优先级 Pod。 
该组件依赖 Prometheus 监控组件以及相关规则配置，建议您安装组件之前仔细阅读 [依赖部署](#DeScheduler)，以免插件无法正常工作。
建议您搭配 TKE [Dynamic Scheduler（动态调度器扩展组件）](https://cloud.tencent.com/document/product/457/50843) 一起使用，多维度保障集群负载均衡。

### 在集群内部署的 Kubernetes 对象

| Kubernetes 对象名称  | 类型               |                   请求资源                   | 所属 Namespace |
| :----------------- | :----------------- | :------------------------------------------: | ------------- |
| descheduler        | Deployment         | 每个实例 CPU:200m，Memory:200Mi，共1个实例 | kube-system   |
| descheduler        | ClusterRole        |                      -                       | kube-system   |
| descheduler        | ClusterRoleBinding |                      -                       | kube-system   |
| descheduler        | ServiceAccount     |                      -                       | kube-system   |
| descheduler-policy | ConfigMap          |                      -                       | kube-system   |
| probe-prometheus   | ConfigMap          |                      -                       | kube-system   |

## 使用场景

DeScheduler 通过重调度来解决集群现有节点上不合理的运行方式。社区版本 DeScheduler 中提出的策略基于 APIServer 中的数据，并没有基于节点真实负载。因此可以增加对于节点的监控，基于真实负载进行重调度调整。

容器服务 TKE 自研的 ReduceHighLoadNode 策略依赖 prometheus + node_exporter 监控数据，根据节点 CPU 利用率、内存利用率、网络 IO、system loadavg 等指标进行 Pod 驱逐重调度，防止出现节点极端负载的情况。DeScheduler 的 ReduceHighLoadNode 与 TKE 自研的 Dynamic Scheduler 基于节点真实负载进行调度的策略需配合使用。

## 限制条件

Kubernetes 版本 ≥ v1.10.x



## 依赖部署[](id:DeScheduler)

DeScheduler 组件依赖于 Node 当前和过去一段时间的真实负载情况来进行调度决策，需要通过 Prometheus 等监控组件获取系统 Node 真实负载信息。在使用 DeScheduler 组件之前，您可以采用自建 Prometheus 监控或采用 TKE 云原生监控，下面对这两种方式依次介绍。


### 自建 Prometheus 监控服务

#### 部署 node-exporter 和 Prometheus

通过 node-exporter 实现对于 Node 指标的监控，您可按需部署 node-exporter 和 Prometheus。

#### 聚合规则配置

在 node-exporter 获取节点监控数据后，需要通过 Prometheus 对原始的 node-exporter 中采集数据进行聚合计算。为了获取 DeScheduler 所需要的 `cpu_usage_avg_5m`、`mem_usage_avg_5m` 等指标，需要在 Prometheus 的 rules 规则中进行配置。示例如下：

```
groups:
      - name: cpu_mem_usage_active
        interval: 30s
        rules:
        - record: mem_usage_active
          expr: 100*(1-node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes)
      - name: cpu-usage-1m
        interval: 1m
        rules:
        - record: cpu_usage_avg_5m
          expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
      - name: mem-usage-1m
        interval: 1m
        rules:
        - record: mem_usage_avg_5m
          expr: avg_over_time(mem_usage_active[5m])
```

#### Prometheus 文件配置


前面定义了`DeScheduler`所需要的指标计算的 rule，然后我们需要把这个 rule 配置到 Prometheus 中，参考一般的 Prometheus 配置文件

```
global:
    evaluation_interval: 30s
    scrape_interval: 30s
    external_labels:
rule_files:
- /etc/prometheus/rules/*.yml # /etc/prometheus/rules/*.yml 是定义的 rules 文件
```

我们把上面的 rules 配置，复制到一个文件如de-scheduler.yaml，文件放到上述 Prometheus 容器的 `/etc/prometheus/rules/` 下，然后 reload prometheus server 就可以从 Prometheus 中获取到动态调度器需要的指标。
 
通常情况下，上述 Prometheus 配置文件和 rules 配置文件都是通过 configmap 存储，然后挂载到 prometheus server 的容器里面，所以修改相应的 configmap 即可。



### 云原生监控 Prometheus

1. 创建与 Cluster 处于同一 VPC 下的云原生监控 Prometheus 实例，并与用户集群关联。 
   ![](https://main.qcloudimg.com/raw/b17e7ea4642e6aaea70c885956f30b0b.png)
2. 与原生托管集群关联后，可以在用户集群看到每个节点都已经安装了 node-exporter。 
   ![](https://main.qcloudimg.com/raw/e35d4af7eeba15f6d9da62ce79176904.png)
3. 接下来设置Prometheus的聚合规则，如下图所示，具体规则内容与上一小节介绍的规则相同，此处不再赘述。 规则保存后立即生效，无需reload server。


## 组件原理

DeScheduler  基于社区 [descheduler](https://github.com/kubernetes-sigs/descheduler) 的重调度思想，定期扫描各个节点上的运行 Pod，发现不符合策略条件的进行驱逐以进行重调度。社区版本的 DeScheduler  已经给出一些策略，只是这些策略是基于 APIServer 中的数据，例如 `LowNodeUtilization` 策略依赖的是 Pod 的request/limit数据，这些数据对均衡集群资源分配，防止出现资源碎片有帮助。但是社区策略缺少节点真实资源占用的支持，例如节点 A 和 B 分配出去的资源一致，但是由于 Pod 实际运行情况，CPU 消耗型和内存消耗型不同，峰谷期不同造成两个节点的负载差别巨大。

因此，腾讯云 TKE 推出 DeScheduler，底层依赖对节点真实负载的监控进行重调度。具体实现上，通过 Prometheus 拿到集群 Node 的负载统计信息，根据用户设置的负载阈值，定期执行策略里面的检查规则，驱逐高负载节点上的 Pod 。

![](https://main.qcloudimg.com/raw/9a31a5d0995c40f3540a83da3b037323.png)

### 查找高负载节点

![](https://main.qcloudimg.com/raw/ac5285d3fc10fad645239507570a3e39.png)

### 筛选可驱逐 Pod

![](https://main.qcloudimg.com/raw/00c60959cb1956e1a1cfa9d683f1f542.png)

可迁移标记是我们指定的 annotation，设置为 `"descheduler.alpha.kubernetes.io/evictable": true`，注入到 workload 中。


### 根据 Pod 驱逐顺序进行驱逐

当节点 CPU 或者内存超过阈值时，对节点进行 Pod 驱逐的顺序基于以下规则排序，例如有两个 Pod：A 与 B。

>? 当节点 CPU 和内存都超过了阈值时，先按照降低内存到目标水位的策略去驱逐 Pod，因为内存是不可压缩资源，且会同步将驱逐的pod对节点 CPU 的降低值 更新到节点负载中。然后再按照降低 CPU 到目标水位的策略去驱逐 Pod。

1. priority 值低的 Pod 优先驱逐。
2. QosClass 低的（besteffort < burstable < guaruanteed）优先驱逐。
3. 如果 A 与 B 的 priority 与 QosClass 都相同，则比较二者对 CPU /内存的利用率，利用率高的优先驱逐（为了快速降低负载）。


## 组件参数说明[](id:parameter)

### Prometheus 数据查询地址

> ! 请确保您已经按照【[依赖部署](#DeScheduler)】>【Prometheus 规则配置】进行了监控数据采集规则配置，这样我们的组件才可以拉取到需要的监控数据，调度策略才会生效。

- 如果您使用自建 Prometheus，直接填入数据查询 URL（HTTPS/HTTPS）即可。
- 如果您使用托管 Promethes，选择托管实例 ID 即可，我们会自动解析实例对应的数据查询 URL。

### 利用率阈值和目标利用率

>! 负载阈值参数我们已经为您设置了默认值，如您无额外需求，可直接采用。


过去五分钟内，节点的 CPU 平均利用率或者内存平均使用率超过设定阈值，Descheduler 会判断节点为高负载节点，执行 Pod 驱逐逻辑（不可驱逐 Pod 筛选以及驱逐顺序请参考组件说明），并尽量通过 Pod 重调度使节点负载降到目标利用率以下。


## 风险控制

1. 该组件已对接TKE的监控告警体系。
2. 推荐您为集群开启事件持久化，以免更好的监控组件异常以及故障定位。
3. 为了避免 `DeScheduler` 驱逐了关键的 Pod，设计的算法是默认不驱逐 Pod，对于可以驱逐的 Pod，用户需要显示给判断 Pod 所属workload 例如 statefulset/deployment 等对象设置可驱逐 annotation。
4. Pod 驱逐太多导致服务不可用
   k8s 原生有 PDB 对象来防止驱逐接口造成workload不可用pod过多，但是需要用户创建这样的pdb配置，腾讯云TKE自研的 `DeScheduler`里面加入了自己的兜底措施，即调用驱逐接口前，判断 workload ready 的 Pod 数是否大于副本数一半，否则则不调用驱逐接口。

## 操作步骤

1. 登录 [容器服务](https://console.cloud.tencent.com/tke2/cluster) 控制台。
2. 按照 [依赖部署](#DeScheduler) 部署 Prometheus、Node-Exporter，并配置好 Prometheus Rule。
3. 单击左侧导航栏中的【集群】，进入集群管理界面。
4. 单击需新建组件的集群 ID，进入集群详情页，在该页面左侧栏中选择【组件管理】。
5. 单击【新建】，进入“新建组件”页面。
6. 在组件列表勾选【Decheduler（重调度器）】，单击【参数配置】。
7. 按照 [参数说明](#parameter) 填写组件所需参数。
8. 单击【完成】，组件安装成功后 DeScheduler 即可正常运行，无需进行额外配置。
9. 对于用户认为可以驱逐的 workload（例如 statefulset/deployment 等对象），可以设置 `Annotation` 如下
   `descheduler.alpha.kubernetes.io/evictable: 'true'`。

