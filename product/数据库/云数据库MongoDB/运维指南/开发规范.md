## 数据库设计规范
### 禁止类
**禁止数据库中创建过多的表**
在 wiretiger 引擎中，每个集合都需要创建多个文件来保存元数据、数据及索引，磁盘上过多的小文件会导致性能下降。建议单个数据库表个数控制在100个以内，整个数据库实例表数量控制在2000个以内。

### 建议类
- 建议数据库名以 db 开头，不能包含除 _ 以外的特殊字符，所有字母全部小写，数据库名不超过64个字符。
- 建议集合名以 t\_开头，不能包含除 _ 以外的特殊字符、集合名不超过120个字符。

 
## 索引设计规范
### 禁止类
- **禁止线上库不带 background 参数建索引**
MongoDB 4.2 及之前的版本，createIndex() 命令默认是 foreground 模式，这种模式下创建索引会阻塞数据库的所有操作，造成业务中断，线上业务执行 createIndex() 务必添加 background参数。
>!background 需要在 createIndex() 命令的 options 参数中，示例：`db.test.createIndex({a: 1}, {unique:true, background: true})`，切勿将不同的参数分开，示例：`db.test.createIndex({a: 1}, {unique:true}, {background: true})`。

- **排序字段需要放到索引中，避免业务大量在内存中排序造成数据库 OOM（Out Of Memory）**
 - MongoDB 4.2 及之前的版本，一条 sql 默认只允许使用32MB内存进行排序，如果超出会提示 `Sort operation used more than the maximum 33554432 bytes of RAM` 错误，此时可以通过执行 `db.runCommand({ getParameter : 1, "internalQueryExecMaxBlockingSortBytes" : 1 } )` 调整排序内存。
但是线上业务禁止调整，因为这样会让数据库 OOM 的概率增大。建议将排序字段加到索引中，通过索引排序实现排序能力。
 - MongoDB 4.4 版本，虽然提供了磁盘排序的选项以避免排序消耗大量内存，但是建议最好使用索引排序。

- **禁止一个表内创建过多的索引**
MongoDB 插入每条数据的时候同时需要写索引。索引越多，写入数据时就要花费更多的代价。因此禁止对索引的滥用，如对每个字段都建立索引，哪怕不会根据该字段进行查询。建议单表索引最多不超过10个。

### 建议类
- **建议定期清理无用索引**
索引在写操作时会带来额外的资源消耗，因此需要尽量精简索引。
MongoDB 4.4 之后的版本，建议使用 hidden index 先隐藏掉无用的索引，隐藏后业务确认正常再删除索引。

- **按照最左匹配原则，如果单列索引已经被复合索引包含，建议删除**
额外的索引会造成写操作时候性能浪费。

- **建议尽量避免使用 $ne/$nin 等操作**
和其他数据库（如 MySQL）一样，不等于及 not in 类的操作无法有效利用索引，尽量应该避免。

- **建议在区分度较大的字段上建立索引**
如果索引字段区分度较小，查询扫描的行数依然会比较多，查询效率较低，对数据库负载影响较大。因此建立索引的字段尽量应该有较大的区分度。

## 使用规范
### 禁止类
- **禁止上线未经过 explain() 确认执行计划的 sql**
上线 sql 前需要 explain() 确认执行计划是否符合预期，否则上线可能会引起故障。

- **线上环境禁止关闭鉴权，特别是开放外网访问的数据库**
关闭鉴权会将数据库暴露给所有人，特别是数据库服务器开通了外网。建议线上环境打开鉴权。如果一定要开启鉴权，务必设置防火墙规则或 IP 白名单。

- **禁止在 admin 库、local 中存储业务数据**
admin 库读写时会加 db 锁，影响性能；local库只会保存到本地，不会复制到从节点，如果发生主从切换会丢失数据。因此禁止使用 admin 库和 local 库。

- **禁止执行 db.dropDatabase() 命令后再创建同名的 db**
 - MongoDB 4.0 及之前的版本，官方文件要求删除 db 并创建同名 db 后，业务读写数据前需要在所有 mongos 节点上执行重启或 flushRouterConfig 命令。
 - MongoDB 4.2 之后的版本，需要对所有的 mongos 和 mongod 节点重启或执行 flushRouterConfig 命令。
因此禁止在业务代码中直接进行 db.dropDatabase() 命令后再创建同名的 db。运维人员在做该操作时，请务必按照官方文档要求进行所有必要的操作。

- **高并发高性能场景，禁止过度使用 in 和 or**
in 或者 or 条件语句在数据库底层需要转换成多次查询，过多的 in 和 or 操作在高并发高性能场景，会严重影响请求的响应时延及数据库负载。

- **高并发高性能场景，禁止将复杂的运算操作交给数据库进行**
MongoDB 提供了强大的计算能力（如 MapReduce 等），这些特性对开发人员非常友好，极大减轻了业务逻辑。但是这些运算不可避免是需要资源的，如果将复杂运算下沉到数据库层，高并发场景势必会给数据库造成极大的负担，数据库一旦故障会造成整个系统雪崩。
建议在高并发高性能的场景下，数据库操作保持简单，复杂的运算交给服务器并适当在数据库前端增加缓存。

- **线上业务禁止直接进行批量数据 remove**
remove 命令到数据库后会先查询符合删除条件记录的 \_id，之后一条条按照 \_id 进行删除，并记录到 oplog 中（删除每条记录都会写一条 oplog）。
当满足 remove 条件的数据较多时对数据库压力较大，且极容易引起主从延迟突然增大。
线上业务建议直接用 drop 集合或用脚本一条条删除并控制删除速度。或尽量使用 ttl 索引。

- **业务禁止自定义 \_id 字段**
\_id 是 MongoDB 内部的默认主键，默认这是一个自增的序列。如果自定义 \_id 并且业务无法保证 \_id 递增，每次插入数据后，\_id 索引不可避免需要对 B 树索引进行调整，这将对数据库带来额外的负担。

- **副本集直连 mongod 节点的场景，使用禁止只在连接串中配置单个 IP；分片集群集群禁止只连接单个 mongos 地址（除非 mongos 和应用服务器部署在一起）**
线上业务如果只连接副本集主节点，一旦数据库发生 HA 会造成写入中断；如果只连接单个 mongos，这个 mongos 故障后会造成业务中断。

- **线上业务禁止设置 Write Concern j:false**
Write Concern 默认一般为 j:true，表示服务端会写入 journal log 完成后再向 client 端返回。一般请勿设置 j:false，否则进程突然故障重启后，可能会造成数据丢失。

- **update 语句中禁止不带条件的更新**
推荐保持 multi 为默认值（false），避免程序 bug（如由于某些异常造成 query 参数传了{}）造成全表数据更新。

- **禁止更新数组内部分元素时，将数组全部拿出来更新后再写回去**
推荐使用 arrayFileters 仅对需要的元素进行修改。


### 建议类
- **建议局部读写而不是全读全写**
查询语句中应尽量使用 $projection 运算符投影出需要的字段；在 update 命令中如果只是修改某个字段，建议使用 $set，请勿将文档全部读出来修改后再全量写进去。

- **线上环境慎重使用 db.collection.renameCollection() 命令**
renameCollection() 在4.0及之前的版本会阻塞 db 的所有操作；在4.2及其之后版本会阻塞当前表及目标表的操作。而且 renameCollection() 执行期间会造成游标失效、changeStream 失效及带 --oplog 命令的 mongodump 失败等问题。线上环境禁止高峰期直接操作。

- **建议核心业务配置 WriteConcern 为 {w: “majority”} 参数**
默认情况下，一般驱动的 WriteConcern 配置为 {w:1}，即在主节点写入完成后认为请求成功。如果机器突然发生故障并且写入的数据还未复制到从节点，这样的配置会导致数据丢失。因此对于线上的核心业务，强烈建议配置{w: “majority”}，这样的配置会等数据同步大多数节点后再返回客户端。当然可靠性和性能不能兼顾，选择了{w: “majority”}配置后请求的延迟也会相应的增加。*

### 不建议类
- 除非必要，不要在高性能场景大量使用多文档事务
4.0以后的版本，mongodb提供了多文档事务。但是多文档事务只是mongodb数据库能力的补充，在高并发高性能的场景下大规模使用多文档事务需要进行充分的压测。

一般来说，多文档事务提交前需要在内存中保留快照，这可能消耗大量的cache从而导致性能的下降。

-  建议不使用短连接
mongodb 的认证逻辑是一个比较复杂的运算过程，而且默认mongodb会为每个连接创建一个线程。大量短连接会对数据库产生较大的负担，特别是没有mongos的副本集集群。建议使用长连接（详细参考mongodb url中Connection Pool参数）。

## 分片集群设计规范
### 禁止类
- 如果使用 _id 字段作为片键，禁止使用范围分片
id 默认是一个递增的序列，随着数据量的增加会一直增大。如果_id作为片键并使用范围分片集群随着数据的插入不断的进行balance。

- 分片集群禁止直连mongod节点写数据
分片集群应该通过mongos写数据，直接通过mongod写入的数据无路由信息会导致访问不到。

- 线上环境禁止长时间关闭 balancer 和 autoSplit 配置
关闭 balance 会导致片之间数据不均衡，关闭 autoSplit 可能会产生 jumbo chunk。

- 分片表尽量避免不带片键的查询
分片表不带片键进行查询，需要扫描所有分片后在mongos聚合结果，比较消耗性能，不推荐使用。

- 线上环境务必设置 balancer 窗口，避免balance对业务造成影响
balance 过程会明显对数据库造成较大的压力，建议放在业务低峰期进行。


### 建议类
- 建议使用区分度较大的字段作为片键，最理想的情况下是使用唯一主键作为片键
假设我们有一个存储人口信息的集合使用性别作为片键，这个片键认为区分度较低，因为集合中性别字段相同的数据理论上会有一半之多。
如果片键区分度不大，可能会导致大量的记录集中在某些片上，而这种不均衡也无法添加分片进行扩展。因此建议使用区分度较大的字段作为片键。

- 如果使用hash分片建议进行预分配，特别是表比较大且经常经常需要大量插入数据
shardCollection() 命令默认每个分片只会创建2个chunk，随着数据量的越来越大，mongodb需要不断的balance和splitChunk，这将对数据库带来较大的负担。因此在对于大集合建议提前进行预分片（shardCollection命令指定numInitialChunks参数，每个分片最大支持8192个），特别是向大集合中批量导数据时。

### 不建议类
- 没有按片建顺序扫描的强需求，不建议使用range分片，推荐hash分片
range 分片容易引起不均衡和数据热点，而且因为无法预分片所以随着数据的写入balance不可避免，因此不建议使用，除非有强烈的按片键范围查询诉求。
这里特别注意，在shardCollection的时候，sh.shardCollection("records.people", { zipcode: 1 } )命令中1表示范围分片，sh.shardCollection("records.people", { zipcode: "hashed" } )命令中"hashed"表示hash分片。注意不要用错。

- 分片集群中不建议使用非分片表
mongodb 的分片集群如果未执行shardCollection命令，默认数据只存储在主分片上。大量未分片的表会造成分片和分片间的数据量不一致。集群长时间运行下去，可能会造成某些片数据量特别多甚至会打满磁盘，运维在这种情况下不得不使用movePrimary手工进行数据搬迁，增加了运维的复杂度。

 

 
