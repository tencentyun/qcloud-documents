## 测试工具 ##
[测试工具下载](https://main.qcloudimg.com/raw/c64c6ed737fdf3aa824ad0074b780127.zip)
## 集群配置 ##
存储容量 350GB，写入能力约5万点/秒。
## 数据样例 ##
- tag：host，tag_0，tag_1，tag_2，均为string类型
- field：value_1，value_2，均为float32类型
- 时间戳：timestamp，为unix_millis类型

其中，tag中的host是必有的，其他tag的数量可通过测试脚本的 -tag 选项修改。

    {
	  "host": "host_24",
	  "tag_0": "v_3411",
	  "tag_1": "v_2656",
	  "tag_2": "v_713",
	  "value1": 7.967921,
	  "value2": 2.0137544,
	  "timestamp": 1515036902
	}

## 测试步骤 ##
**1.建表**
命令如下
```
    #建立metric（注意这里tags里只有一个host，但当写入的数据有新的字段时，这些字段将自动作为tag，放入tags里面）
	curl -u {user}:{passwd} -XPUT {ctsdb_ip_port}/_metric/ctsdb_bench?pretty -d '{ 
	"tags": {
	"host": "string"
	},
	"fields":{
	"value_1": "float",
	"value_2": "float"
	},
	"time": {   
	"name": "timestamp",
	"format": "epoch_second"
	},
	"options": { 
	"expire_day": -1, 
	"refresh_interval": "10s",   
	"number_of_shards": 3, 
	"number_of_replicas": 1, 
	"rolling_period": -1
	}
	}'
	# 查询metric
	curl {ctsdb_ip_port}/_metric/ctsdb_bench?pretty
	# 删除metric（同时会删除对应的所有数据）
	curl -XDELETE  {ctsdb_ip_port}/_metric/ctsdb_bench
```
>  其中，{ctsdb_ip_port} 为腾讯云提供的CTSDB访问端口,{user}和{passwd}分别为用户名和密码。


**2.写入数据**

使用脚本批量写入，参数简介： 
脚本在附件中，ctsdb_benchmark\bin目录下
 - batch int
    批量写入点数 (default 5000)
 - print_interval int
    打印写入速率的时间间隔, 单位：s (default 5)
 - routing
    是否使用routing功能（用于提高查询效率）
 - run_time int
    写入进程运行时间，单位：s (default 300)
 - tag int
    每条数据Tag个数 (default 3)
 - threads int
    写入并发数 (default 9)
 - urls string
    CTSDB访问列表地址（格式：http://{ip1}:{port1},http://{ip2}:{port2},http://{ip3}:{port3}）
 -user_passwd string
    用户名密码(格式：{user}:{passwd})

使用样例：
```
    ./ctsdb_bench -urls=http://10.125.32.102:9200,http://10.125.32.102:9201 -threads=10
```

脚本输出： 
分为三部分，param：选项参数，qps：每段时间间隔内的qps，result：最终结果
```
    -------------- param --------------
	tag: 3
	batch: 5000
	routing: false
	threads: 9
	urls: [***]
	print_interval: 10
	-------------- qps --------------
	2018-01-04 12:31:27.889214892 +0800 CST , qps: 71500/s
	2018-01-04 12:31:37.889166997 +0800 CST , qps: 69500/s
	2018-01-04 12:31:47.889225539 +0800 CST , qps: 59500/s
	2018-01-04 12:31:57.889212547 +0800 CST , qps: 60000/s
	2018-01-04 12:32:07.88920677 +0800 CST , qps: 59000/s
	2018-01-04 12:32:17.889202309 +0800 CST , qps: 58000/s
	-------------- result --------------
	doc count: 3775000, bulk count: 755, qps: 62916/s
```
> 可以看到峰值写入速率为7.1w/s，平均写入速率为6.3w/s

**3.查看写入的数据量**

命令如下
```

	# 查询命令
	curl '{ctsdb_ip_port}/_cat/indices/ctsdb_bench@0_-1?v'
	#返回结果
	health status indexuuid   pri rep docs.count docs.deleted store.size pri.store.size
	green  open   ctsdb_bench@0_-1 EKPS4Q9rRuuvoZYZ-wCQlQ   3   1   209700000  1.4gb733.1mb
```
**4.查询数据**

样例查询1：查询一段时间内某个host的所有数据
```  
    # 查询命令
	curl -XPOST "{ctsdb_ip_port}/ctsdb_bench/_search?pretty" -d '{
	  "size": 100,
	  "query": {
	    "bool": {
	      "filter": [
	        {
	          "range": {
	            "timestamp": {
	              "format": "yyyy-MM-dd HH:mm:ss",
	              "time_zone": "+08:00",
	              "gte": "2018-01-01 00:00:00",
	              "lt": "2018-01-08 00:00:00"
	            }
	          }
	        },
	        {
	          "term": {
	            "host": "host_3368"
	          }
	        }
	      ]
	    }
	  },
	  "docvalue_fields": [
	    "host",
	    "tag_0",
	    "tag_1",
	    "tag_2",
	    "value_1",
	    "value_2",
	    "timestamp"
	  ]
	}'
	# 返回结果
	{
	  "took" : 3,
	  "timed_out" : false,
	  "_shards" : {
	    "total" : 3,
	    "successful" : 3,
	    "skipped" : 0,
	    "failed" : 0
	  },
	  "hits" : {
	    "total" : 4194,
	    "max_score" : 0.0,
	    "hits" : [
	      {
	        "_index" : "ctsdb_bench@0_-1",
	        "_type" : "doc",
	        "_id" : "AWC_aZ3gxbEXnFyEZTmi",
	        "_score" : 0.0,
	        "fields" : {
	          "host" : [
	            "host_3368"
	          ],
	          "value_2" : [
	            1651.0557861328125
	          ],
	          "tag_0" : [
	            "v_266"
	          ],
	          "tag_1" : [
	            "v_189"
	          ],
	          "tag_2" : [
	            "v_4461"
	          ],
	          "value_1" : [
	            3033.96337890625
	          ],
	          "timestamp" : [
	            1515039821000
	          ]
	        }
	      },
	      {
	        "_index" : "ctsdb_bench@0_-1",
	        "_type" : "doc",
	        "_id" : "AWC_aV_eMdRQ4gVPAh2d",
	        "_score" : 0.0,
	        "fields" : {
	          "host" : [
	            "host_3368"
	          ],
	          "value_2" : [
	            3133.74658203125
	          ],
	          "tag_0" : [
	            "v_4505"
	          ],
	          "tag_1" : [
	            "v_1657"
	          ],
	          "tag_2" : [
	            "v_2986"
	          ],
	          "value_1" : [
	            535.3303833007812
	          ],
	          "timestamp" : [
	            1515039821000
	          ]
	        }
	      },
	      {
	        "_index" : "ctsdb_bench@0_-1",
	        "_type" : "doc",
	        "_id" : "AWC_aWTdMdRQ4gVPAmu9",
	        "_score" : 0.0,
	        "fields" : {
	          "host" : [
	            "host_3368"
	          ],
	          "value_2" : [
	            676.7848510742188
	          ],
	          "tag_0" : [
	            "v_3521"
	          ],
	          "tag_1" : [
	            "v_531"
	          ],
	          "tag_2" : [
	            "v_4813"
	          ],
	          "value_1" : [
	            243.2778778076172
	          ],
	          "timestamp" : [
	            1515039821000
	          ]
	        }
	      }
	     ......
	    ]
	  }
	}
```
样例查询2：查询一段时间内某个host的所有数据，对结果按分钟粒度分桶，计算每个桶内有多少条数据和桶内value_1字段的最大值。
```
    # 查询命令
	curl -XPOST "{ctsdb_ip_port}/ctsdb_bench/_search?pretty" -d '{
	  "size": 0,
	  "query": {
	    "bool": {
	      "filter": [
	        {
	          "range": {
	            "timestamp": {
	              "format": "yyyy-MM-dd HH:mm:ss",
	              "time_zone": "+08:00",
	              "gte": "2018-01-01 00:00:00",
	              "lt": "2018-01-08 00:00:00"
	            }
	          }
	        },
	        {
	            "term":{
	            "host":"host_3368"
	            }
	        }
	      ]
	    }
	  },
	  "aggs":{
	    "buckets":{
	      "date_histogram":{
	        "field":"timestamp",
	        "interval":"1m",
	        "format":"yyyy-MM-dd-HH:mm:ss"
	      },
	      "aggs":{
	        "max_value_1":{
	          "max":{
	            "field":"value_1"
	          }
	        }
	      }
	    }
	  }
	}'
	# 返回结果
	{
	  "took" : 73,
	  "timed_out" : false,
	  "_shards" : {
	    "total" : 3,
	    "successful" : 3,
	    "skipped" : 0,
	    "failed" : 0
	  },
	  "hits" : {
	    "total" : 4194,
	    "max_score" : 0.0,
	    "hits" : [ ]
	  },
	  "aggregations" : {
	    "buckets" : {
	      "buckets" : [
	        {
	          "key_as_string" : "2018-01-04-04:17:00",
	          "key" : 1515039420000,
	          "doc_count" : 1300,
	          "max_value_1" : {
	            "value" : 3364.01318359375
	          }
	        },
	        {
	          "key_as_string" : "2018-01-04-04:18:00",
	          "key" : 1515039480000,
	          "doc_count" : 545,
	          "max_value_1" : {
	            "value" : 3364.951904296875
	          }
	        },
	        {
	          "key_as_string" : "2018-01-04-04:19:00",
	          "key" : 1515039540000,
	          "doc_count" : 0,
	          "max_value_1" : {
	            "value" : null
	          }
	        }
	    ......
	    ]
	```
