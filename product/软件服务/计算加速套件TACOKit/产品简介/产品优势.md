TACO Train AI 训练加速引擎和 TACO Infer AI 推理加速引擎通过软硬件协同优化，屏蔽底层硬件差异，适配 CPU、GPU、NPU 等不同加速硬件，降低用户使用计算资源的学习成本的同时提高计算效能。

## TACO Train AI 训练加速引擎优势

###  多层级深度优化加速
提供从自底向上的网络通信、分布式策略及训练框架等多层级的优化加速组件，用户可以根据需要选择适配。

### 支持无侵入式业务迁移
HARP、LightCC 等优化技术支持插件式集成，无需业务代码改动，即可加速分布式训练业务。

### 灵活扩展分布式训练场景
支持大规模多机多卡分布式训练场景，提高加速比和模型迭代效率。

### 训练性能提升数据

- TencentTensorflow（以下简称 TTF）动态 Embedding 在某推荐业务上对 AUC 的提升效果：
![img](https://main.qcloudimg.com/raw/6c812787715e8fcec62ffd32204a42f5.png)        
- TTF XLA 在某游戏业务上的性能加速效果：
![img](https://main.qcloudimg.com/raw/fa625ab276b9fc8f87419fbacd8f7507.png)        
- 在腾讯云50G VPC 环境下，ResNet50的多机训练加速效果：
![img](https://main.qcloudimg.com/raw/40f554fabea5ec282b6349a33a4719f4.png)        
- 在腾讯云50G VPC 环境下，Transformer 的多机训练加速效果：
![img](https://main.qcloudimg.com/raw/31e57bc8b8ae9c9a4cd2536458e8db7e.png)        
- 在腾讯云50G VPC 环境下，BERT-Base 的多机训练加速效果：
![img](https://main.qcloudimg.com/raw/754c416a6b7e8d796c380f35d1025fbc.png)        



##  TACO Infer AI 推理加速引擎优势

#### 部署简洁
TACO Infer 仅有一行简洁的优化接口，不会改变用户的模型格式。用户可以保持其一贯的使用和部署习惯，并提供插件式的第三方开发接口，支持适配不同业务场景。

#### 软硬件兼容
支持多种框架模型和多种加速硬件，可运行在虚拟机、物理机、容器等各种环境。

#### 一站式解决推理部署相关优化依赖
集成硬件厂商的定向开源的加速方案，整合先进的编译优化、图优化和算子优化技术。
