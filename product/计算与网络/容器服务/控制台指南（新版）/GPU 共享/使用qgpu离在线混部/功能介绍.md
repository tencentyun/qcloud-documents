
## 功能概述
通常场景下，qGPU Pod 会公平地使用物理 GPU 资源，qGPU 内核驱动为各任务分配等价的 GPU 时间片。但不同 GPU 计算任务的运行特点和重要性会有很大差异，导致对 GPU 资源的使用和要求不同。如实时推理对 GPU 资源比较敏感，要求低延迟，在使用时需要尽快拿到 GPU 资源进行计算，但它对 GPU 资源的使用率通常不高。模型训练对 GPU 资源使用量较大，但对延迟敏感度较低，可以忍受一定时间的抑制。
在这种背景下，腾讯云推出了 qGPU 离在线混部功能。qGPU 离在线混部是腾讯云创新性推出的 GPU 离在线混部调度技术，它支持在线（高优）任务和离线（低优）任务同时混合部署在同一张 GPU 卡上，在内核与驱动层面，实现了低优100%使用闲置算力及高优100%抢占。依赖 qGPU 离在线混部调度技术，可将用户的 GPU 资源做进一步压榨，将 GPU 利用率提升到100%，把 GPU 使用成本降到最低。
![](https://qcloudimg.tencent-cloud.cn/raw/f0798dc99609e88ce27db8d56973d3ad.png)

## 功能优势
qGPU 离在线混部实现了对 GPU 算力资源的两个“100%”控制，通过创新性的技术做到了对 GPU 算力的极限压榨：
- 100%使用高优闲置算力：高优任务闲时，低优任务可100%使用 GPU 算力资源。
- 100%抢占低优占用算力：高优任务忙时，可100%抢占低优任务所使用 GPU 算力资源。

## 典型场景
#### 在线推理与离线推理混部
搜索 / 推荐等推理任务用于支持线上服务，对 GPU 算力实时性要求。数据预处理等推理任务用于支持线下数据清洗和处理，对 GPU 算力实时性要求较低。通过将线上推理业务设置为高优任务，线下推理业务设置成低优任务，混合部署在同一张 GPU 卡上。

#### 在线推理与离线训练混部
实时推理对 GPU 算力可用性要求高，资源使用较少。模型训练对 GPU 算力使用较多，敏感度要求较低。通过将推理设置为高优任务，训练设置为低优任务，混合部署在同一张 GPU 卡上。

## 技术原理
![](https://qcloudimg.tencent-cloud.cn/raw/5eeb358aaf0866976fff229191f3304f.png)
通过 TKE 集群提供的在离线调度策略可以开启 qGPU 离在线混部能力，帮助在线任务（高优）和离线任务（低优）更高效的共享使用物理 GPU 资源。qGPU 离在线混部技术主要包含两个功能：
#### 功能1：低优 Pod 可以100%使用闲置算力
低优 Pod 在调度到节点 GPU 上后，如果 GPU 算力没有被高优 Pod 占用，低优 Pod 可以完全使用 GPU 算力。多个低优 Pod 共享 GPU 算力会受到 qGPU policy 策略控制。多个高优 Pod 之间不受具体 policy 控制，会是争抢模式。

#### 功能2：高优 Pod 可以100%抢占低优 Pod
qGPU 离在线混部提供了一种优先级抢占能力，可以保证高优 Pod 在忙时能立刻、完全使用 GPU 算力资源，这是通过一种优先级抢占调度策略实现的。我们在 qGPU 驱动层实现了这种绝对抢占能力：
首先，qGPU 驱动可以感知高优 Pod 对 GPU 算力的需求。高优 Pod 一旦提交涉及 GPU 算力的计算任务，qGPU 驱动会在第一时间将算力全部提供给高优 Pod 使用，响应时间被控制在1ms以内。当高优 Pod 无任务运行时，驱动会在100ms后释放所占用算力，并重新分配给离线 Pod 使用。
其次，qGPU 驱动可以支持计算任务的暂停和继续。当高优 Pod 有计算任务运行时，原有占用 GPU 的低优 Pod 会立刻被暂停，将 GPU 算力让出，给高优 Pod 使用。当高优 Pod 任务结束，低优 Pod 会随即被唤醒，按照中断点继续计算。各优先级计算任务运行的时序图如下所示：
	![](https://qcloudimg.tencent-cloud.cn/raw/cabe84f2592d2be1d1462b3c46460b0b.png)

#### 调度策略
在普通 qGPU 节点中，用户可以通过设置 policy 影响不同 Pod qGPU 在同一张卡上的调度策略。离在线混部功能中，policy 只会对低优 Pod 的调度产生影响。
- 低优 Pod
当前高优 Pod 处于休眠状态，低优 Pod 在运行，低优 Pod 之间仍会按照 policy 策略调度。当高优 Pod 开始使用 GPU 算力，所有低优 Pod 会立刻被暂停，直到高优 Pod 计算任务结束，低优任务会重新按照 policy 策略继续运行。
- 高优 Pod
高优 Pod 在有计算任务后会立即抢占 GPU 算力，高优 Pod 与低优 Pod 间是绝对抢占关系，不受具体 policy 影响。多个高优 Pods 之间的 GPU 算力分配是一种争抢模式，不受具体 policy 策略控制。
