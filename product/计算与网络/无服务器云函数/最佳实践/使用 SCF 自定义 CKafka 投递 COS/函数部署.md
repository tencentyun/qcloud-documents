## 环境准备

在开始部署云函数前，您需要完成以下操作：
1. 在您的电脑上，安装 Python2.7 环境和 Pip 工具。
>?  您也可以通过下载示例代码的压缩包，省略环境搭建和本机代码编写工作。
> 示例代码的压缩包 [请点此下载](https://main.qcloudimg.com/raw/498f2eaf73fdd65665ae865e20a9e6b4.zip)。

2. 使用腾讯云账号登录 [云 API 密钥控制台](https://console.cloud.tencent.com/cam/capi)，查看并获取 SecretID 和 SecretKey。如下图所示：
>? 在云函数中调用 AI 和 COS 的 SDK 接口时，需使用到 SecretID 和 SecretKey 密钥参数。

 ![](https://main.qcloudimg.com/raw/b6009190cd36cebf503dbd120880214d.png)

3. 切换到 [对象存储 COS 的控制台](https://console.cloud.tencent.com/cos5/bucket)，创建一个 bucket。
该 bucket 用于存放云函数处理后的 Ckafka 消息。
4. 切换到 [Ckafka 控制台](https://console.cloud.tencent.com/ckafka?rid=1)，购买 Ckafka 实例，并创建 Topic。

## 创建云函数

> ? 如果您已下载示例代码的压缩包，可直接执行 [步骤5](#step5)。

1. 在本地创建待放置函数代码的文件夹，并在该目录下，执行以下命令，安装 pytz 库。
```
pip install pytz -t .
```

2. 在函数代码文件夹的根目录下，使用以下示例代码创建 Python 文件。
>? Python 文件名可自定义，推荐命名为：Ckafka_SCF_COS.py。

 ```
# -*- coding: utf-8 -*-
import os
import logging
import datetime
import random
import pytz
from qcloud_cos_v5 import CosConfig
from qcloud_cos_v5 import CosS3Client
from qcloud_cos_v5 import CosServiceError
from qcloud_cos_v5 import CosClientError
# 设置用户属性, 包括secret_id, secret_key, region，bucket
appid = '1251762227'  # 请替换为您的 APPID
secret_id = u'*********'  # 请替换为您的 SecretId
secret_key = u'********'  # 请替换为您的 SecretKey
region = 'ap-guangzhou'  # 替换为用户的region
token = ''  # 使用临时密钥需要传入Token，默认为空,可不填
bucket_upload = "mason-ckafka-scf-cos-1251762227"  # 替换为需要写入的COS Bucket
# 获取配置对象
config = CosConfig(Region=region, Secret_id=secret_id, Secret_key=secret_key, Token=token)
client = CosS3Client(config)
logger = logging.getLogger()
# 生成写入文件名
def object_key_generater():
    logger.info("start to generate key name")
    tz = pytz.timezone('Asia/Shanghai')
    time = datetime.datetime.now(tz).strftime("%Y-%m-%d-%H:%M:%S")
    random_name = random.randint(1, 200)
    dir_name = datetime.datetime.now(tz).strftime("%Y-%m-%d-%H")
    file_name = format(time) + '-' + str(random_name) +'.txt'
    object_key = '{}/{}'.format( dir_name,file_name)
    return object_key
# 检查文件是否已存在
def check_cos_file(key):
    try:
        resp = client.head_object(
            Bucket=bucket_upload,
            Key=key
        )
        logger.info("check_cos_file of resp is [%s]"% resp)
        return True
    except CosServiceError, e:
        # print("head error")
        # if e['code'] == "NoSuchResource":
        logger.info("e is [%s]"% e)
        if e.get_error_code()== "NoSuchResource":
            logger.info("check_cos_file is [%s]"% e.get_error_code())
            return False
#删除本地文件
def delete_local_file(src):
    logger.info("delete files and folders")
    if os.path.isfile(src):
        try:
            os.remove(src)
        except:
            pass
    elif os.path.isdir(src):
        for item in os.listdir(src):
            itemsrc = os.path.join(src, item)
            delete_local_file(itemsrc)
        try:
            os.rmdir(src)
        except:
            pass
#上传文件到COS
def upload_loacal_file(loacalpath):
    logger.info("Start to upload")
    if os.path.isfile(loacalpath):
        logger.info("local_filename is [%s]" % loacalpath)
        key = object_key_generater()
        while check_cos_file(key) == True:
            key = object_key_generater()
        logger.info("cos_object_name is [%s]" % key)
        response = client.put_object_from_local_file(
            Bucket=bucket_upload,
            LocalFilePath=loacalpath,
            Key=key)
        logger.info("upload result is [%s]" % response)
        delete_local_file(str(loacalpath))
        return True
    else:
        logger.info("Upload fail")
        return False
def main_handler(event, context):
    logger.info("start main handler")
    local_path = '/tmp/local_file.txt'
    data = ""
    with open(local_path, "a") as f:
        for record in event['Records']:
            if 'Ckafka' not in record.keys():
                continue
            data = record['Ckafka']['msgBody'].decode("unicode-escape")
            # logger.info("data is [%s]" % data)
            f.write(data)
            f.write('\r\n')
    if upload_loacal_file(local_path) == True:
        return "write success"
    else:
        return "write fail"
```

3. 保存 Python 文件，并回到根目录。
4. 压缩根目录中的所有文件，并保证 **Ckafka_SCF_COS.py 存在于根目录下，且压缩包为 zip 格式。**
>! 压缩所有文件时，不要只对外层的文件夹压缩。
<span id="step5"></span>
5. 切换至 [无服务器云函数控制台](https://console.cloud.tencent.com/scf/list?rid=4)，将地域设置为 “广州”，并单击【新建】。
6. 在 “新建函数” 页面，填写以下参数信息：
 - 创建方式：选择 “空白函数”。
 - 函数名称：自定义，推荐命名为 Ckafka_SCF_COS。
 - 运行环境：选择 Python2.7。
7. 单击【完成】。
8. 选择 “函数代码” 页签，并在该页签中，将 “提交方法” 设置为 “本地上传zip包”。
9. 上传已压缩的 zip 包，将**“执行方法”设置为：Ckafka_SCF_COS.main_handler**，单击【保存】。如下图所示：
![](https://main.qcloudimg.com/raw/30a47380d8a412286bc4819c5217d8a6.png)
10. 代码保存成功后，将 “提交方法” 设置为 “在线编辑”，并将 appid、secret_id、secret_key 和 bucket_upload 替换为您的 APPID、SecretId、SecretKey 和 bucket，单击【保存】，完成创建。如下图所示：
![](https://main.qcloudimg.com/raw/72f03a350b6327473ce14146994ca6c6.png)


## 配置 Ckafka 触发器

1. 在 “触发方式” 页签中，单击【添加触发方式】，并根据页面的参数信息进行填写。如下图所示：
![](https://main.qcloudimg.com/raw/6b7d486e0fe4d3b23b7c2a7bd5a4a5a6.png)
主要参数信息如下：
 - 触发方式：选择 “Ckafka触发”。
 - Ckafka实例：选择需要对接的 Ckafka 实例。
 - Topic：选择需要对接的 Topic。
 - 最大批量消息数：请根据单条消息的大小和实际业务量进行配置，默认消息总数的大小要小于1MB。单次触发云函数运行时最大可处理的消息条数。例如，配置500，则最多会有500条消息会触发一次云函数。Ckafka 生产的消息过多时，消息组将自动触发多个函数实例运行，加速消息速度。
2. 单击【保存】，即完成操作。
