本文介绍如何在 GPU 云服务器实例上部署及使用 TI-ACC 训练加速。


## 说明事项[](id:explanation)
- 目前 TI-ACC 处于内测阶段，您需填写 [使用申请](https://cloud.tencent.com/apply/p/vl6fzemdq1)。通过申请后可获取私有镜像临时登录指令。
- TI-ACC 训练加速仅支持以下操作系统、Python版本、设备类型及框架版本：
 - 操作系统：Linux
 - Python 版本：Python 3.6
 - 设备类型：GPU 实例，并支持 CUDA 10.1、10.2、11.1
 - 框架版本：PyTorch 1.7.1、1.8.1、1.9.0


## 操作步骤

### 实例环境准备

1. 参考 [购买 NVIDIA GPU 实例](https://cloud.tencent.com/document/product/560/30211) 创建实例。其中：
 - **镜像**：请选择 Ubuntu 18.04及以上版本。并勾选“后台自动安装GPU驱动”，使用自动安装功能安装 GPU 驱动。
CUDA 及 cuDNN 的自动安装非本次部署的必选项，您可根据实际情况选择。如下图所示：
![](https://main.qcloudimg.com/raw/9450ebf911ca9b88a847c2a299fcc2cc.png)
 - **系统盘**：结合 Docker 镜像的大小以及训练中间状态文件的存储，推荐配置100G以上的系统盘。
2. 请对应实例的操作系统类型，参考以下文档安装 Docker。
<table>
<thead>
<tr>
<th>操作系统</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>CentOS</td>
<td>参考 <a href="https://docs.docker.com/engine/install/centos/">Docker 官方文档 - 在 CentOS 中安装 Docker</a> 进行安装。</td>
</tr>
<tr>
<td>Ubuntu</td>
<td>参考 <a href="https://docs.docker.com/engine/install/ubuntu/">Docker 官方文档 - 在 Ubuntu 中安装 Docker</a> 进行安装。</td>
</tr>
</tbody></table>
3. 安装 nvidia-docker，详情请参见 [NVIDIA 官方文档 - 安装nvidia-docker](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker)。
4. 登录实例，并依次执行命令获取加速镜像。本文提供如下参考命令：
 - 使用 [说明事项](#explanation) 中已获取的私有镜像临时登录指令，登录腾讯云容器服务 Docker Registry 加速镜像仓库。
```plaintext
docker login tiacc-test.tencentcloudcr.com --username xxx --password xxx
```
<dx-alert infotype="explain" title="">
username 为账号 ID，password 为临时登录指令。请结合实际情况进行替换。
</dx-alert>
 - 从 Registry 加速镜像仓库拉取镜像。
```plaintext
docker pull tiacc-test.tencentcloudcr.com/tiacc/tiacc_pytorch:[tag]
```
<dx-alert infotype="explain" title="">
tag 为镜像名称，请结合实际情况进行替换。
</dx-alert>
5. 执行命令，启动加速镜像并进入容器实例。本文提供如下参考命令：
```plaintext
docker run -it --net=host --privileged --rm --gpus all --shm-size=32g --ulimit memlock=-1 --ulimit stack=67108864 --name TI-ACC-gpu tiacc-test.tencentcloudcr.com/tiacc/tiacc_pytorch:[tag]
```
6. 在容器中依次执行命令，配置多实例镜像间免密登录。
```plaintext
# 修改 docker 的 ssh 端⼝，确保和宿主机的端口不冲突
sed -i 's/#Port 22/Port 2222/' /etc/ssh/sshd_config
```
```plaintext
# 启动 ssh 服务
service ssh start && netstat -tulpn
```
```plaintext
# 免密处理
# 将 publickey 添加至 ~/.ssh/authorized_keys，请注意本机和对端的 key 均需添加至 authorized_keys
ssh-keygen
```
```plaintext
# 确认 ssh 可以互通
ssh -p 2222 root@10.0.0.17
or
ssh -p 2222 root@10.0.0.11
```
```plaintext
# 配置 ssh 默认使⽤2222端⼝通信，编辑两台实例的 ~/.ssh/config
Host *
StrictHostKeyChecking no
Port 2222
```



### 使用训练加速
训练加速中的通信加速能力由兼容原生的 DDP 工具提供，用户无需修改原生的使用代码即可直接使用。数据 IO 优化、自适应 FP16均通过已封装的简单函数/类进行提供，仅需增加少量代码便可使用。

#### 引入训练加速库
执行以下命令，引入训练加速库。
```plaintext
import tiacc_training.torch
```

#### 使用 DDP 分布式训练通信优化
在原生 DPP 训练代码开头处，增加以下代码，即可使用 DDP 分布式训练通信优化。
```plaintext
import tiacc_training.torch.distributed as tdist
tdist.init_tiacc_training()
```
以 mpirun 的方式启动训练脚本，2机16卡训练脚本的内容参考示例如下：
```plaintext
node_list=node1:8,node2:8   //node1和node2为服务器IP或主机名
gpu_num=16  //总的gpu卡数

mpirun --allow-run-as-root -np ${gpu_num} -H ${node_list} -map-by slot -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 \
-x NCCL_DEBUG=INFO \
-x NCCL_SOCKET_IFNAME=eth0 \
-x NCCL_IB_DISABLE=1 \
-x LIGHT_2D_ALLREDUCE=1 \     //使用2D allreduce通信加速
-x TIACC_TRAINING_FUSION_THRESHOLD=25217728 \    //TIACC_Training会对小的包进行融合通信，TIACC_TRAINING_FUSION_THRESHOLD表示融合后桶的最大字节数
-x TIACC_TRAINING_NUM_NCCL_STREAMS=3 \
python3 \
/demo/TIACC-Training-Benchmarks/pytorch_native_ddp_demo.py  //训练脚本
```

硬件环境以 GPU 实例 GN10Xp.20XLARGE320为例，DDP 分布式训练通信优化实测数据如下表所示：
<table>
<tr>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生 DDP<br>（examples/sec per V100）</th>
<th>TI-ACC 通信优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td rowspan=3>resnext50_32x4d</td>
<td>1（单机）</td>
<td>227</td>
<td>227</td>
</tr>
<tr>
<td>8（单机）</td>
<td>215 </td>
<td>215</td>
</tr>
<tr>
<td>16（双机）</td>
<td>116</td>
<td>158.6</td>
</tr>
</table>


#### 使用数据 IO 优化
执行以下命令，进行数据预处理及 IO 优化。
```plaintext
train_dataset = tiacc_training.torch.tiacc_torch_warp.IndexTFRDataset(tfrecored_dir, tfrecord_file, transform)
```
tfrecord_file 可使用 TI-ACC 提供的 tools 工具进行生成。说明如下：
<dx-accordion>
::: tiacc_training/tools/general_image_list.py
- **具体功能**：生成 tfrecord_file 需要的 image list。
- **输入参数**：
 - img_dir：必填，图片存放路径。包含若干文件夹，文件夹名为当前类别名。
 - img_list：必填，期望生成的 list 文件名，格式为 `图片路径 当前图片类别标签`。您可查看 [list 文件示例](https://tiacc-1308240844.cos.ap-nanjing.myqcloud.com/list%E6%96%87%E4%BB%B6%E7%A4%BA%E4%BE%8B.txt)。
 - label_str2int：非必填，类别名（str）到类别 id（int）的映射关系文件。若不输入，则会自动生成。您可查看 [label_str2int 文件示例](https://tiacc-1308240844.cos.ap-nanjing.myqcloud.com/label_str2int.pkl)。
- **使用示例**：
```plaintext
python3 tiacc_training/tools/general_image_list.py --img_dir val_demo/ --img_list val_list
```
:::
::: tiacc_training/tools/img2tfrecord.py
- **具体功能**：转 tfrecord 格式，生成数据 IO 优化需要的 tfrecord_file。
- **输入参数**：
 - img_dir：图片存放路径。
 - img_list：1中生成。
 - tfrecords_name：生成数据名称。
 - dataset_type：目前支持 ImageFold、coco 两种。
 - workers：非必填，默认为0，tfrecord 生成支持多线程。若需加速，可指定大于1的整数。
- **使用示例**：
```plaintext
python3 tiacc_training/tools/img2tfrecord.py --img_dir val_demo --img_list val_list --tfrecords_name val_demo --dataset_type ImageFold
```
:::
</dx-accordion>
硬件环境以 GPU 实例 GN10Xp.20XLARGE320为例，数据 IO 优化实测数据如下表所示：
<table>
<tr>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生 PyTorch<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO 优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td>resnet50 mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
</tr>
<tr>
<td>centernet mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
</tr>
</table>



#### 使用自适应混合精度优化
通过如下代码，使用自适应混合精度优化：
```plaintext
import torch.cuda.amp as amp 
scaler = amp.GradScaler() 
#实例化自适应混合精度策略类的对象
policy = tiacc_training.torch .tiacc_torch_warp.MixedPrecision_TrainingPolicy(policy,start_step,hold_step,end_step,test_interval,test_step)
#根据输入的参数得到当前epoch是否需要开启混合精度
mixed_precision = policy.enable_mixed_precision(epoch,lr,loss,scaler=scaler)
with amp.autocast(enabled=mixed_precision):
      outputs = model(inputs)
     loss = criterion(outputs, targets)
scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```
硬件环境以 GPU 实例 GN10Xp.20XLARGE320为例，使用自适应混合精度优化实测数据如下表所示：
<table>
<tr>
<th width="10%">模型</th>
<th width="15%">GPU 卡数</th>
<th>原生 PyTorch<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO 优化<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO+自适应混合精度优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td>resnet50 mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
<td>379.2</td>
</tr>
<tr>
<td>centernet mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
<td>30.6</td>
</tr>
</table>

## 训练加速类函数说明
<dx-accordion>
::: init_tiacc_training 函数
初始化 DDP 通信加速优化，会默认将原生 DDP 相关的函数调整为调用 TI-ACC 通信加速能力，原生 DDP 相关的主要模块/类包括：`torch.distributed` 和 `torch.nn.parallel.DistributedDataParallel()`。

:::
::: IndexTFRDataset 类
实现实例化训练过程中数据集的功能，底层实现了对于 CV 场景下的图片小文件 IO 的优化。

初始化参数说明如下表：
<table>
<tr>
<th>参数</th>
<th>类型</th>
<th>是否必填</th>
<th>参数说明</th>
<th>默认值</th>
<th>示例</th>
</tr>
<tr>
<td>tfrecored_dir</td>
<td>STRING</td>
<td>是</td>
<td>存放此数据 tfrecord 文件的目录。</td>
<td>无</td>
<td>'./tfrecord_train_path'</td>
</tr>
<tr>
<td> tfrecord_file</td>
<td>STRING</td>
<td>是</td>
<td>存放此数据 tfrecord index（标签+索引）的文件。</td>
<td>无</td>
<td>'./tfrecord_train_path/train.index'</td>
</tr>
<tr>
<td>transform</td>
<td>Callable</td>
<td>否</td>
<td>数据预处理变换方式。</td>
<td>None</td>
<td>'transforms.Compose([transforms.RandomHorizontalFlip(), <br>transforms.ToTensor(), <br>transforms.Normalize(mean=rgb_mean, std=rgb_std)])'</td>
</tr>
</table>
<table>
<tr>
<th>对象</th>
<th>类型</th>
<th>对象说明</th>
</tr>
<tr>
<td>dataset</td>
<td>IndexTFRDataset 类</td>
<td>训练过程中读取数据集的对象</td>
</tr>
</table>

:::
::: adaptfp16.MixedPrecision_TrainingPolicy 类
实现对训练过程中自动混合精度自适应策略的实例化。自适应策略包括时间混合精度、时间学习率混合精度策略、损失函数混合精度策略。

初始化参数说明如下表：
<table>
<tr>
<th>参数</th>
<th>类型</th>
<th>是否必填</th>
<th>参数说明</th>
<th>默认值</th>
<th>示例</th>
</tr>
<tr>
<td>policy</td>
<td>INT</td>
<td>是</td>
<td>
自适应混合精度策略：
<ul style="margin-bottom:0px;">
<li>0：时间混合精度，适用于通用自适应情况。</li>
<li>1：时间学习率混合精度策略，适用于训练过程中某一阶段 loss 波动出现异常的情况。</li>
<li>2：损失函数混合精度策略，适用于训练过程中 loss 下降过快或过慢情况。</li>
</ul>
</td>
<td>无</td>
<td>0</td>
</tr>
<tr>
<td>start_time</td>
<td>INT</td>
<td>否</td>
<td>开启自适应混合精度的开始时间，一般建议设为10。策略为0和1时必填，为2时非必填。</td>
<td>10</td>
<td>10</td>
</tr>
<tr>
<td>end_time</td>
<td>INT</td>
<td>否</td>
<td>开启自适应混合精度的结束时间，一般建议设为最后一个 epoch 时间。策略为0和1时必填，为2时非必填。</td>
<td>None</td>
<td>1000</td>
</tr>
<tr>
<td>hold_time</td>
<td>INT</td>
<td>否</td>
<td>开启策略1时的保持时间，在保持时间内采用统一策略（开启或者不开启）。一般建议为训练过程中 loss 异常波动的持续时间。策略为1时必填，为0和2时非必填。</td>
<td>None</td>
<td>20</td>
</tr>
<tr>
<td>interval_time</td>
<td>INT</td>
<td>否</td>
<td>开启策略2的间隔时间，值为1000即每间隔1000轮 epoch 开启策略2。策略为2时需要填写，为0和1时无需必填。</td>
<td>1000</td>
<td>1000</td>
</tr>
<tr>
<td>interval_hold_time</td>
<td>INT</td>
<td>否</td>
<td>在 interval_time 间隔时间开启策略2后的保持时间。值为100时，若 interval_time 为1000，则在1000 - 1100,2000 - 2100...开启策略2。策略为2时需要填写，为0和1时无需必填。</td>
<td>100</td>
<td>100</td>
</tr>
</table>
<table>
<tr>
<th>对象</th>
<th>类型</th>
<th>对象说明</th>
</tr>
<tr>
<td>policy</td>
<td>MixedPrecision_TrainingPolicy 类</td>
<td>训练过程中自动混合精度自适应策略的实例化对象。</td>
</tr>
</table>

:::
::: enable_mixed_precision 函数方法
属于 MixedPrecision_TrainingPolicy 类，根据输入的参数得到当前 epoch 是否需要开启自动混合精度。


输入参数说明如下表：
<table>
<tr>
<th>参数</th>
<th>类型</th>
<th>是否必填</th>
<th>参数说明</th>
<th>默认值</th>
<th>示例</th>
</tr>
<tr>
<td>epoch</td>
<td>INT</td>
<td>是</td>
<td>当前的 epoch。</td>
<td>无</td>
<td>20</td>
</tr>
<tr>
<td>scaler</td>
<td>torch.cuda.amp.GradScaler </td>
<td>是</td>
<td>梯度缩放实例化对象。</td>
<td>无</td>
<td>scaler</td>
</tr>
<tr>
<td>lr</td>
<td>float</td>
<td>否</td>
<td>lr 为当前 epoch 的学习率。</td>
<td>None</td>
<td>0.01</td>
</tr>
<tr>
<td>loss</td>
<td>float</td>
<td>否</td>
<td>loss 为上一轮 epoch 的损失值。</td>
<td>None</td>
<td>0.1</td>
</tr>
</table>

输出参数说明如下表：
<table>
<tr>
<th>输出参数</th>
<th>类型</th>
<th>参数说明</th>
</tr>
<tr>
<td>mixed_precision</td>
<td>BOOL</td>
<td>输入的参数得到当前 epoch 是否需要开启自动混合精度，是返回 TRUE，否返回 FLASE。</td>
</tr>
</table>
:::
</dx-accordion>

