AI 加速服务（Artificial Intelligence Acceleration Service，TI-ACC）为企业提供 AI 模型训练、推理加速服务，支持多种框架和场景，显著提高模型训练推理效率，降低用户成本。


## 功能介绍

### TI-ACC 推理加速
TI-ACC 推理加速在推荐、CV、NLP 等模型推理场景中，实现计算优化、低精度加速、内存优化等能力。能力通过统一的加速库和优化函数的形式提供，用户仅需通过一个函数即可进行推理加速优化，函数支持多种模型输入格式、多种优化级别、固定&动态输入维度、自定义算子、自定义测试数据输出测试报告以及对模型进行保存输出，并很好的兼容原生 PyTorch、TensorFlow 框架，无需进行模型转换，可帮助用户降低使用模型推理的门槛，显著节省训练时间和计算成本。


### TI-ACC 训练加速
TI-ACC 训练加速在推荐、CV、NLP 等模型训练场景中，实现数据 IO 优化、计算加速、通信加速、并行训练、显存优化等能力。能力通过统一的加速库以及简单易用的函数/类的形式提供，并很好的兼容原生 PyTorch、TensorFlow 框架和 DDP、PS 工具，可帮助用户降低使用模型训练的门槛，显著节省训练时间和计算成本。




## 具备优势

### 性能优越
基于业界领先的 AI 加速技术，提供高性能模型训练、推理加速服务，可显著提升性能，经微信刷脸支付、手 Q、微视等多个项目验证。您可通过下列实测数据，了解 TI-ACC 提升性能的能力。

<dx-accordion>
::: 推理加速实测数据
**硬件环境**：GPU 实例 GN7.2XLARGE32
<table>
<tr>
<th >模型</th>
<th>batch</th>
<th>torchscript(ms)</th>
<th>TI-ACC(ms)</th>
<th>加速比</th>
</tr>
<tr>
<td rowspan=2>resnet50<br>(torchvision)<br>224x224</td>
<td>1</td>
<td>5.4622</td>
<td>1.1482</td>
<td>4.8x</td>
</tr>
<tr>
<td>8</td>
<td>27.062 </td>
<td>4.5707</td>
<td>5.9x</td>
</tr>
<tr>
<td rowspan=2>resnest50<br>(mmcls)<br>224x224</td>
<td>1</td>
<td>7.7667</td>
<td>4.3958</td>
<td>1.8x</td>
</tr>
<tr>
<td>8</td>
<td>36.806</td>
<td>14.1152</td>
<td>2.6x</td>
</tr>
<tr>
<td rowspan=2>centernet<br>640x640</td>
<td>1</td>
<td>20.9992</td>
<td>4.7775</td>
<td>4.4x</td>
</tr>
<tr>
<td>8</td>
<td>170.5488</td>
<td>34.3523</td>
<td>5.0x</td>
</tr>
<tr>
<td rowspan=2> yolov3<br>(ultralytics)<br>640x640</td>
<td>1</td>
<td>47.19</td>
<td>10.3671</td>
<td>4.5x</td>
</tr>
<tr>
<td>8</td>
<td>302.983</td>
<td>82.6971</td>
<td>3.7x</td>
</tr>
<tr>
<td> Cascade Mask R-CNN<br>(mmdet)<br>2016x3008</td>
<td>1</td>
<td>600.0671</td>
<td>165.8467</td>
<td>3.6x</td>
</tr>
<tr>
<td> Faster R-CNN<br>(mmdet)<br>1088x800</td>
<td>1</td>
<td>107.3483</td>
<td>35.5021</td>
<td>3.0x</td>
</tr>
<tr>
<td>Vision Transformer<br>224x224</td>
<td>8</td>
<td>28.887</td>
<td>10.53</td>
<td>2.7x</td>
</tr>
<tr>
<td>Wide & Deep<br>(NVIDIA DeepLearningExamples)</td>
<td>512</td>
<td>15.7</td>
<td>4.436</td>
<td>3.5x</td>
</tr>
<tr>
<td>DeepFM<br>(NVIDIA DeepLearningExamples)</td>
<td>512</td>
<td>12.91</td>
<td>4.51</td>
<td>2.9x</td>
</tr>
</table>


:::
::: 训练加速-DDP 通信优化实测效果
**硬件环境**：GPU 实例 GN10Xp.20XLARGE320
<table>
<tr>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生 DDP<br>（examples/sec per V100）</th>
<th>TI-ACC 通信优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td rowspan=3>resnext50_32x4d</td>
<td>1（单机）</td>
<td>227</td>
<td>227</td>
</tr>
<tr>
<td>8（单机）</td>
<td>215 </td>
<td>215</td>
</tr>
<tr>
<td>16（双机）</td>
<td>116</td>
<td>158.6</td>
</tr>
</table>

:::
::: 训练加速-数据 IO 优化实测效果
**硬件环境**：GPU 实例 GN10Xp.20XLARGE320
<table>
<tr>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生 PyTorch<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO 优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td>resnet50 mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
</tr>
<tr>
<td>centernet mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
</tr>
</table>

:::
::: 训练加速-自适应混合精度优化实测效果
**硬件环境**：GPU 实例  GN10Xp.20XLARGE320
<table>
<tr>
<th width="10%">模型</th>
<th width="15%">GPU 卡数</th>
<th>原生 PyTorch<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO 优化<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO+自适应混合精度优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td>resnet50 mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
<td>379.2</td>
</tr>
<tr>
<td>centernet mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
<td>30.6</td>
</tr>
</table>

:::
</dx-accordion>


### 功能丰富
- 推理加速底层通过接口支持多种模型输入格式、多种优化级别、固定及动态输入维度、自定义测试数据输出测试报告以及对模型进行保存输出等功能。
- 训练加速底层通过接口提供数据 IO 优化、自适应 FP16、通信加速等功能。


### 接入便捷
推理加速和训练加速已支持原生的 Pytorch 框架，后续支持 TensorFlow 等框架，用户可直接在原生框架下使用 TI-ACC 的加速能力，无需进行额外的模型格式转换等适配工作。
- 推理加速整体能力通过一个函数提供，用户可通过该函数使用推理加速的所有能力。
- 训练加速中的通信加速能力由兼容原生的 DDP 工具提供，使用户无需修改原生的使用代码即可直接使用。数据 IO 优化、自适应 FP16均通过封装好的简单函数/类进行提供，仅需增加几行代码便可使用。


### 技术强大
- 推理加速底层提供计算优化、低精度加速、内存优化等能力。技术架构图如下所示：
![](https://qcloudimg.tencent-cloud.cn/raw/7762e29bb8ed421c3c28b0a1acc1cf0f.png)
- 训练加速底层提供数据 IO 优化、计算优化、通信加速、并行训练、显存优化等能力。技术架构图如下所示：
![](https://qcloudimg.tencent-cloud.cn/raw/9829b2d7e5fb5d6170dcbdd5d549727a.png)



## 开始使用
在推荐、CV、NLP 等模型训练和推理场景中，都可以使用 TI-ACC 的推理和训练加速能力。目前通过容器方式提供给用户使用，具体使用方式请参见 [推理加速部署及实践](https://cloud.tencent.com/document/product/560/64709) 及 [训练加速部署及实践](https://cloud.tencent.com/document/product/560/64710)。

