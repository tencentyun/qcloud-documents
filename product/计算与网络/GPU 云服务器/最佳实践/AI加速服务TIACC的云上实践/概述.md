AI 加速服务（Artificial Intelligence Acceleration Service，TI-ACC）为企业提供 AI 模型训练、推理加速服务，支持多种框架和场景，显著提高模型训练推理效率，降低用户成本。


## 功能介绍

### TI-ACC 推理加速
TI-ACC 推理加速在推荐、CV、NLP 等模型推理场景中，实现计算优化、低精度加速、内存优化等能力。能力通过统一的加速库和优化函数的形式提供，用户仅需通过一个函数即可进行推理加速优化。函数支持多种模型输入格式、多种优化级别、固定及动态输入维度、自定义测试数据输出测试报告以及对模型进行保存输出，并很好的兼容原生 Pytorch 框架，无需进行模型转换，可帮助用户以较低的门槛使用模型进行推理，显著节省训练时间和计算成本。


### TI-ACC 训练加速
TI-ACC 训练加速在推荐、CV、NLP 等模型训练场景中，实现数据 IO 优化、计算加速、通信加速、并行训练、显存优化等能力。能力通过统一的加速库以及简单易用的函数/类的形式提供，并很好的兼容原生 Pytorch 框架和 DDP 工具，可帮助用户以较低的门槛使用模型进行训练，显著节省训练时间和计算成本。



## 具备优势

### 性能优越
基于业界领先的 AI 加速技术，提供高性能模型训练、推理加速服务，可显著提升性能，经微信刷脸支付、手 Q、微视等多个项目验证。您可通过下列实测数据，了解 TI-ACC 提升性能的能力。

<dx-accordion>
::: 推理加速实测数据
**硬件环境**：GPU 实例 GN7.2XLARGE32
<table>
<tr>
<th>模型</th>
<th>batch</th>
<th>torchscript</th>
<th>TI-ACC</th>
<th>TI-ACC（fp16）</th>
</tr>
<tr>
<td rowspan=4>resnet50 torchvision 224x224</td>
<td>1</td>
<td>7.10</td>
<td>3.35</td>
<td>1.10</td>
</tr>
<tr>
<td>16</td>
<td>42.67 </td>
<td>30.75 </td>
<td>7.97 </td>
</tr>
<tr>
<td>32</td>
<td>82.79 </td>
<td>59.01 </td>
<td>14.12 </td>
</tr>
<tr>
<td>64</td>
<td>162.67 </td>
<td>115.62</td>
<td>26.49 </td>
</tr>
<tr>
<td rowspan=4>resnest50 mmcls 224x224</td>
<td>1</td>
<td>12.47 </td>
<td>7.78 </td>
<td>5.22</td>
</tr>
<tr>
<td>16</td>
<td>61.22 </td>
<td>44.40 </td>
<td>24.53 </td>
</tr>
<tr>
<td>32</td>
<td>168.47  </td>
<td>85.63</td>
<td>46.03  </td>
</tr>
<tr>
<td>64</td>
<td>348.70  </td>
<td>171.82 </td>
<td>88.44 </td>
</tr>
<tr>
<td rowspan=4>centernet-custom</td>
<td>1</td>
<td>29.28 </td>
<td>13.88 </td>
<td>4.89 </td>
</tr>
<tr>
<td>2</td>
<td>56.18 </td>
<td>27.22 </td>
<td>9.41 </td>
</tr>
<tr>
<td>4</td>
<td>113.25 </td>
<td>53.53</td>
<td>16.03</td>
</tr>
<tr>
<td>8</td>
<td>232.11  </td>
<td>108.45 </td>
<td>32.41  </td>
</tr>
</table>


:::
::: 训练加速-DDP 通信优化实测效果
**硬件环境**：GPU 实例 GN10Xp.20XLARGE320
<table>
<tr>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生 DDP<br>（examples/sec per V100）</th>
<th>TI-ACC 通信优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td rowspan=3>resnext50_32x4d</td>
<td>1（单机）</td>
<td>227</td>
<td>227</td>
</tr>
<tr>
<td>8（单机）</td>
<td>215 </td>
<td>215</td>
</tr>
<tr>
<td>16（双机）</td>
<td>116</td>
<td>158.6</td>
</tr>
</table>

:::
::: 训练加速-数据 IO 优化实测效果
**硬件环境**：GPU 实例 GN10Xp.20XLARGE320
<table>
<tr>
<th>模型</th>
<th>GPU 卡数</th>
<th>原生 PyTorch<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO 优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td>resnet50 mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
</tr>
<tr>
<td>centernet mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
</tr>
</table>

:::
::: 训练加速-自适应混合精度优化实测效果
**硬件环境**：GPU 实例  GN10Xp.20XLARGE320
<table>
<tr>
<th width="10%">模型</th>
<th width="15%">GPU 卡数</th>
<th>原生 PyTorch<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO 优化<br>（examples/sec per V100）</th>
<th>TI-ACC 数据 IO+自适应混合精度优化<br>（examples/sec per V100）</th>
</tr>
<tr>
<td>resnet50 mmcls</td>
<td>8（单机）</td>
<td>70.8</td>
<td>350.5</td>
<td>379.2</td>
</tr>
<tr>
<td>centernet mmdet</td>
<td>8（单机）</td>
<td>26.4</td>
<td>28.6</td>
<td>30.6</td>
</tr>
</table>

:::
</dx-accordion>


### 功能丰富
- 推理加速底层通过接口支持多种模型输入格式、多种优化级别、固定及动态输入维度、自定义测试数据输出测试报告以及对模型进行保存输出等功能。
- 训练加速底层通过接口提供数据 IO 优化、自适应 FP16、通信加速等功能。


### 接入便捷
推理加速和训练加速已支持原生的 Pytorch 框架，后续支持 TensorFlow 等框架，用户可直接在原生框架下使用 TI-ACC 的加速能力，无需进行额外的模型格式转换等适配工作。
- 推理加速整体能力通过一个函数提供，用户可通过该函数使用推理加速的所有能力。
- 训练加速中的通信加速能力由兼容原生的 DDP 工具提供，使用户无需修改原生的使用代码即可直接使用。数据 IO 优化、自适应 FP16均通过封装好的简单函数/类进行提供，仅需增加几行代码便可使用。


### 技术强大
- 推理加速底层提供计算优化、低精度加速、内存优化等能力。技术架构图如下所示：
![](https://qcloudimg.tencent-cloud.cn/raw/7762e29bb8ed421c3c28b0a1acc1cf0f.png)
- 训练加速底层提供数据 IO 优化、计算优化、通信加速、并行训练、显存优化等能力。技术架构图如下所示：
![](https://qcloudimg.tencent-cloud.cn/raw/9829b2d7e5fb5d6170dcbdd5d549727a.png)



## 开始使用
在推荐、CV、NLP 等模型训练和推理场景中，都可以使用 TI-ACC 的推理和训练加速能力。目前通过容器方式提供给用户使用，具体使用方式请参见 [推理加速部署及实践](https://cloud.tencent.com/document/product/560/64709) 及 [训练加速部署及实践](https://cloud.tencent.com/document/product/560/64710)。

