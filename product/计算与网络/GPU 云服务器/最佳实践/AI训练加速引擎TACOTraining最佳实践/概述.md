

AI 加速引擎 TACO-Training 是基于腾讯云 IaaS 资源推出的 AI 训练加速引擎，为用户提供开箱即用的 AI 训练套件，用于分场景支持高性能分布式训练。

TACO-Training 基于腾讯内部丰富的 AI 业务场景，提供自底向上的网络通信、分布式策略及训练框架等多层级的优化，是一套全生态的训练加速方案。为了更好的服务用户，腾讯云决定免费提供内部深度优化的 AI 训练加速方案，助力用户节约计算成本，提高 AI 产品研发效率。

## 使用 TACO 进行云上 AI 加速

随着云计算的普及，GPU 算力的增强，基于深度学习的 AI 技术已经渗透到各行业。应用场景更加复杂，特征也更加丰富，网络模型从MB增长到GB甚至TB级别，训练所花费的时间越来越长。如何利用有限的 GPU 算力更高效地解决 AI 业务场景中遇到的问题成为了共同关注的焦点。   

用户可以使用 TACO 方案加速深度学习，其架构如下图所示：
![](https://qcloudimg.tencent-cloud.cn/raw/4ffc37483b1eb067884d5cee4619fa2a.jpg)

<dx-alert infotype="explain" title="">
目前仅提供 TACO-Training 加速 AI 训练场景。关于支持推理场景 TACO-Inference 加速引擎的发布信息，请您定期关注 [GPU 云服务最佳实践文档](https://cloud.tencent.com/document/product/560/57679)。 
</dx-alert>

TACO-Training 提供以下三个训练加速组件：
- **Tencent Tensorflow 1.15**：基于 Tensorflow 1.15深度优化的训练框架。
- **LightCC**：基于 Horovod 深度优化的分布式训练框架。
- **HARP**：自研用户态网络协议栈。


## 应用场景

TACO-Training 加速组件支持但是不限于以下场景：
- 推荐系统。例如，Wide&Deep，DeepFM 等。
- 自然语言处理。例如，BERT，Transformer 等。
- 图像识别。例如，ResNet、MobileNet 及 Inception 系列等。


## 组件介绍

### TTF

TensorFlow 是深度学习领域中应用最广泛的开源框架之一，但是在很多业务场景下，开源 Tensorflow 有其特定的限制。为了解决实际业务中遇到的问题，TencentTensorflow（以下简称 TTF）提供了以下能力：
- 相比原始的静态 Embedding，高维稀疏动态 Embedding 帮助用户在不需要重新训练的条件下，动态添加和删除特征，按需使用内存，避免 Hash 冲突，同时保留原始 TF 的 API 设计风格。
- 混合精度在原有实现的基础上增加了调整精度的策略，根据 loss 的状态自动在全精度和半精度之间切换，避免精度损失。
- 针对特定业务场景的 XLA、Grappler 图优化及自适应编译框架，解决冗余重编译的问题。
- 开源 TF 1.x 版本不再提供对 Ampere GPU 的支持，但考虑到很多用户仍然在使用 TF 1.15版本，为了解决该问题，TTF 添加了对 CUDA 11+的支持，使用户可以使用 A100来进行模型训练。



### LightCC

LightCC 是基于 Horovod 深度优化的分布式训练框架，在保留了原生 Horovod 的易用性上，增加了性能更好的通信方式。LightCC API 与 Horovod 完全兼容，业务不需要任何改动，无缝迁移。相比 Horovod，LightCC 提供了以下能力：
- 2D AllReduce 充分利用通信带宽。
- 高效的梯度融合方式。
- TOPK 压缩通信，降低通信量，提高传输效率。


### HARP

随着网络硬件技术的发展，网卡的速度从10G增长到100G甚至更高，并在数据中心大量部署使用。但目前普遍使用的内核网络协议栈存在着一些必要的开销，使其不能很好地利用高速网络设备。为了解决内核网络协议栈存在的问题，腾讯云自研了用户态网络协议栈 HARP，可以以 Plug-in 的方式集成到 NCCL 中，无需任何业务改动，加速云上分布式训练性能。在 VPC 的环境下，相比传统的内核协议栈，HARP 提供了以下的能力：
- 支持全链路内存零拷贝，HARP 协议栈提供特定的 buffer 给应用，使应用的数据经过协议栈处理后由网卡直接进行收发，消除内核协议栈中耗时及占用 CPU 较高的多次内存拷贝操作。
- 支持协议栈多实例隔离，即应用可以在多个 CPU core 上创建特定协议栈实例处理网络报文，每个实例间相互隔离，保证性能线性增长。
- 数据平面无锁设计，HARP 协议栈内部保证网络 session 的数据仅在创建该 session 的 CPU core 上，使用特定的协议栈实例处理。减少了内核中同步锁的开销，也降低了 CPU 的 Cache Miss 率，大幅提升网络数据的处理性能。

## 性能提升

- TTF 动态 Embedding 在某推荐业务上对 AUC 的提升效果：
![](https://main.qcloudimg.com/raw/6c812787715e8fcec62ffd32204a42f5.png)            
- TTF XLA 在某游戏业务上的性能加速效果：
![](https://main.qcloudimg.com/raw/fa625ab276b9fc8f87419fbacd8f7507.png)
- 在腾讯云50G VPC 环境下，ResNet50的多机训练加速效果：
![](https://main.qcloudimg.com/raw/40f554fabea5ec282b6349a33a4719f4.png)
- 在腾讯云50G VPC 环境下，Transformer 的多机训练加速效果：
![](https://main.qcloudimg.com/raw/31e57bc8b8ae9c9a4cd2536458e8db7e.png)
- 在腾讯云50G VPC 环境下，BERT-Base 的多机训练加速效果：
![](https://main.qcloudimg.com/raw/754c416a6b7e8d796c380f35d1025fbc.png)

## 开始使用
目前 TACO-Training 将以容器方式提供给用户使用，具体使用方式可参考 [部署及实践](https://cloud.tencent.com/document/product/560/61565)。
