## 操作场景

在通过数据接入平台 DIP 处理数据流入流出任务时，通常需要对数据进行简易的清洗操作，如格式化原始数据、解析特定字段、数据格式转换等等。

DIP 提供简单的数据处理功能，通过传入数据和配置项，可以实现对数据格式化处理，然后返回处理完成的结构化数据，分发给离线/在线处理平台，构建数据源和数据处理系统间的桥梁。

## 操作步骤

1. 登录 [DIP 控制台](https://console.cloud.tencent.com/ckafka/datahub-overview)。
2. 在左侧导航栏单击**任务管理** > **任务列表**，选择好地域后，单击**新建任务**。
3. 填写任务信息后，单击**下一步**。
   - 任务名称：只能包含字母、数字、下划线、“-”、“.”。
   - 任务类型：选择**数据处理**。
   - 源 Topic：源数据 CKafka Topic。
   - 目标 Topic：目标数据 CKafka Topic。
   - 起始位置：选择转储时历史消息的处理方式，topic offset 设置。
![](https://qcloudimg.tencent-cloud.cn/raw/1118565e000fd08c1dcdb592792c2e50.png)
4. 设置数据处理规则。
![](https://qcloudimg.tencent-cloud.cn/raw/62962e2a65dc8a8bf2c8a9380611576f.png)
   - 原始数据：支持**从源 Topic 拉取**或者**自定义**。
   - 解析格式：支持 **JSON**，**分隔符**和**正则提取**三种解析方式。
     - JSON
     - 分隔符：支持 `空格`、`制表符`、`,`、`;`、`|`、`自定义`。
     - 正则提取：需填写正则表达式。
5. 选择好解析模式后，单击**确认**按钮，开始解析数据，等待解析完成。解析完成后点击解析后的数据可以在右侧生成结构化预览。
![](https://qcloudimg.tencent-cloud.cn/raw/bfec03e8f1d8f2a24f86533edd363539.png)
6. （可选）开启 key-value 二次解析后，将对 value 里的数据进行 key-value 解析。
   ![](https://qcloudimg.tencent-cloud.cn/raw/2df7eaca1a54ab9940cd4429d17c86b9.png)
7. 设置数据处理规则，操作支持有**系统预设-当前时间、映射、自定义和 JSONPATH** 四种。
    - 操作 = 系统预设：可以选择系统预设的 VALUE ，目前支持 DATE（时间戳）。
    - 操作 = 映射：可以选择已有的 KEY，最终输出的 VALUE 值由指定的 KEY 映射而来。
    - 操作 = 自定义：可以输入自定义 VALUE。
    - 操作 = JSONPATH：解析多层嵌套的 JSON 数据，用`$`符号开头，`. `符号定位到多层 JSON 的具体字段。
8. 单击 VALUE 栏旁边的**处理value**可以对 value 值进行处理，支持**替换**、**截取**、**转换时间格式**和**去除前后空格**四种处理方式。
9. 单击测试，查看数据处理的测试结果。
   ![](https://qcloudimg.tencent-cloud.cn/raw/2d60915e84c5619532d0ce717328eab3.png)
10. （可选）开启过滤器，仅输出符合过滤器规则的数据。过滤器的匹配模式支持**前缀匹配**、**后缀匹配**、**包含匹配（contains）**、**除外匹配（except）**、**数值匹配**和**IP匹配**。详情参见 [过滤器规则说明](https://cloud.tencent.com/document/product/597/66021)。
![](https://qcloudimg.tencent-cloud.cn/raw/cd56bc8ef361d45ea8f9db75b70bfbf7.png)
11. 设置投递失败的消息处理规则，支持**丢弃**、**保留**和投递到**死信队列**（需指定死信队列 Topic）。
![](https://qcloudimg.tencent-cloud.cn/raw/eda377d1baebd3b741c01d53fd6dc0e5.png)
12. 单击**提交**，可以在任务列表看到刚刚创建的任务，在状态栏可以查看任务创建进度。
