本文列举了数据接入平台（Data Integration Platform）中对一些指标和性能的限制，请您在使用中注意不要超出对应的限制值，避免出现异常。

| 限制项       | 说明                                                         |
| ------------ | ------------------------------------------------------------ |
| 任务并行度   | 数据接入、处理、转储底层都是多个子任务（worker）并发运行的。默认情况下，worker 并行度为1。系统会自动检查上有数据是否有堆积，当有堆积时会自动扩容运行 worker 数，以提高任务处理能力。当前阶段，worker 数的上限 = kafka Topic 的分区数。worker 数用户不可配置，系统会自动扩缩容 worker。 |
| 任务吞吐性能 | DIP 是以任务形态进行，其任务性能依赖上下游组件的服务能力。如上游是 Kafka > DIP > Elasticsearch 链路。当上下游无性能瓶颈时，DIP 会通过调整任务并行度来提高数据处理能力，当上下游有性能瓶颈时，则数据的流转耗时会相应增加。客户可以通过查看监控指标和配置堆积告警等手段来发现瓶颈。 |
| 任务数量     | 默认情况下，每个客户的任务数量上限是200。如果需要更多的数量，可以 [提工单](https://console.cloud.tencent.com/workorder/category) 申请。 |
| 连接数量     | 默认情况下，每个客户的连接数量上限是100。如果需要更多的数量，可以 [提工单](https://console.cloud.tencent.com/workorder/category) 申请。 |
| 主题数量     | 默认情况下，每个客户的主题 数量上限是200。如果需要更多的数量，可以 [提工单](https://console.cloud.tencent.com/workorder/category) 申请。 |
| Schema 数量   | 默认情况下，每个客户的主题 数量上限是100。每个 Schema 最多允许100个字段。如果需要更多的数量，可以 [提工单](https://console.cloud.tencent.com/workorder/category) 申请。 |
|HTTP 接入 QPS 限制|  默认情况下，每个 HTTP 接入点的 QPS 的限制为2000。如果需要更多的数量，可以 [提工单](https://console.cloud.tencent.com/workorder/category) 申请。|
|数据上报每批次数据总大小 | HTTP 数据上报的每批次上报的数据大小最大为5MB，超过该数据大小就会报错。 |
| 数据上报每批次数据条数   | HTTP 数据上报的每批次上报的数据条数最大为500条，超过该数据大小就会报错。 |
