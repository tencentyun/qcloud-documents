为了节约用户的开发成本和提升使用效率，TSF 提供了 Spring Cloud 全链路跟踪的组件。用户只需要在代码中配置组件依赖，即可直接使用 TSF 的全链路跟踪功能，无需关心日志采集、分析、存储等过程。 用户仅需要安装了对应的依赖包及添加依赖项即可，无须其他配置。

## 准备工作
开始实践调用链功能前，请确保已完成 [SDK 下载](https://cloud.tencent.com/document/product/649/20231)。

## 一、依赖项

向工程中添加 `spring-cloud-tsf-starter` 依赖并开启 `@EnableTsf` 注解，详情请参考 [快速入门](https://cloud.tencent.com/document/product/649/20261) 文档。

>!如果您使用的是 1.15.0-Edgware-RELEASE/1.15.0-Finchley-RELEASE 及之前的版本，使用方法参考 [Spring Cloud SDK 历史版本使用方法](https://cloud.tencent.com/document/product/649/45864)。

## 二、微服务对下游组件访问的链路支持
微服务对 Redis、MySQL、MongoDB、消息队列 CMQ 的访问操作会产生跟踪日志， TSF 会对该日志进行采集、分析、统计，这些组件的调用会展现在 TSF 平台的链路追踪中。
>?非微服务组件的链路支持功能依赖于1.14.0版本及以上版本的 SDK，详情请参考 [SDK 更新日志](https://cloud.tencent.com/document/product/649/38983)。

### 1. Redis 链路使用说明
考虑到 Redis 库的多样性，以及 spring-data-redis 库的易用性，目前只对`spring-boot-starter-data-redis`进行支持，在引用 spring-boot-starter-data-redis 时不要指定版本，只需要整个工程依赖 parent pom 即可：
```pom
<parent>
    <groupId>com.tencent.tsf</groupId>
    <artifactId>spring-cloud-tsf-dependencies</artifactId>
    <version>tsf 的版本号（1.14以后开始支持 Redis）</version>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-redis</artifactId>
     </dependency>
</parent>
```

`spring-boot-starter-data-redis`的版本为 parent pom 文件管理的 Redis Starter 的版本。在代码中具体使用时，引入 RedisTemplate，然后使用其方法即可。不建议直接引用 Jedis 和 Lettuce 相关的依赖，spring-boot-starter-data-redis 会自动引用相关的依赖，并做适配。
如果通过其他方式引入 Redis 客户端（例如直接 new Jedis），则将无法在 TSF 的链路中查看到相应的信息。


#### 16.1-Finchley-RELEASE 版本 Redis 调用链使用方式

- 使用 lettuce 方式，pom 依赖如下：
```pom.xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis</artifactId>
</dependency>
```
不需要额外依赖，他自动依赖了lettuce方面的jar包，可以直接使用。也具有链路追踪的能力。

- 使用 jedis 方式，pom 依赖如下：
```pom.xml
<dependency>
    <groupId>org.springframework.data</groupId>
    <artifactId>spring-data-redis</artifactId>
</dependency>
<!-- redis -->
<dependency>
    <groupId>redis.clients</groupId>
    <artifactId>jedis</artifactId>
</dependency>
```

这样也能使用 SDK 的链路追踪能力。

### 2. MySQL 链路使用说明
支持实现 JDBC 规范的 MySQL 驱动器和各类连接池（如 Tomcat-JDBC、DBCP、Hikari、Druid），在使用时需引入 SpringBoot 相关依赖和 MySQL 驱动依赖：
```
<!-- spring-boot-starter-jdbc -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-jdbc</artifactId>
    <version>RELEASE</version>
</dependency>
<!-- mysql -->
<dependency>
    <groupId>mysql</groupId>
    <artifactId>mysql-connector-java</artifactId>
    <version>RELEASE</version>
</dependency>
```
引入依赖后，根据需要添加相关数据库连接池依赖或直接使用 SpringBoot 默认选项。

### 3. MongoDB 链路使用说明
考虑到 spring-data-mongodb 库的易用性，目前只对`spring-boot-starter-data-mongodb`进行支持，在引用 spring-boot-starter-data-mongodb 时不要指定版本，只需要整个工程依赖 parent pom 即可，示例如下：
```pom
  <parent>
      <groupId>com.tencent.tsf</groupId>
      <artifactId>spring-cloud-tsf-dependencies</artifactId>
      <version>tsf的版本号（1.14以后开始支持 MongoDB）</version>
      <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-data-mongodb</artifactId>
       </dependency>
  </parent>
```

`spring-boot-starter-data-mongodb`的版本即是 parent pom 文件管理的 mongoldb starter 的版本。在代码中具体使用时，引入MongoTemplate，然后使用其方法即可。
- 如果需要制定 MongoDB 连接的 URI，需要满足以下格式：
```shell
mongodb://host[:port1][/[database][?options]] #暂时只支持单节点 MongonDB
```
也可以不用填写，即默认 host 是本机，默认端口27017。
- 如果通过其他方式引入 MongoDB 客户端，例如直接`new MongoClient(host,port)`，则在 TSF 的链路中将无法查看到相应的信息。

### 4. 消息队列 CMQ 链路使用说明
CMQ 组件目前通过 Spring Cloud Stream Binder 方式接入Spring Cloud 体系，对于 CMQ 组件的全链路追踪目前基于`spring-cloud-stream-binder-cmq`扩展实现，使用时需在上下游服务中添加`spring-cloud-stream-binder-cmq`依赖并按照规范进行 CMQ 配置。
```
<!-- 使用CMQ -->
<dependency>
    <groupId>com.qcloud</groupId>
    <artifactId>spring-cloud-stream-binder-cmq</artifactId>
    <version>VERSION</version>
</dependency>
```
配置参考：
```
spring:
  application:
    name: cmq-demo
  cloud:
    stream:
      bindings:
        input:
          destination: test-topic
        output:
          destination: test-topic
      cmq:
        bindings:
          input:
            consumer:
              pollingWaitSeconds: 3
        binder:
          secretId: ***
          secretKey: ***
          endpoint: https://cmq-queue-***.api.qcloud.com
```

### 5. Kafka 链路追踪使用说明

Kafka 的链路追踪能力通过 Spring Boot 的自动配置方式实现。

#### 1.16.0-Edgware 版本说明

实现方式是向 bean 容器中各加入了一个 producerFactory 和 consumerFactory 类的 bean。他们各自分别重写了 createKafkaProducer 方法和 createKafkaConsumer 方法。使用该 producerFactory/consumerFactory 便具有了链路追踪的能力。建议使用 Spring 默认的 KafkaTemplate，无须自定义。

 **1.16.0-Edgware** 版使用的 spring-kafka 版本必须在**1.3.0**以上，因为从这个版本开始 kafka-client 中增加了请求头，这才能方便的实现链路追踪。

```xml
<!--支持kafka使用调用链-->
        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
            <version>1.3.0.RELEASE</version>
        </dependency>
```

参考配置：

```properties
#============== kafka ===================
# 指定 kafka 代理地址，可以多个
spring.kafka.bootstrap-servers=
  
#=============== provider  =======================
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432
  
# 指定消息 key 和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
  
#=============== consumer  =======================
# 指定默认消费者 Group ID
spring.kafka.consumer.group-id=test-consumer-group
  
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100
  
# 指定消息 key 和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
```

其他更详细配置、使用方法详见 Demo 示例。

#### 1.16.0-Finchley 版本说明
实现方式是向 Spring 容器中各增加了一个对切面，分别作用于 ProducerFactory.createProducer 方法和 ConsumerFactory.createConsumer 方法的，使得通过他们返回的 KafkaProducer 和 KafkaConsumer 具有链路追踪的能力。

使用 1.16.0-Finchley 版本**无须**考虑 spring-kafka 版本问题，无须指定它的版本，因为底层依赖的 Finchley 版本的 spring cloud 会自动为它配置高于 1.3.0.RELEASE 版本的spring-kafka。

```xml
        <!--支持kafka使用调用链-->
        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
        </dependency>
```

参考配置：

```yml
  server:
    servlet:
      context-path: /
    port: xxxxx
  spring:
    application:
      name: xxxxxx
    kafka:
      bootstrap-servers: xxxxxx
      #生产者的配置，大部分我们可以使用默认的，这里列出几个比较重要的属性
      producer:
        #每批次发送消息的数量
        batch-size: 16
        #设置大于0的值将使客户端重新发送任何数据，一旦这些数据发送失败。注意，这些重试与客户端接收到发送错误时的重试没有什么不同。允许重试将潜在的改变数据的顺序，如果这两个消息记录都是发送到同一个partition，则第一个消息失败第二个发送成功，则第二条消息会比第一条消息出现要早。
        retries: 0
        #producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常，以“block.on.buffer.full”来表明。这项设置将和producer能够使用的总内存相关，但并不是一个硬性的限制，因为不是producer使用的所有内存都是用于缓存。一些额外的内存会用于压缩（如果引入压缩机制），同样还有一些用于维护请求。
        buffer-memory: 33554432
        #key序列化方式
        key-serializer: org.apache.kafka.common.serialization.StringSerializer
        value-serializer: org.apache.kafka.common.serialization.StringSerializer
      #消费者的配置
      consumer:
        #Kafka中没有初始偏移或如果当前偏移在服务器上不再存在时,默认区最新 ，有三个选项 【latest, earliest, none】
        auto-offset-reset: latest
        #是否开启自动提交
        enable-auto-commit: true
        #自动提交的时间间隔
        auto-commit-interval: 100
        #key的解码方式
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        #value的解码方式
        value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        #在/usr/local/etc/kafka/consumer.properties中有配置
        group-id: test-consumer-group
  tsf:
    swagger:
      enabled: false
  logging:
    file: /tsf-demo-logs/${spring.application.name}/root.log
```

其他更详细配置、使用方法详见 Demo 示例。

###6、RocketMq链路追踪使用说明

从1.23.0版本开始支持rocketMq使用联路追踪能力。

####链路追踪原理

利用springboot提供自动配置原理，加入一个能插手bean DefaultMQProducer、和bean DefaultMQPushConsumer创建过程的自动配置类。使用代理来增强DefaultMQProducer/DefaultMQPushConsumer，在调用相应方法是加入tracing的逻辑，在方法结束时将tracing数据搜集起来，统一存储。最后分析展示给前端页面。

#### 引入依赖及配置

```xml
				<!-- TSF 启动器 -->
        <dependency>
            <groupId>com.tencent.tsf</groupId>
            <artifactId>spring-cloud-tsf-starter</artifactId>
        </dependency>

        <!--RocketMQ-->
        <dependency>
            <groupId>org.apache.rocketmq</groupId>
            <artifactId>rocketmq-client</artifactId>
            <version>4.4.0</version>
        </dependency>
```

```yml
apache:
  rocketmq:
    consumer:
      pushConsumer: myConsumer
    producer:
      producerGroup: myProducer
    name-server: xxx.xxx.xx.xx #rocketMq ip
    topic: long-topic
```

#### 生产者示例

- 向spring容器中加入bean DefaultMQProducer

```java
@Configuration
public class ProducerConfiguration {
    private static final Logger logger = LoggerFactory.getLogger(ProducerConfiguration.class);

    @Value("${apache.rocketmq.name-server}")
    private String namesrvAddr;

    @Value("${apache.rocketmq.producer.producerGroup}")
    private String producerGroup;

    @Bean
    public DefaultMQProducer defaultMQProducer() throws MQClientException {
        DefaultMQProducer producer = new DefaultMQProducer(producerGroup);

        producer.setNamesrvAddr(namesrvAddr);

        producer.setVipChannelEnabled(false);
        producer.setRetryTimesWhenSendAsyncFailed(0);
        producer.start();
        logger.info("rocketmq producer is starting");
        return producer;
    }
}
```

- 引用DefaultMQProducer，发送消息

```java
@Service
public class RocketmqService {
    private static  final Logger logger = LoggerFactory.getLogger(RocketmqService.class);

    @Autowired
    private DefaultMQProducer defaultMQProducer;

    // 使用application.properties里定义的topic属性
    @Value("${apache.rocketmq.topic}")
    private String springTopic;

    private AtomicLong id =new AtomicLong(0);

    @Scheduled(fixedDelayString = "${consumer.auto.test.interval:5000}")
    public String prepareSend() throws InterruptedException, RemotingException, MQClientException, MQBrokerException {
       return send();
    }

    public String send() throws InterruptedException, RemotingException, MQClientException, MQBrokerException {
        String sentText = "rocketmq message: msg id="+id.addAndGet(1);

        Message message = new Message(springTopic,"push", sentText.getBytes());
        message.putUserProperty("traceID","1234567");

        SendResult sendResult = defaultMQProducer.send(message);
      
        logger.info("消息id:"+id.get()+","+"发送状态:"+sendResult.getSendStatus());

        return sendResult.getMsgId();
    }
}
```

#### 消费者

```java
@Configuration
public class ConsumerConfiguration {
    private static final Logger logger = LoggerFactory.getLogger(ConsumerConfiguration.class);


    @Value("${apache.rocketmq.name-server}")
    private String namesrvAddr;

    @Value("${apache.rocketmq.topic}")
    private String springTopic;

    @Value("${apache.rocketmq.consumer.pushConsumer}")
    private String consumerGroup;

    @Bean
    public DefaultMQPushConsumer pushConsumer() {
        DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroup);

        consumer.setNamesrvAddr(namesrvAddr);
        try {

            // 订阅PushTopic下Tag为push的消息,都订阅消息
            consumer.subscribe(springTopic, "push");

            // 程序第一次启动从消息队列头获取数据
            consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);
            //可以修改每次消费消息的数量，默认设置是每次消费一条
            consumer.setConsumeMessageBatchMaxSize(1);

            //在此监听中消费信息，并返回消费的状态信息
            consumer.registerMessageListener((MessageListenerConcurrently) (msgs, context) -> {

                // 会把不同的消息分别放置到不同的队列中
                for (Message msg : msgs) {
                    System.out.println("接收到了消息：" + new String(msg.getBody()));
                    logger.info("接收到了消息：" + new String(msg.getBody()));
                    try {
                        Thread.sleep(50);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
            });

            consumer.start();

        } catch (Exception e) {
            e.printStackTrace();
        }
        return consumer;
    }
}
```



## 标签与自定义元数据

调用链支持用户在代码中设置标签（Tag） 和自定义元数据（CustomMetada），分别用于调用链的筛选和附带业务信息。

**接口定义：**
```
public class TsfContext {
    /**
     * 设置多个 Tag。如果有某个 Tag 之前已经被设置过，那么它的值会被覆盖。
     */
    public static void putTags(Map<String, String> tagMap, TagControlFlag... flags) {}

    /**
     * 设置 Tag。如果该 key 之前已经被设置过，那么它的值会被覆盖。
     */
    public static void putTag(String key, String value, TagControlFlag... flags) {}
    
    /**
     * 设置 CustomMetadata。
     */
    public static void putCustomMetadata(Object customMetadata)
}
```

## 注入和获取 trace 信息

TSF SDK1.23 及之后版本，支持注入和获取 traceId、spanId、tag 信息。
>?
- traceId、spanId 格式不建议自定义，可能有未知错误。
- TSF 不保证注入后调用链的正确性。



#### E 版本 SDK 使用方式

```java
 private static final Logger LOG = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass()); 
 @Autowired
 private Tracer tracer;
 
 public void addSpan() throw Exception{
 	//获取 traceId、spanId、tag
        Span oldSpan = tracer.getCurrentSpan();
        String traceId = oldSpan.getTraceId();
        String spanId = oldSpan.getSpanId();
        Map<String, String> tags = oldSpan.tags();
        LOG.info("traceId: {}, spanId: {}", traceId, spanId);
        for (String key : tags.keySet()) {
            LOG.info("key: {}, value: {}", key, tags.get(key));
        }

        //设置 tag
        tracer.addTag("http.method","get");
        Map<String, String> tags1 = tracer.getCurrentSpan().tags();
        for (String key : tags1.keySet()) {
            LOG.info("key: {}, value: {}", key, tags1.get(key));
        }

        //设置 traceId、spanId（必须先新建 span）
        Span.SpanBuilder spanBuilder = Span.builder();
        Span span = spanBuilder.name("mockName").traceId(UUID.randomUUID().toString()).spanId(UUID.randomUUID().toString()).tag("key", "value").build();

        tracer.continueSpan(span);

        Span newSpan = tracer.getCurrentSpan();
        String newTraceId = newSpan.getTraceId();
        String newSpanId = newSpan.getSpanId();
        
        LOG.info("traceId: {}, spanId: {}", newTraceId, newSpanId);
 }
  
```



#### F、G 版本 SDK 使用方式

```java
    private static final Logger LOG = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
    @Autowired
    private Tracing tracing; 
		
   public void addSpan() throw Exception{
      TraceContext traceContext = tracing.tracer().currentSpan().context();

        TraceContext context = traceContext.toBuilder().traceId(2035873338086630653L).spanId(-2035873338086630653L).build();

        CurrentTraceContext currentTraceContext = tracing.currentTraceContext();
        currentTraceContext.newScope(context);

        Span spanCur = tracing.tracer().currentSpan();


        long traceId1 = spanCur.context().traceId();
        long spanId1 = spanCur.context().spanId();
        LOG.info("traceId1:{},spanId1:{}",traceId1, spanId1);


        //添加tag
        spanCur.tag("qx-test1","value");
        spanCur.tag("qx-test2","value");
        spanCur.tag("qx-test1","value");

        //获取tag
        Field state1 = spanCur.getClass().getDeclaredField("state");
        state1.setAccessible(true);
        MutableSpan mutableSpan1 = (MutableSpan)state1.get(spanCur);
        Field tags1 = mutableSpan1.getClass().getDeclaredField("tags");
        tags1.setAccessible(true);
        ArrayList<String> list1 = (ArrayList<String>) tags1.get(mutableSpan1);
        String key1 =null, value1 =null;
        for (int i = 0, length = list1.size(); i < length; i += 2) {
            key1 =  list1.get(i);
            value1 = list1.get(i + 1);

            LOG.info("tags key1: {}, value1: {}", key1, value1);
        }

        //获取 traceid、spanid
        TraceContext traceContext1 = spanCur.context();
        long traceId2 = traceContext1.traceId();
        long spanId2 = traceContext1.spanId();
        LOG.info("traceId1:{},spanId1:{}",traceId2, spanId2);
    }
```

###线程池中反复使用线程局部变量

某些场景，会将某个变量塞入线程局部两边ThreadLocal，但是在新建的线程池中继承不了母县城的现场局部变量。如果使用InheritableThreadLocal虽然能继承，但是如果子线程在线程池中运行，反复使用，那么塞入的子线程局部变量的值将被一直持有，会影响该线程的后续使用，如果能在子线程被线程池回收时自动清理，只保留母线程的局部变量呢？**TransmittableThreadLocal**即是解决该问题的。

F、G版本sdk使用方法相同，该特性从1.24版本开始支持。

使用实例：

```java
public class TtlExecutorsTest {


    private Runnable createRunnable(TransmittableThreadLocal<String> context){
        return  ()-> {
            System.out.println("子线程开始");

            String child = context.get();
            System.out.println(child);
            context.set("child runnable");
            System.out.println(context.get());

            System.out.println("子线程结束");
        };
    }

    private Callable createCallable(TransmittableThreadLocal<String> context){
        return ()->{
            System.out.println("子线程开始");

            String child = context.get();
            System.out.println(child);
            context.set("child callable");
            System.out.println(context.get());

            System.out.println("子线程结束");

            return "success";
        };
    }

    /**
     * 简单使用 runnable
     * @throws Exception
     */
    @Test
    public void Test1()throws Exception{

        TransmittableThreadLocal<String> context = new TransmittableThreadLocal<String>();
        context.set("value-set-in-parent");

        Runnable task = createRunnable(context);

        Executor executor = Executors.newSingleThreadExecutor();
        TtlRunnable ttlRunnable = TtlRunnable.get(task);

        executor.execute(ttlRunnable);
        executor.execute(ttlRunnable);

        // =====================================================
        TimeUnit.SECONDS.sleep(1);
        System.out.println("=========parent thread========");
        String value = context.get();
        System.out.println(value);
    }

    @Test
    public void Test2()throws Exception{

        TransmittableThreadLocal<String> context = new TransmittableThreadLocal<String>();
        context.set("value-set-in-parent");

        Callable callable = createCallable(context);

        ExecutorService executorService = Executors.newSingleThreadExecutor();
        TtlCallable ttlCallable = TtlCallable.get(callable);

        executorService.submit(ttlCallable);
        executorService.submit(ttlCallable);

        // =====================================================
        TimeUnit.SECONDS.sleep(1);
        System.out.println("=========parent thread========");
        String value = context.get();
        System.out.println(value);
    }

    /**
     * 线程池 Executor
     * @throws Exception
     */
    @Test
    public void Test3() throws Exception{
        TransmittableThreadLocal<String> context = new TransmittableThreadLocal<String>();
        context.set("value-set-in-parent");

        Runnable task = createRunnable(context);

        Executor executor = Executors.newSingleThreadExecutor();
        Executor ttlExecutors = TtlExecutors.getTtlExecutors(executor);
        ttlExecutors.execute(task);
        ttlExecutors.execute(task);


        // =====================================================
        TimeUnit.SECONDS.sleep(1);
        System.out.println("=========parent thread========");
        String value = context.get();
        System.out.println(value);
    }


    /**
     * 线程池 ExecutorService
     * @throws Exception
     */
    @Test
    public void Test4() throws Exception{
        TransmittableThreadLocal<String> context = new TransmittableThreadLocal<String>();
        context.set("value-set-in-parent");

        Runnable runnableTask = createRunnable(context);

        ExecutorService executorService = Executors.newFixedThreadPool(1);
        ExecutorService ttlExecutorService = TtlExecutors.getTtlExecutorService(executorService);
        ttlExecutorService.submit(runnableTask);
        ttlExecutorService.submit(runnableTask);

        Callable callableTask = createCallable(context);
        ttlExecutorService.submit(callableTask);
        ttlExecutorService.submit(callableTask);

        // =====================================================
        TimeUnit.SECONDS.sleep(1);
        System.out.println("=========parent thread========");
        String value = context.get();
        System.out.println(value);
    }

    /**
     * 线程池 ScheduledExecutorService
     * @throws Exception
     */
    @Test
    @SuppressWarnings("uncheck")
    public void Test5() throws Exception{
        TransmittableThreadLocal<String> context = new TransmittableThreadLocal<String>();
        context.set("value-set-in-parent");

        Runnable runnableTask = createRunnable(context);

        ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(1);
        ScheduledExecutorService ttlScheduledExecutorService = TtlExecutors.getTtlScheduledExecutorService(scheduledExecutorService);
        ttlScheduledExecutorService.submit(runnableTask);
        ttlScheduledExecutorService.submit(runnableTask);

        Callable callableTask = createCallable(context);
        ttlScheduledExecutorService.submit(callableTask);
        ttlScheduledExecutorService.submit(callableTask);

        // =====================================================
        TimeUnit.SECONDS.sleep(1);
        System.out.println("=========parent thread========");
        String value = context.get();
        System.out.println(value);
    }
}

```



