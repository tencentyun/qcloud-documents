## 定制推流画面

### 方案一：修改 OpenGL 纹理
研发实力不俗的客户，会有自定义图像处理的需求（例如堆加字幕），同时又希望复用 RTMP SDK 的整体流程，如果是这样，您可以按照如下攻略进行定制。

- **设置视频处理回调**
设置 **TXLivePush** 的 **videoProcessDelegate** 代理点，即可实现对视频画面的定制。

```objectivec
@protocol TXVideoCustomProcessDelegate <NSObject>

/**
 * 在OpenGL线程中回调，在这里可以进行采集图像的二次处理
 * @param textureId  纹理 ID
 * @param width      纹理的宽度
 * @param height     纹理的高度
 * @return           返回给 SDK 的纹理
 * 说明：SDK回调出来的纹理类型是 GL_TEXTURE_2D，接口返回给SDK的纹理类型也必须是 GL_TEXTURE_2D
 */
-(GLuint)onPreProcessTexture:(GLuint)texture width:(CGFloat)width height:(CGFloat)height;
 
/**
 * 在OpenGL线程中回调，可以在这里释放创建的OpenGL资源
 */
-(void)onTextureDestoryed;

@end
```

- **在回调函数中对视频数据进行加工**
实现 TXVideoCustomProcessDelegate 的 onPreProcessTexture 函数，以实现对视频画面的自定义处理。textureId 指定的纹理是一块类型为 GLES20.GL_TEXTURE_2D 的纹理。

 对于 texture 数据的操作，需要一定的 OpenGL 基础知识，另外计算量不宜太大，因为 onPreProcessTexture 的调用频率跟 FPS 相同，过于繁重的处理很容易造成 GPU 过热。

### 方案二：自己采集数据
如果您只希望使用 SDK 来编码和推流（例如已经对接了商汤等产品），音视频采集和预处理（即美颜、滤镜这些）全部由自己的代码来控制，可以按如下步骤实现：

- **Step1. 不再调用 TXLivePush 的 startPreview 接口**
这样 SDK 本身就不会再采集视频数据和音频数据，而只是启动预处理、编码、流控、发送等跟推流相关的工作。

- **Step2. 通过 TXLivePushConfig 设置 customModeType**

```objectiveC
     #define CUSTOM_MODE_AUDIO_CAPTURE          0X001   //客户自己采集声音
     #define CUSTOM_MODE_VIDEO_CAPTURE          0X002   //客户自己采集视频
		 
	//如果声音和视频都要自己采集，可以设置 customModeType 为 3
	 @interface TXLivePushConfig : NSObject
	        @property(nonatomic, assign) int customModeType;
	 @end
```

- **Step3. 使用 sendVideoSampleBuffer 向 SDK 填充 Video 数据**
sendVideoSampleBuffer 的作用是向 SDK 塞入您采集和处理后的视频数据，目前支持 RGBA 和 NV12 两种格式。

```objectiveC
    TXLivePushConfig* config = [[TXLivePushConfig alloc] init];
    config.customModeType    = CUSTOM_MODE_VIDEO_CAPTURE;  // 自定义采集数据
    TXLivePush pusher = [[TXLivePush alloc] initWithConfig:config];
    
	//可以塞入自己采集和处理的 RGBA 或者 NV12 数据
    [pusher sendVideoSampleBuffer:sampleBuffer];
```

- **Step4. 使用 sendAudioSampleBuffer 向 SDK 填充 Audio 数据**
[sendAudioSampleBuffer](https://cloud.tencent.com/document/product/454/34755#sendaudiosamplebuffer) 的作用是向 SDK 塞入您采集和处理后的音频数据，请使用单声道、16位宽、48000Hz 的 PCM 声音数据。

 该函数支持两种 RPSampleBufferType， RPSampleBufferTypeAudioApp 和 RPSampleBufferTypeAudioMic，前者用于 replaykit，后者用于常规的麦克风采集（也用于 replaykit）。

```objectiveC
    TXLivePushConfig* config = [[TXLivePushConfig alloc] init];
    config.customModeType    = CUSTOM_MODE_AUDIO_CAPTURE;  // 自定义采集数据
    TXLivePush pusher = [[TXLivePush alloc] initWithConfig:config];
    
	//可以塞入自己采集和处理的 声音数据
    [s_txLivePublisher sendAudioSampleBuffer:sampleBuffer withType:RPSampleBufferTypeAudioMic];
```


## 定制播放数据

- **设置 TXLivePlayConfig 的 TXVideoCustomProcessDelegate 属性**

 ```objectiveC
  @interface TXLivePlayer : NSObject
  // 设置之后，Player 的每帧画面都会经过 onPlayerPixelBuffer 
  @property(nonatomic, weak) id <TXVideoCustomProcessDelegate> videoProcessDelegate;
```

- **通过 onPlayerPixelBuffer 回调捕获 Player 的图像数据。**

 如果当前 Player 是硬解码模式，pixelBuffer 的图像格式是 **NV12**，如果当前 Player 是软解码模式，pixelBuffer 的图像格式是 **i420** 。

 onPlayerPixelBuffer 返回值为 YES 时， SDK 不会继续做图像渲染，这种方式可以解决 OpenGL 线程冲突的问题。

 ```objectiveC
 @protocol TXVideoCustomProcessDelegate <NSObject>
 @optional

 /**
 * 视频渲染对象回调
 * @prarm pixelBuffer   渲染图像
 * @return              返回YES则SDK不再显示；返回NO则SDK渲染模块继续渲染
 *  说明：渲染图像的数据类型为config中设置的renderPixelFormatType
 */
-(BOOL)onPlayerPixelBuffer:(CVPixelBufferRef)pixelBuffer;
 @end
 ```
