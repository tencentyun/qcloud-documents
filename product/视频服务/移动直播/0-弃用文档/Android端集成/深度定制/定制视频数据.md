## 定制推流画面

### 方案一：修改OpenGL纹理
研发实力不俗的客户，会有自定义图像处理的需求（比如堆加字幕），同时又希望复用rtmp sdk的整体流程，如果是这样，您可以按照如下攻略进行定制。

- **设置视频处理回调**
通过 **TXLivePusher** 的 **setVideoProcessListener** 接口设置自定义视频处理回调

```java
public interface VideoCustomProcessListener {

    /**
    * 增值版回调人脸坐标
    * @param points   归一化人脸坐标，每两个值表示某点P的X,Y值。值域[0.f, 1.f]
    */
    void onDetectFacePoints(float[] points);

    /**
    * 在OpenGL线程中回调，在这里可以进行采集图像的二次处理
    * @param textureId  纹理ID
    * @param width      纹理的宽度
    * @param height     纹理的高度
    * @return           返回给SDK的纹理
    * 说明：SDK回调出来的纹理类型是GLES20.GL_TEXTURE_2D，接口返回给SDK的纹理类型也必须是GLES20.GL_TEXTURE_2D
    */
    int onTextureCustomProcess(int textureId, int width, int height);

    /**
    * 在OpenGL线程中回调，可以在这里释放创建的OpenGL资源
    */
    void onTextureDestoryed();
}
```

- **在回调函数中对视频数据进行加工**
实现 VideoCustomProcessListener 的 onTextureCustomProcess() 函数，以实现对视频画面的自定义处理。textureId 指定的纹理是一块类型为 GLES20.GL_TEXTURE_2D 的纹理。

> 对于 texture 数据的操作，需要一定的 OpenGL 基础知识，另外计算量不宜太大，因为 onTextureCustomProcess 的调用频率跟 FPS 相同，过于繁重的处理很容易造成 GPU 过热。

### 方案二：自己采集数据
如果您只希望使用 SDK 来编码和推流（比如已经对接了商汤等产品），音视频采集和预处理（即美颜、滤镜这些）全部由自己的代码来控制，可以按如下步骤实现：

- **Step1. 不再调用 TXLivePusher 的 startCameraPreview 接口**
这样 SDK 本身就不会再采集视频数据和音频数据，而只是启动预处理、编码、流控、发送 等跟推流相关的工作

- **Step2. 使用 sendCustomVideoData 向SDK填充Video数据**
sendCustomVideoData 的作用是向 SDK 塞入您采集和处理后的视频数据，目前支持 i420 格式。

- **Step3. 使用 sendCustomPCMData 向SDK填充Audio数据**
sendAudioSampleBuffer 的作用是向 SDK 塞入您采集和处理后的音频数据，请使用单声道、16位宽、48000Hz 的 PCM  声音数据。


## 定制播放数据

### 方案一：修改OpenGL纹理（仅适用硬解码播放）

- **step 1: 添加一个 TextureView**
为了能够展示播放器的视频画面，您需要在布局xml文件中使用 `TextureView` 替代 `TXCloudVideoView`
```xml
    <TextureView
            android:id="@+id/video_view"
            android:layout_width="match_parent"
            android:layout_height="match_parent"/>
```

- **step 2: 在代码中获取 TextureView 对象**
```
mTextureView = (TextureView) findViewById(R.id.video_view);
```

- **step 3: 通过 setSurface 接口绑定**
通过 TXLivePlayer 的 setSurface(mSurface) 接口将视频数据渲染的 mTextureView 绑定到 TXLivePlayer
```Java
mTextureView.setSurfaceTextureListener(new TextureView.SurfaceTextureListener() {

        @Override
        public void onSurfaceTextureAvailable(SurfaceTexture texture, int width, int height) {
            //创建 Surface
            mSurface = new Surface(texture);
                //设置 Surface，mSurface 和 mTextureView 通过 texture 关联在了一起，
                //所以调用该接口后，解码数据自动渲染到 mTextureView 上
            mLivePlayer.setSurface(mSurface);
        }
    
        ......
});
```

- **OpenGL 相关参考代码**
如果您在调整画面尺寸遇到问题，可以参考下完整的示例代码 - [调整画面尺寸](https://cloud.tencent.com/document/product/454/9723)
如果您在使用 OpenGL ES 对视频数据进行二次处理没有思路，可以参考下示例代码 - [OpenGL ES 处理数据](https://cloud.tencent.com/document/product/454/9724)

### 方案二：获取 YUV 数据（仅适用软解码播放）

如果您想通过获取 SDK 解码之后的 YUV 类型的视频数据，您可以按如下步骤实现。

- 监听 PLAY_EVT_CHANGE_RESOLUTION 事件

```Java
    public void onPlayEvent(int event, Bundle param) {
        //...
        if (event == TXLiveConstants.PLAY_EVT_CHANGE_RESOLUTION) {
            //获取视频的宽高
            int width = param.getInt(TXLiveConstants.EVT_PARAM1, 0);
            int height = param.getInt(TXLiveConstants.EVT_PARAM2, 0);
            if (width != 0 && height != 0 && !mHWDecode) {
                //创建存储 yuv 数据的 buffer，目前输出的 yuv 格式为 I420
                byte[] buf = new byte[width * height * 3 / 2];
                //将 buffer 设置进 mLivePlayer
                mLivePlayer.addVideoRawData(buf);
            }
        }
    }
```

- 通过 VideoRawDataListener 获取 YUV 裸数据

```Java
TXVideoRawDataObserver.ITXVideoRawDataListener rawDataListener = new
TXVideoRawDataObserver.ITXVideoRawDataListener() {
    @Override
    public void onVideoRawDataAvailable(byte[] buf, int width, int height, int timestamp) {
        //解码一帧后的数据回调，buf 中存放了 yuv 数据，格式为 I420
        if (!mHWDecode) {
            //如果需要继续获取yuv数据，需要重新调用addVideoRawData方法
            mLivePlayer.addVideoRawData(buf);
        }
    }
};

mLivePlayer.setVideoRawDataListener(rawDataListener);
```
